# ==== æœ¬é¡µéšè—ä¾§æ ï¼ˆæ›´å¼ºå…¼å®¹ç‰ˆï¼‰+ æ”¾å¤§å­—ä½“ ====
import streamlit as st
import streamlit.components.v1 as components

# åªä¿ç•™ä¸€æ¬¡ set_page_configï¼Œæ”¾æœ€å‰
try:
    st.set_page_config(page_title="æ¸©æ§å™¨åˆ†æï¼ˆ1.1.3.3ï¼‰", layout="wide", initial_sidebar_state="collapsed")
except Exception:
    pass

# â€”â€” CSSï¼šå¼ºåˆ¶éšè—å„ç§ Sidebar å®¹å™¨ä¸æŠ˜å æŒ‰é’®ï¼ˆè¦†ç›–ä¸åŒç‰ˆæœ¬çš„ data-testidï¼‰
st.markdown("""
<style>
/* å‘½ä¸­ä¸åŒç‰ˆæœ¬/ä¸»é¢˜ä¸‹çš„ä¾§æ åŠå…¶å®¹å™¨ã€æŠ˜å æŒ‰é’® */
aside[aria-label="sidebar"],
aside[aria-label="Sidebar"],
aside[class*="sidebar"],
[data-testid="stSidebar"],
[data-testid^="stSidebar"],
[data-testid*="Sidebar"],
[data-testid="stSidebarNav"],
[data-testid="stSidebarContent"],
[data-testid="stSidebarCollapsedControl"],
[data-testid*="Collapse"],
[data-testid*="collapsed"],
nav[aria-label="Sidebar navigation"]{
  display: none !important;
  width: 0 !important; min-width: 0 !important; max-width: 0 !important;
  visibility: hidden !important; pointer-events: none !important; opacity: 0 !important;
}

/* æœ‰äº›ç‰ˆæœ¬ä¸»å®¹å™¨ä¼šç»™ä¾§æ ç•™å‡ºç©ºä½ï¼Œå‹å›å» */
div.block-container{
  padding-left: 1rem !important;
  padding-right: 1rem !important;
  margin-left: 0 !important;
}
section.main, div.main, [data-testid="stAppViewContainer"]{
  margin-left: 0 !important;
}
</style>
""", unsafe_allow_html=True)

# â€”â€” JSï¼šå¦‚æœç”¨æˆ·ç‚¹äº†â€œå±•å¼€ä¾§æ â€ï¼Œä¹Ÿç«‹å³å†éšè—ï¼ˆDOM å˜æ›´ç›‘å¬ï¼‰
components.html("""
<script>
(function(){
  function nuke(){
    const sels = [
      'aside[aria-label="sidebar"]',
      'aside[aria-label="Sidebar"]',
      'aside[class*="sidebar"]',
      '[data-testid="stSidebar"]',
      '[data-testid^="stSidebar"]',
      '[data-testid*="Sidebar"]',
      '[data-testid="stSidebarNav"]',
      '[data-testid="stSidebarContent"]',
      '[data-testid="stSidebarCollapsedControl"]',
      '[data-testid*="Collapse"]',
      '[data-testid*="collapsed"]',
      'nav[aria-label="Sidebar navigation"]'
    ];
    for (const s of sels){
      document.querySelectorAll(s).forEach(el=>{
        el.style.display='none';
        el.style.width='0'; el.style.minWidth='0'; el.style.maxWidth='0';
        el.style.visibility='hidden'; el.style.pointerEvents='none'; el.style.opacity='0';
      });
    }
    const bc = document.querySelector('div.block-container');
    if (bc){ bc.style.paddingLeft='1rem'; bc.style.paddingRight='1rem'; }
  }
  nuke();
  new MutationObserver(nuke).observe(document.body, {subtree:true, childList:true, attributes:true});
  // ä¿é™©ï¼šé—´éš”æ£€æŸ¥ï¼ˆé˜²æ­¢æŸäº›ç‰ˆæœ¬çš„å¼‚æ­¥æŒ‚è½½æ¼ç½‘ï¼‰
  setInterval(nuke, 500);
})();
</script>
""", height=0)
# ==== éšè—ä¾§æ éƒ¨åˆ†ç»“æŸ ====
# ================= åŸºç¡€ä¾èµ– =================
import streamlit as st
import pandas as pd
import numpy as np
import re, json
from pathlib import Path
from urllib.parse import unquote

# ================= é¡µé¢æŠ¬å¤´ =================
st.set_page_config(page_title="æ¸©æ§å™¨é…ä»¶åˆ†æï¼ˆ1.1.3.3ï¼‰", layout="wide", initial_sidebar_state="expanded")
st.title("æ¸©æ§å™¨é…ä»¶åˆ†æ 1.1.3.3")

# ================= æŒä¹…åŒ–è·¯å¾„ =================
STORE_PARQUET     = Path("data_store.parquet")
STORE_CSV         = Path("data_store.csv")
MODEL_FLEET_JSON  = Path("model_fleet_counts.json")   # å‹å·ç³»åˆ—åœ¨ä¿é‡ï¼ˆå¯é€‰ï¼‰
SPEC_FLEET_JSON   = Path("spec_fleet_counts.json")    # âœ… å…·ä½“å‹å·åœ¨ä¿é‡ï¼ˆé€šç”¨ï¼‰
CTRL_2COL_JSON    = Path("ctrl_model_map_2col.json")  # âœ… æ¸©æ§å‹å·ä¸¤åˆ—ç²˜è´´ä¸“ç”¨ï¼ˆä»…æ¸©æ§å™¨åˆ†æç”¨ï¼‰
RAW_EXCEL_STORE = Path("raw_excel_store.parquet")

def _load_raw_excel_store() -> pd.DataFrame:
    if RAW_EXCEL_STORE.exists():
        try:
            return pd.read_parquet(RAW_EXCEL_STORE)
        except Exception:
            try:
                return pd.read_csv(RAW_EXCEL_STORE.with_suffix(".csv"), dtype=str)
            except Exception:
                pass
    return pd.DataFrame()


# === ç»Ÿä¸€å…¼å®¹ç‰ˆï¼šå…·ä½“å‹å·åœ¨ä¿é‡ ===
from pathlib import Path
import json, re
import pandas as pd

SPEC_FLEET_JSON = Path("spec_fleet_counts.json")  # ä¸¤ä¸ªé¡µé¢ä¿æŒå®Œå…¨ä¸€è‡´

def normalize_model_key(s: str) -> str:
    s = "" if s is None else str(s)
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s).strip()
    return s.upper()

def _load_spec_fleet_any():
    """å…¼å®¹ä¸¤ç§æ–‡ä»¶æ ¼å¼ï¼š
       1) æ—§ç‰ˆ: { "AOM 48": 123, ... }
       2) æ–°ç‰ˆ: {"triples":[{"a":"AOM 48","b":"","fleet":123}, ...]}
    """
    if not SPEC_FLEET_JSON.exists():
        return [], {}
    try:
        data = json.loads(SPEC_FLEET_JSON.read_text(encoding="utf-8"))
    except Exception:
        return [], {}

    if isinstance(data, dict) and "triples" in data:
        triples = data["triples"]
    elif isinstance(data, dict):
        triples = [{"a": k, "b": "", "fleet": v} for k, v in data.items()]
    elif isinstance(data, list):
        triples = data
    else:
        triples = []

    mp = {}
    for r in triples:
        a = normalize_model_key(r.get("a", ""))
        b = normalize_model_key(r.get("b", ""))
        f = int(pd.to_numeric(r.get("fleet", 0), errors="coerce") or 0)
        if a: mp[a] = f
        if b: mp[b] = f
    return triples, mp

# â€”â€” ä¼šè¯æ€åˆå§‹åŒ–ï¼ˆä¸¤ä¸ªé¡µé¢éƒ½ç”¨è¿™å¥—ï¼‰
if "spec_fleet_triples" not in st.session_state or "spec_fleet_map" not in st.session_state:
    triples, mp = _load_spec_fleet_any()
    st.session_state.spec_fleet_triples = triples
    st.session_state.spec_fleet_map = mp

def lookup_spec_fleet(model_name: str) -> int:
    return int(st.session_state.spec_fleet_map.get(normalize_model_key(model_name), 0))

def _save_spec_fleet_triples(triples: list[dict]) -> tuple[bool, str]:
    """ç»Ÿä¸€ä¿å­˜ä¸ºæ–°ç‰ˆç»“æ„ {"triples":[...]}ï¼Œä¸¤é¡µé¢å…±äº«"""
    try:
        payload = {"triples": triples}
        SPEC_FLEET_JSON.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
        return True, ""
    except Exception as e:
        return False, str(e)


# ================== æ¸©æ§å‹å·ä¸¤åˆ—ç²˜è´´ Â· ç‹¬ç«‹æ˜ å°„ ==================
def _norm_txt2(s: str) -> str:
    s = "" if s is None else str(s)
    s = s.replace("\u3000", " ")
    s = re.sub(r"\s+", " ", s).strip()
    return s

def _norm_key2(s: str) -> str:
    return _norm_txt2(s).upper()

def _parse_left_cell(cell: str) -> tuple[str, str]:
    """
    è§£æå·¦åˆ—ï¼š`æ¸©æ§å‹å·  ä¾›åº”å•†/`
    è¿”å›ï¼š(æ¸©æ§å‹å·, ä¾›åº”å•†)
    """
    s = _norm_txt2(cell)
    m = re.match(r"^(?P<ctrl>.+?)\s+(?P<vendor>.+?)\/\s*$", s)
    if m:
        return _norm_txt2(m.group("ctrl")), _norm_txt2(m.group("vendor"))
    m2 = re.match(r"^(?P<ctrl>.+?)\s+(?P<vendor>[^\/]+)$", s)
    if m2:
        return _norm_txt2(m2.group("ctrl")), _norm_txt2(m2.group("vendor"))
    return s, ""

def _load_ctrl2col_rows() -> list[dict]:
    if CTRL_2COL_JSON.exists():
        try:
            data = json.loads(CTRL_2COL_JSON.read_text(encoding="utf-8"))
            if isinstance(data, list):
                return data
            if isinstance(data, dict) and "rows" in data:
                return data["rows"]
        except Exception:
            pass
    return []

def _save_ctrl2col_rows(rows: list[dict]) -> tuple[bool, str]:
    try:
        CTRL_2COL_JSON.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding="utf-8")
        return True, ""
    except Exception as e:
        return False, str(e)

# â€”â€” ä¼šè¯æ€ä¸æŸ¥æ‰¾å‡½æ•°
if "ctrl2col_rows" not in st.session_state:
    st.session_state.ctrl2col_rows = _load_ctrl2col_rows()

def _build_ctrl_maps_2col(rows: list[dict]):
    ctrl2code, ctrl2vendor = {}, {}
    for r in rows:
        ctrl = _norm_key2(r.get("ctrl", "")) or _norm_key2(r.get("fan", ""))  # å…¼å®¹å†å²å­—æ®µå
        if not ctrl:
            continue
        ctrl2code[ctrl] = _norm_txt2(r.get("code", ""))
        ctrl2vendor[ctrl] = _norm_txt2(r.get("vendor", ""))
    return ctrl2code, ctrl2vendor

CTRL2CODE, CTRL2VENDOR = _build_ctrl_maps_2col(st.session_state.ctrl2col_rows)

def ctrl2code(ctrl: str) -> str:
    return CTRL2CODE.get(_norm_key2(ctrl), "")

def ctrl2vendor(ctrl: str) -> str:
    return CTRL2VENDOR.get(_norm_key2(ctrl), "")

# === åŸºäºæ˜ å°„çš„å¸¦äº§å“æŸ¥æ‰¾å·¥å…·ï¼ˆäº§å“=æ•´æœºå‹å·ï¼Œå¯é€‰ï¼‰ ===
def _build_index_from_session_rows():
    rows = st.session_state.get("ctrl2col_rows", []) or []
    ctrl_index = {}     # { CTRL_UPPER: [row, ...] }
    product_index = {}  # { PRODUCT_UPPER: [row, ...] }
    for r in rows:
        # å…¼å®¹å†å²å­—æ®µ fan
        ctrl_u = _norm_key2(r.get("ctrl", "") or r.get("fan", ""))
        prod_u = normalize_model_key(r.get("product", ""))
        if ctrl_u:   ctrl_index.setdefault(ctrl_u, []).append(r)
        if prod_u:   product_index.setdefault(prod_u, []).append(r)
    return ctrl_index, product_index

def _choose_row(rows):
    # ä¼˜å…ˆè¿”å›æœ‰ code çš„é‚£æ¡ï¼›å¦åˆ™ç¬¬ä¸€æ¡
    for r in rows:
        if _norm_txt2(r.get("code", "")):
            return r
    return rows[0] if rows else None

def ctrl_map_lookup(ctrl: str = "", *, product: str | None = None):
    """
    è¿”å› (display_ctrl_with_vendor, code)
       display_ctrl_with_vendor: 'TC-55  EGO/'ï¼ˆè‹¥æ—  vendor åˆ™ä»…å‹å·ï¼‰
       code: ç‰©æ–™ç¼–ç 
    """
    ctrl_index, product_index = _build_index_from_session_rows()

    def _display(row):
        c = _norm_txt2(row.get("ctrl", "") or row.get("fan", ""))
        v = _norm_txt2(row.get("vendor", ""))
        return f"{c}  {v}/" if c and v else c

    if ctrl:
        ckey = _norm_key2(ctrl)
        if ckey in ctrl_index:
            hit = _choose_row(ctrl_index[ckey])
            if hit:
                return _display(hit), _norm_txt2(hit.get("code", ""))

    if product:
        pkey = normalize_model_key(product)
        if pkey in product_index:
            hit = _choose_row(product_index[pkey])
            if hit:
                return _display(hit), _norm_txt2(hit.get("code", ""))

    return _norm_txt2(ctrl), ""

with st.expander("æ¸©æ§å‹å·æ˜ å°„ï¼ˆä¸¤åˆ—ç²˜è´´ï¼›å·¦=â€œæ¸©æ§å‹å·  ä¾›åº”å•†/â€ï¼Œå³=â€œç‰©æ–™ç¼–ç â€ï¼‰", expanded=False):
    st.caption("æ­¤è¡¨ä»…ç”¨äºæ¸©æ§å™¨åˆ†æï¼Œä¸å½±å“å…¶ä»–é…ä»¶ã€‚å¯ç›´æ¥ä»ä¸¤åˆ—è¡¨æ ¼å¤åˆ¶ç²˜è´´ã€‚")
    pasted = st.text_area(
        "ç²˜è´´ä¸¤åˆ—æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ¡ï¼›ä¸¤åˆ—ä¹‹é—´ç”¨Tabæˆ–â‰¥2ç©ºæ ¼ï¼›å·¦åˆ—æœ«å°¾ä¿ç•™â€œ/â€æ›´ç¨³ï¼‰ï¼š",
        height=140,
        placeholder="ç¤ºä¾‹ï¼š\nTC-55  EGO/    R03002000011\nXR-20CX  DIXELL/    R03002000022"
    )

    if st.button("è§£æå¹¶è¿½åŠ åˆ°ä¸‹æ–¹è¡¨æ ¼", use_container_width=True):
        add_rows = []
        for line in pasted.splitlines():
            line = line.strip()
            if not line:
                continue
            parts = re.split(r"[\t]{1,}|\s{2,}", line)
            if len(parts) < 2:
                parts = re.split(r"\s+", line)
                if len(parts) >= 2:
                    left = " ".join(parts[:-1]); right = parts[-1]
                else:
                    continue
            else:
                left, right = parts[0], parts[1]

            ctrl, vendor = _parse_left_cell(left)
            code = _norm_txt2(right)
            add_rows.append({"ctrl": ctrl, "vendor": vendor, "code": code, "product": ""})

        if add_rows:
            cols = ["ctrl","vendor","code","product"]
            cur = pd.DataFrame(st.session_state.ctrl2col_rows) if st.session_state.ctrl2col_rows else pd.DataFrame(columns=cols)
            cur = cur.reindex(columns=cols)
            if not cur.empty:
                cur["K"] = cur["ctrl"].map(_norm_key2)
            for r in add_rows:
                k = _norm_key2(r["ctrl"])
                if not cur.empty and (cur["K"] == k).any():
                    idx = cur.index[cur["K"] == k][0]
                    cur.loc[idx, ["vendor","code"]] = [r["vendor"], r["code"]]
                else:
                    cur = pd.concat([cur, pd.DataFrame([r])], ignore_index=True)
            if "K" in cur.columns:
                cur = cur.drop(columns=["K"])
            st.session_state.ctrl2col_rows = cur.fillna("").to_dict(orient="records")
            CTRL2CODE, CTRL2VENDOR = _build_ctrl_maps_2col(st.session_state.ctrl2col_rows)
            st.success(f"å·²è¿½åŠ /è¦†ç›– {len(add_rows)} æ¡ã€‚")

    # å¯ç¼–è¾‘è§†å›¾
    _rows = st.session_state.ctrl2col_rows or []
    view2 = (
        pd.DataFrame(_rows)
        .reindex(columns=["ctrl","vendor","product","code"])
        .rename(columns={
            "ctrl":"æ¸©æ§å‹å·",
            "vendor":"ä¾›åº”å•†",
            "product":"å‹å·ï¼ˆäº§å“å‹å·ï¼‰",
            "code":"ç‰©æ–™ç¼–ç "
        })
    )
    if not view2.empty:
        def _join(c, v): return f"{c}  {v}/" if v else c
        view2.insert(1, "æ¸©æ§å‹å·+ä¾›åº”å•†", view2.apply(lambda r: _join(_norm_txt2(r["æ¸©æ§å‹å·"]), _norm_txt2(r["ä¾›åº”å•†"])), axis=1))
        view2 = view2[["æ¸©æ§å‹å·","æ¸©æ§å‹å·+ä¾›åº”å•†","å‹å·ï¼ˆäº§å“å‹å·ï¼‰","ç‰©æ–™ç¼–ç "]].sort_values(
            ["æ¸©æ§å‹å·","å‹å·ï¼ˆäº§å“å‹å·ï¼‰","æ¸©æ§å‹å·+ä¾›åº”å•†"], ignore_index=True
        )
    else:
        view2 = pd.DataFrame(columns=["æ¸©æ§å‹å·","æ¸©æ§å‹å·+ä¾›åº”å•†","å‹å·ï¼ˆäº§å“å‹å·ï¼‰","ç‰©æ–™ç¼–ç "])

    edited2 = st.data_editor(
        view2,
        num_rows="dynamic",
        use_container_width=True,
        key="ctrl2col_editor",
        column_config={
            "æ¸©æ§å‹å·": st.column_config.TextColumn(help="ä¾‹å¦‚ XR-20CXã€TC-55 ç­‰"),
            "æ¸©æ§å‹å·+ä¾›åº”å•†": st.column_config.TextColumn(help="ç¤ºä¾‹ï¼šXR-20CX  DIXELL/"),
            "å‹å·ï¼ˆäº§å“å‹å·ï¼‰": st.column_config.TextColumn(help="æ•´æœºäº§å“å‹å·ï¼Œå¯ç•™ç©º"),
            "ç‰©æ–™ç¼–ç ": st.column_config.TextColumn(help="ç¤ºä¾‹ï¼šR03002000022"),
        }
    )

    c1, c2, c3 = st.columns(3)
    with c1:
        if st.button("ä¿å­˜åˆ°æœ¬åœ°ï¼ˆctrl_model_map_2col.jsonï¼‰", use_container_width=True):
            rows = []
            for _, r in edited2.iterrows():
                fv = _norm_txt2(r.get("æ¸©æ§å‹å·+ä¾›åº”å•†","")) or _norm_txt2(r.get("æ¸©æ§å‹å·",""))
                ctrl, vendor = _parse_left_cell(fv)
                product = _norm_txt2(r.get("å‹å·ï¼ˆäº§å“å‹å·ï¼‰",""))
                code = _norm_txt2(r.get("ç‰©æ–™ç¼–ç ",""))
                if not ctrl and not code and not product:
                    continue
                rows.append({"ctrl": ctrl, "vendor": vendor, "code": code, "product": product})
            ok, msg = _save_ctrl2col_rows(rows)
            if ok:
                st.session_state.ctrl2col_rows = rows
                CTRL2CODE, CTRL2VENDOR = _build_ctrl_maps_2col(rows)
                st.success(f"å·²ä¿å­˜ {len(rows)} æ¡ã€‚")
            else:
                st.error(f"ä¿å­˜å¤±è´¥ï¼š{msg}")

    with c2:
        if not edited2.empty:
            st.download_button(
                "å¯¼å‡ºå½“å‰è¡¨ä¸º CSV",
                data=edited2.to_csv(index=False, encoding="utf-8-sig"),
                file_name="ctrl_model_map_2col.csv",
                mime="text/csv",
                use_container_width=True
            )

    with c3:
        if st.button("æ¸…ç©ºï¼ˆä»…å†…å­˜ï¼Œä¸è½ç›˜ï¼‰", use_container_width=True):
            st.session_state.ctrl2col_rows = []
            CTRL2CODE, CTRL2VENDOR = _build_ctrl_maps_2col([])
            st.rerun()

# ================= å·¥å…·å‡½æ•°ï¼ˆè½»é‡æ¸…æ´—ï¼‰ =================
def ensure_cols(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame(columns=[
            "Date","Category1","Category2","TAG1","TAG2","TAG3","TAG4",
            "CostUSD","PaidQty","IsWarranty","Completed","Year","Month","Quarter","_SrcYM"
        ])
    mapping = {}
    for c in df.columns:
        lc = str(c).strip().lower()
        if lc in ["æ—¥æœŸ","date","created_at","å‘ç”Ÿæ—¥æœŸ","ç”Ÿäº§æ—¥æœŸ"]: mapping[c] = "Date"
        elif lc in ["åˆ†ç±»1","category1","å¤§ç±»"]: mapping[c] = "Category1"
        elif lc in ["åˆ†ç±»2","category2","å°ç±»"]: mapping[c] = "Category2"
        elif lc in ["tag1","tag 1","tag-1"]: mapping[c] = "TAG1"
        elif lc in ["tag2","tag 2","tag-2"]: mapping[c] = "TAG2"
        elif lc in ["tag3","tag 3","tag-3"]: mapping[c] = "TAG3"
        elif lc in ["tag4","tag 4","tag-4"]: mapping[c] = "TAG4"
        elif lc in ["cost","costusd","amount","è´¹ç”¨","é‡‘é¢","fee","cost(usd)","cost usd"]: mapping[c] = "CostUSD"
        elif lc in ["paidqty","paid_qty","å·²ä»˜æ¬¾æ•°é‡"]: mapping[c] = "PaidQty"
        elif lc in ["iswarranty","warranty","æ˜¯å¦æ‰¿ä¿"]: mapping[c] = "IsWarranty"
        elif lc in ["completed","æ˜¯å¦å®Œæˆ","ç»´ä¿®çŠ¶æ€","çŠ¶æ€"]: mapping[c] = "Completed"
    if mapping:
        df = df.rename(columns=mapping)
    for col, default in [
        ("Category1",""),("Category2",""),("TAG1",""),("TAG2",""),("TAG3",""),("TAG4",""),
        ("CostUSD",0.0),("PaidQty",0),("IsWarranty",False),("Completed",False)
    ]:
        if col not in df.columns:
            df[col] = default
    df["CostUSD"] = pd.to_numeric(df["CostUSD"], errors="coerce").fillna(0.0)
    df["PaidQty"] = pd.to_numeric(df["PaidQty"], errors="coerce").fillna(0).astype(int)
    if "Year" in df.columns:
        df["Year"] = pd.to_numeric(df["Year"], errors="coerce")
    if "Month" in df.columns:
        df["Month"] = pd.to_numeric(df["Month"], errors="coerce")
    return df

def _clean_text(s: str) -> str:
    s = ("" if pd.isna(s) else str(s)).lower().replace("\u3000", " ")
    s = re.sub(r"[\s\-_\/]+", " ", s)
    return s.strip()

def get_param(name: str, default=None, cast=int):
    try:
        v = st.query_params.get(name, default)
    except Exception:
        qp = st.experimental_get_query_params()
        v = (qp.get(name, [default]) or [default])[0]
    if v is None:
        return default
    if cast is None:
        return v
    try:
        return cast(v)
    except Exception:
        return default

def get_param_str(name: str, default=None):
    try:
        v = st.query_params.get(name, default)
    except Exception:
        qp = st.experimental_get_query_params()
        v = (qp.get(name, [default]) or [default])[0]
    if isinstance(v, str):
        return unquote(v)
    return default

def load_store_df_from_disk() -> pd.DataFrame:
    if STORE_PARQUET.exists():
        try:
            return pd.read_parquet(STORE_PARQUET)
        except Exception:
            pass
    if STORE_CSV.exists():
        try:
            return pd.read_csv(STORE_CSV)
        except Exception:
            pass
    return pd.DataFrame()

def get_store_df() -> pd.DataFrame:
    if "store_df" in st.session_state and isinstance(st.session_state["store_df"], pd.DataFrame):
        return ensure_cols(st.session_state["store_df"].copy())
    return ensure_cols(load_store_df_from_disk())

def money(v) -> str:
    try:
        return f"${float(v):,.0f}"
    except Exception:
        return "$0"

def _fmt_pct(v, digits=2):
    try:
        if v is None or (isinstance(v, float) and np.isnan(v)): 
            return ""
        return f"{float(v):.{digits}f}%"
    except Exception:
        return ""

def format_percent_cols(df: pd.DataFrame, cols: list[str], digits: int = 2) -> pd.DataFrame:
    if df is None or df.empty: 
        return df
    df2 = df.copy()
    for c in cols:
        if c in df2.columns:
            df2[c] = df2[c].map(lambda x: _fmt_pct(x, digits))
    return df2

# ================= å‚æ•°ä¸æ•°æ®è¯»å– =================
code  = get_param_str("code", default="1.1.3.3")
year  = get_param("year", default=None, cast=int)
month = get_param("month", default=None, cast=int)

# æ–°å¢ï¼šæ”¯æŒå¤šæœˆ/å­£åº¦
months_param = get_param_str("months", default=None)   # å½¢å¦‚ "1,2,3"
q_param      = get_param_str("q", default=None)        # å½¢å¦‚ "Q1"

df_all = get_store_df()
if df_all.empty:
    st.warning("æœªè·å–åˆ°ä»»ä½•æ•°æ®ï¼šè¯·å…ˆåœ¨â€œå†°ç®±æ•°æ®â€é¡µé¢ä¸Šä¼ æ•°æ®ï¼›æˆ–ç¡®è®¤ data_store.parquet / data_store.csv æ˜¯å¦å­˜åœ¨ã€‚")
    st.stop()

yy = pd.to_numeric(df_all.get("Year"), errors="coerce")
mm = pd.to_numeric(df_all.get("Month"), errors="coerce")

# â€”â€” è§£æ sel_year / sel_months
# å¹´ä»½ä¼˜å…ˆç”¨å‚æ•°ï¼›æ²¡æœ‰å°±ç”¨æ•°æ®ä¸­çš„æœ€å¤§å¹´
if year is None:
    if yy.notna().any():
        year = int(yy.dropna().max())
    else:
        year = 2025

# è§£ææœˆä»½é›†åˆï¼ˆä¼˜å…ˆçº§ï¼šmonths > month > q > å•æœˆå›é€€åˆ°å½“å¹´æœ€æ–°æœˆï¼‰
sel_months = None

# 1) months=1,2,3
if months_param:
    try:
        sel_months = [int(x) for x in re.split(r"[,\s]+", months_param) if x]
    except Exception:
        sel_months = None

# 2) month=3
if (sel_months is None) and (month is not None):
    sel_months = [int(month)]

# 3) q=Q1/Q2/Q3/Q4
if (sel_months is None) and q_param:
    _q_map = {"Q1":[1,2,3], "Q2":[4,5,6], "Q3":[7,8,9], "Q4":[10,11,12]}
    sel_months = _q_map.get(str(q_param).upper(), None)

# 4) æ²¡æœ‰ä»»ä½•æœˆä»½å…¥å‚ï¼Œå°±ç”¨å½“å¹´æ•°æ®é‡Œæœ€æ–°æœˆä»½
if sel_months is None:
    mm_this_year = pd.to_numeric(df_all.loc[yy == year, "Month"], errors="coerce")
    if mm_this_year.notna().any():
        sel_months = [int(mm_this_year.dropna().max())]
    else:
        sel_months = [1]  # å®åœ¨æ²¡æœ‰å°±ç»™ä¸ªå…œåº•

# ä»£è¡¨æœˆï¼ˆç”¨äºåé¢è¡¨æ ¼é‡Œåœ¨ä¿é‡å£å¾„ï¼›æ²¿ç”¨â€œé€‰æ‹©å­£åº¦æ—¶å–è¯¥æœŸé—´æœ€åä¸€æœˆâ€çš„ä¹ æƒ¯ï¼‰
month_for_fleet = int(sorted(sel_months)[-1])

# â€”â€” è¿‡æ»¤æœŸé—´æ•°æ®
mask_year   = (yy == int(year))
mask_months = mm.isin([int(m) for m in sel_months])
scope_df    = df_all[mask_year & mask_months].copy()

# â€”â€” å£å¾„æ ‡é¢˜
if set(sel_months) == {1,2,3}:
    scope_text = f"{year} Q1"
elif set(sel_months) == {4,5,6}:
    scope_text = f"{year} Q2"
elif set(sel_months) == {7,8,9}:
    scope_text = f"{year} Q3"
elif set(sel_months) == {10,11,12}:
    scope_text = f"{year} Q4"
elif len(sel_months) == 1:
    scope_text = f"{year}-{int(sel_months[0]):02d}"
else:
    scope_text = f"{year} æœˆä»½ï¼š{','.join(str(m) for m in sel_months)}"

if scope_df.empty:
    st.info(f"{scope_text} æ²¡æœ‰å¯ç»Ÿè®¡æ•°æ®ã€‚")
    st.stop()


joined_all = scope_df.astype(str).agg(" ".join, axis=1).map(_clean_text)
pat_code = re.compile(rf"(?<![0-9a-z]){re.escape(code)}(?![0-9a-z])", re.I)
mask_code = joined_all.str.contains(pat_code)
df_code   = scope_df[mask_code].copy()

st.caption(f"ç»Ÿè®¡å£å¾„ï¼š{scope_text} | ç¼ºé™·ç ï¼š{code}")
if df_code.empty:
    st.warning("è¯¥å£å¾„ä¸‹æœªå‘½ä¸­ä»»ä½• 1.1.3.3 ç›¸å…³è®°å½•ã€‚")
    st.stop()
# ================= é¡¶éƒ¨æŠ¬å¤´æ¡ =================
def render_topbar(_code: str, _scope_text: str, df_scope: pd.DataFrame):
    paid = pd.to_numeric(df_scope.get("CostUSD", 0), errors="coerce").fillna(0)
    qty  = len(df_scope)
    cost = float(paid[paid > 0].sum())
    avg  = float(paid[paid > 0].mean()) if (paid > 0).any() else 0.0
    col1, col2, col3, col4 = st.columns([1.2, 1, 1, 1])
    with col1:
        st.markdown(
            f"""
            <div style="padding:12px 16px;border-radius:14px;background:#0f172a;color:#fff;">
              <div style="font-size:13px;opacity:.7;">ç¼ºé™·ç  / ç»Ÿè®¡å£å¾„</div>
              <div style="font-size:20px;font-weight:700;line-height:1.2;margin-top:2px;">{_code}</div>
              <div style="font-size:13px;margin-top:2px;">{_scope_text}</div>
            </div>
            """, unsafe_allow_html=True
        )
    with col2: st.metric("è®°å½•æ•°", f"{qty}")
    with col3: st.metric("å·²ä»˜æ¬¾æ€»è´¹ç”¨", money(cost))
    with col4: st.metric("å•å‡å·²ä»˜æ¬¾è´¹ç”¨", money(avg))

render_topbar(code, scope_text, df_code)
st.markdown("---")
# ================= 1.1.3.3.xï¼ˆæ¸©æ§å™¨ï¼‰åˆ†é¡¹ =================
def build_1133_subtable(df_in: pd.DataFrame):
    # é¢„å¤„ç†
    join = df_in.astype(str).agg(" ".join, axis=1).str.lower().str.replace("\u3000", " ", regex=False)
    join = join.str.replace(r"[\s\-_\/]+", " ", regex=True).str.strip()

    # å„å­ç±»æ­£åˆ™ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼Œé¿å…è¯¯åŒ…å«ï¼‰
    def _pat(s): 
        return re.compile(rf"(?<![0-9a-z]){re.escape(s)}(?![0-9a-z])", re.I)

    pats = {
        "1.1.3.3.1 error code":                      ("æ˜¾ç¤º ER",         _pat("1.1.3.3.1")),
        "1.1.3.3.2 P3/P4":                           ("æ˜¾ç¤º P3/P4",      _pat("1.1.3.3.2")),
        "1.1.3.3.3 DO/EO":                           ("æ˜¾ç¤º DO/EO",      _pat("1.1.3.3.3")),
        "1.1.3.3.4 No Display":                      ("ä¸æ˜¾ç¤º",           _pat("1.1.3.3.4")),
        "1.1.3.3.5 Setting temp/HY Code":            ("æ¸©å·®ï¼Œè°ƒæ•´Hy",     _pat("1.1.3.3.5")),
        "1.1.3.3.6 Reprogram controller/parameters tech didn't mention":
                                                     ("å‚æ•°è°ƒæ•´",         _pat("1.1.3.3.6")),
    }

    # å·²è¢«ä»»ä½•å­ç±»å‘½ä¸­çš„è®°å½•
    mask_any_sub = np.zeros(len(df_in), dtype=bool)
    rows = []

    # å­ç±»è¡Œ
    for en_name, (cn_name, pat) in pats.items():
        m = join.str.contains(pat)
        mask_any_sub |= m.values
        qty = int(m.sum())
        fee = float(pd.to_numeric(df_in.loc[m, "CostUSD"], errors="coerce").fillna(0).sum())
        rows.append({"è‹±æ–‡åç§°": en_name, "è´¨é‡é—®é¢˜": cn_name, "æ•°é‡": qty, "è´¹ç”¨": fee})

    # é¡¶å±‚ 1.1.3.3ï¼ˆåªç®—æ²¡æœ‰ .1~.6 çš„é‚£äº›ï¼‰
    # æ³¨æ„ï¼šæ­¤å‡½æ•°åº”è¯¥å¯¹ df_code è°ƒç”¨ï¼›df_code å·²ç»æ˜¯ 1.1.3.3 çš„å­é›†
    m_top_only = ~mask_any_sub
    qty_top = int(m_top_only.sum())
    fee_top = float(pd.to_numeric(df_in.loc[m_top_only, "CostUSD"], errors="coerce").fillna(0).sum())
    rows.insert(0, {"è‹±æ–‡åç§°": "1.1.3.3 Temp Controller", "è´¨é‡é—®é¢˜": "æ¸©æ§å™¨", "æ•°é‡": qty_top, "è´¹ç”¨": fee_top})

    # æ€»è®¡è¡Œï¼ˆå¯é€‰ï¼‰
    df_out = pd.DataFrame(rows)
    total_row = {"è‹±æ–‡åç§°": "æ€»è®¡", "è´¨é‡é—®é¢˜": "", "æ•°é‡": int(df_out["æ•°é‡"].sum()), "è´¹ç”¨": float(df_out["è´¹ç”¨"].sum())}
    df_out = pd.concat([df_out, pd.DataFrame([total_row])], ignore_index=True)
    return df_out

# â€”â€” æ¸²æŸ“
df_1133 = build_1133_subtable(df_code)
st.markdown("### 1.1.3.3.x åˆ†é¡¹ï¼ˆæ¸©æ§å™¨ï¼‰")
if not df_1133.empty:
    # é‡‘é¢åˆ—æ ¼å¼åŒ–æ˜¾ç¤ºï¼ˆ$xx,xxxï¼‰
    df_view = df_1133.copy()
    df_view["è´¹ç”¨"] = df_view["è´¹ç”¨"].map(lambda v: f"${float(v):,.0f}")
    st.dataframe(df_view, use_container_width=True)
    st.download_button(
        "ä¸‹è½½ CSVï¼ˆ1.1.3.3 åˆ†é¡¹ï¼‰",
        data=df_1133.to_csv(index=False, encoding="utf-8-sig"),
        file_name=f"ctrl_1133_breakdown_{scope_text.replace(' ','_')}.csv",
        mime="text/csv",
        use_container_width=True
    )
else:
    st.info("æš‚æ—  1.1.3.3 ç›¸å…³è®°å½•ã€‚")

    
# ================= ä¸‰å¼ ç»Ÿè®¡è¡¨ï¼ˆâ€œæŒ‰ç³»åˆ—/æŒ‰å…·ä½“å‹å·/æŒ‰æ¸©æ§å‹å·â€ï¼‰ =================
USE_MONTH_CAND = [
    "å·²ä½¿ç”¨ä¿ä¿®æ—¶é•¿","å·²ä½¿ç”¨ä¿ä¿®æœˆæ•°","ä¿ä¿®å·²ä½¿ç”¨æ—¶é•¿","å·²ä½¿ç”¨æœˆä»½","ä¿ä¿®ä½¿ç”¨æœˆæ•°",
    "ä½¿ç”¨æœˆæ•°","ä½¿ç”¨æœˆ","ServiceMonths","months_in_use","use_months"
]
SERIES_PRI_CAND = ["å‹å·å½’ç±»","å‹å·ç³»åˆ—","series","model_series"]
SERIES_SEC_CAND = ["æœºå‹","äº§å“å‹å·","MODEL","Model"]
SPEC_MODEL_CAND = ["å‹å·","å…·ä½“å‹å·","æœºå‹æ˜ç»†","MODEL","Model","Part Model","PartModel","Part"]
CTRL_KIND_CAND  = ["æ¸©æ§å‹å·","æ§åˆ¶å™¨å‹å·","Controller","ControllerModel","Thermo","Thermostat"]
PART_CODE_CAND  = ["Rç ","ç‰©æ–™ç¼–ç ","ç‰©æ–™å·","PartCode","Part No"]

MODEL_CATEGORY_MAP = {
    "MBF":"å†°ç®±","MCF":"é™ˆåˆ—æŸœ","MSF":"æ²™æ‹‰å°","MGF":"å·¥ä½œå°","MPF":"ç»ç’ƒå°","CHEF BASE":"æŠ½å±‰å·¥ä½œå°",
    "MBC":"æ»‘ç›–å†·è—æŸœ","MBB":"å§å¼å§å°","SBB":"ç§»é—¨å§å°","MKC":"å•¤é…’æŸœ","MBGF":"æ»‘ç›–å†·å†»æŸœ",
    "AMC":"ç‰›å¥¶æŸœ","RDCS":"æ–¹å½¢å±•ç¤ºæŸœ","CRDC":"å¼§å½¢å±•ç¤ºæŸœ","CRDS":"å°é¢æ–¹å½¢å±•ç¤ºæŸœ","ATHOM":"é¥®æ–™æŸœ",
    "AOM":"ç«‹å¼é¥®æ–™æŸœ","MSCT":"é…æ–™å°",
}
MODEL_ORDER = ["AOM","CHEF BASE","MBC","MBF","MBGF","MCF","MGF","MPF","MSF"]
ALIASES = {"CHEFBASE":"CHEF BASE","CHEF-BASE":"CHEF BASE","CHEF_BASE":"CHEF BASE","CHEF BASE":"CHEF BASE"}

def resolve_model_key(raw: str) -> str:
    s = (raw or "").strip().replace("\u3000"," ")
    s_norm = re.sub(r"[\s\-_\/]+", " ", s).strip()
    key_up = s_norm.upper().replace(" ", "")
    for k,v in ALIASES.items():
        if key_up == k.upper().replace(" ",""):
            return v
    toks = s_norm.split()
    if len(toks)>1: return " ".join(t.upper() for t in toks)
    return s_norm.upper()

def _pick_col(df: pd.DataFrame, cands: list):
    for c in cands:
        if c in df.columns: return c
    norm = {re.sub(r"[\s_]+","", str(c).lower()): c for c in df.columns}
    for want in cands:
        k = re.sub(r"[\s_]+","", str(want).lower())
        if k in norm: return norm[k]
    return None

def load_model_fleet():
    if MODEL_FLEET_JSON.exists():
        try:
            return json.loads(MODEL_FLEET_JSON.read_text(encoding="utf-8"))
        except Exception:
            pass
    return {}

def get_fleet_month(fleet: dict, year: int=None, month: int=None)->dict:
    if not fleet:
        return {k:0 for k in MODEL_CATEGORY_MAP.keys()}
    if year is None or month is None:
        try:
            yy = max(int(y) for y in fleet.keys())
            mm = max(int(m) for m in fleet[str(yy)].keys())
            year, month = yy, mm
        except Exception:
            return {k:0 for k in MODEL_CATEGORY_MAP.keys()}
    y, m = str(int(year)), str(int(month))
    return {k:int(fleet.get(y,{}).get(m,{}).get(k,0)) for k in MODEL_CATEGORY_MAP.keys()}

def _bucket_series(months: pd.Series):
    m = pd.to_numeric(months, errors="coerce").where(lambda x: x > 0)
    return pd.cut(m, bins=[0, 4, 8, np.inf],
                  labels=["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"],
                  include_lowest=True, right=True)

def build_tables(df_subset: pd.DataFrame, *, year=None, month=None):
    months_col = _pick_col(df_subset, USE_MONTH_CAND)
    series_col = _pick_col(df_subset, SERIES_PRI_CAND) or _pick_col(df_subset, SERIES_SEC_CAND)
    spec_col   = _pick_col(df_subset, SPEC_MODEL_CAND)
    ctype_col  = _pick_col(df_subset, CTRL_KIND_CAND)  # æºæ•°æ®ä¸­çš„æ¸©æ§å‹å·ï¼ˆè‹¥æœ‰ï¼‰
    if months_col is None:
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    if series_col is None and spec_col is not None:
        tmp = df_subset[spec_col].astype(str).str.upper().str.extract(r"^([A-Z]{2,4})")
        df_subset = df_subset.copy()
        df_subset["__SERIES__"] = tmp[0]
        series_col = "__SERIES__"

    m = pd.to_numeric(df_subset[months_col], errors="coerce")
    valid_mask = m.notna() & (m > 0)
    df_valid = df_subset[valid_mask].copy()
    if df_valid.empty:
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
    df_valid["__bucket__"] = _bucket_series(df_valid[months_col])


    # è¡¨1ï¼šæŒ‰ç³»åˆ—
    tbl1 = pd.DataFrame()
    if series_col is not None:
        g = pd.pivot_table(df_valid, index=series_col, columns="__bucket__", values="Date",
                           aggfunc="count", fill_value=0)
        for c in ["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"]:
            if c not in g.columns: g[c] = 0
        g = g[["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"]]
        g["æ€»è®¡"] = g.sum(axis=1)
        g.reset_index(inplace=True)
        g.rename(columns={series_col:"å‹å·"}, inplace=True)

        fleet = load_model_fleet()
        month_fleet = get_fleet_month(fleet, year, month)
        def _fleet_lookup(s):
            key = resolve_model_key(s)
            return int(month_fleet.get(key, 0))
        g["åœ¨ä¿é‡"] = g["å‹å·"].map(_fleet_lookup).fillna(0).astype(int)
        g["é—®é¢˜æ¯”ä¾‹(%)"] = np.where(g["åœ¨ä¿é‡"]>0, g["æ€»è®¡"]/g["åœ¨ä¿é‡"]*100.0, np.nan)

        order_map = {k:i for i,k in enumerate(MODEL_ORDER)}
        g["__ord__"] = g["å‹å·"].map(order_map).fillna(9999)
        g = g.sort_values(["__ord__","æ€»è®¡"], ascending=[True,False]).drop(columns="__ord__")
        tbl1 = g

    # è¡¨2ï¼šæŒ‰å…·ä½“å‹å·ï¼ˆè¡¥é½â€œæ¸©æ§å‹å·/ç‰©æ–™ç¼–ç â€ï¼‰
    tbl2 = pd.DataFrame()
    if spec_col is not None:
        g2 = pd.pivot_table(
            df_valid, index=spec_col, columns="__bucket__", values="Date",
            aggfunc="count", fill_value=0
        )
        for c in ["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"]:
            if c not in g2.columns: g2[c] = 0
        g2 = g2[["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"]]
        g2["æ€»è®¡"] = g2.sum(axis=1)
        g2.reset_index(inplace=True)
        g2.rename(columns={spec_col: "å…·ä½“å‹å·"}, inplace=True)

        # æºæ•°æ®æ¸©æ§å‹å·çš„ä¼—æ•°ï¼ˆè‹¥æœ‰åˆ—ï¼‰
        def _mode(series):
            s = series.dropna().astype(str)
            if s.empty: return ""
            m0 = s.mode()
            return m0.iloc[0] if not m0.empty else s.iloc[0]
        if ctype_col:
            base_ctrl = (
                df_subset.groupby(spec_col)[ctype_col].apply(_mode)
                .reindex(g2["å…·ä½“å‹å·"]).fillna("").values
            )
        else:
            base_ctrl = [""] * len(g2)

        out_ctrl_display, out_code = [], []
        for i, row in g2.iterrows():
            spec_model = _norm_txt2(row["å…·ä½“å‹å·"])
            ctrl_guess = _norm_txt2(base_ctrl[i]) if isinstance(base_ctrl, (list, np.ndarray)) else _norm_txt2(base_ctrl)
            display_ctrl, code_from_map = ctrl_map_lookup(
                ctrl=ctrl_guess,
                product=spec_model
            )
            out_ctrl_display.append(display_ctrl if display_ctrl else ctrl_guess)
            out_code.append(code_from_map)

        g2["æ¸©æ§å‹å·"] = out_ctrl_display
        g2["ç‰©æ–™ç¼–ç "] = out_code

        g2["åœ¨ä¿é‡"] = g2["å…·ä½“å‹å·"].map(lookup_spec_fleet).fillna(0).astype(int)
        g2["æ¯”ä¾‹(%)"] = np.where(g2["åœ¨ä¿é‡"]>0, g2["æ€»è®¡"]/g2["åœ¨ä¿é‡"]*100.0, np.nan)
        g2 = g2.sort_values("æ€»è®¡", ascending=False)

        for c in ["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡"]:
            if c not in g2.columns: g2[c] = 0
        for c in ["æ¸©æ§å‹å·","ç‰©æ–™ç¼–ç "]:
            if c not in g2.columns: g2[c] = ""
        tbl2 = g2

    # è¡¨3ï¼šç”±â€œæŒ‰å…·ä½“å‹å·â€æ±‡æ€» -> æ¸©æ§å‹å·
    tbl3 = pd.DataFrame()
    if spec_col is not None and not tbl2.empty:
        tmp = tbl2.copy()
        tmp["æ¸©æ§å‹å·"] = tmp["æ¸©æ§å‹å·"].replace("", np.nan).fillna("(æœªè¯†åˆ«)")
        sum_cols = ["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡"]
        for c in sum_cols:
            if c not in tmp.columns: tmp[c] = 0
        g3 = tmp.groupby("æ¸©æ§å‹å·", as_index=False)[sum_cols].sum()
        g3["é—®é¢˜æ¯”ä¾‹(%)"] = np.where(g3["åœ¨ä¿é‡"] > 0, g3["æ€»è®¡"] / g3["åœ¨ä¿é‡"] * 100.0, np.nan)
        g3 = g3.sort_values("æ€»è®¡", ascending=False)
        tbl3 = g3

    return tbl1, tbl2, tbl3

# â€”â€” æ¸²æŸ“ï¼ˆæ¸©æ§å™¨ä¸å†åŒºåˆ† 5.1/5.2 å­ç±»ï¼‰
t1, t2, t3 = build_tables(df_code, year=year, month=month_for_fleet)
base1 = pd.DataFrame(columns=["å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"])
base2 = pd.DataFrame(columns=["å…·ä½“å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ¸©æ§å‹å·","ç‰©æ–™ç¼–ç ","æ€»è®¡","åœ¨ä¿é‡","æ¯”ä¾‹(%)"])
base3 = pd.DataFrame(columns=["æ¸©æ§å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"])

def render_sortable_table(title: str, df: pd.DataFrame, *, order_cols):
    cols = [c for c in order_cols if c in df.columns]
    view = df.loc[:, cols].copy() if cols else df.copy()
    for pct_col in ["é—®é¢˜æ¯”ä¾‹(%)", "æ¯”ä¾‹(%)"]:
        if pct_col in view.columns:
            view[pct_col] = view[pct_col].map(lambda x: "" if pd.isna(x) else f"{float(x):.2f}%")
    st.subheader(title)
    st.caption("æç¤ºï¼šç‚¹å‡»åˆ—å¤´å¯æ’åºï¼›å†æ¬¡ç‚¹å‡»åˆ‡æ¢å‡/é™åºï¼›æŒ‰ä½ Shift æ”¯æŒå¤šåˆ—æ’åºã€‚")
    st.dataframe(view, use_container_width=True)

def render_sortable_table_collapsed(title: str, df: pd.DataFrame, *, order_cols, expanded=False):
    cols = [c for c in order_cols if c in df.columns]
    view = df.loc[:, cols].copy() if cols else df.copy()
    for pct_col in ["é—®é¢˜æ¯”ä¾‹(%)", "æ¯”ä¾‹(%)"]:
        if pct_col in view.columns:
            view[pct_col] = view[pct_col].map(lambda x: "" if pd.isna(x) else f"{float(x):.2f}%")
    with st.expander(title, expanded=expanded):
        st.caption("æç¤ºï¼šç‚¹å‡»åˆ—å¤´å¯æ’åºï¼›å†æ¬¡ç‚¹å‡»åˆ‡æ¢å‡/é™åºï¼›æŒ‰ä½ Shift æ”¯æŒå¤šåˆ—æ’åºã€‚")
        st.dataframe(view, use_container_width=True)

render_sortable_table("æ¸©æ§å™¨ï¼ˆæŒ‰ç³»åˆ—ï¼‰", (t1 if not t1.empty else base1),
                      order_cols=("å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"))

render_sortable_table("æ¸©æ§å™¨ï¼ˆæŒ‰å…·ä½“å‹å·ï¼‰", (t2 if not t2.empty else base2),
                      order_cols=("å…·ä½“å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ¸©æ§å‹å·","ç‰©æ–™ç¼–ç ","æ€»è®¡","åœ¨ä¿é‡","æ¯”ä¾‹(%)"))


render_sortable_table("æ¸©æ§å™¨ï¼ˆæŒ‰æ¸©æ§å‹å·ï¼‰", (t3 if not t3.empty else base3),
                      order_cols=("æ¸©æ§å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"))

# ===== åˆ†é¡¹æ·±å…¥åˆ†æï¼ˆä»…æ•°é‡>0ï¼Œå« 1.1.3.3.1 ~ 1.1.3.3.6ï¼‰=====
st.markdown("## åˆ†é¡¹æ·±å…¥åˆ†æï¼ˆä»…æ•°é‡>0ï¼Œå« 1.1.3.3.1 ~ 1.1.3.3.6ï¼‰")

import re  # <- ç¡®ä¿æœ‰

def _clean_join(df_):
    j = df_.astype(str).agg(" ".join, axis=1).str.lower().str.replace("\u3000", " ", regex=False)
    return j.str.replace(r"[\s\-_\/]+", " ", regex=True).str.strip()

def _subset_1133_item(df_src: pd.DataFrame, en_name: str) -> pd.DataFrame:
    """ä» df_code ä¸­ç­›é€‰æŒ‡å®šå­é¡¹ï¼ˆ1~6ï¼‰ã€‚"""
    if df_src is None or df_src.empty:
        return df_src.iloc[0:0].copy()
    j = _clean_join(df_src)
    # é¢„ç¼–è¯‘ 1~6 çš„æ­£åˆ™
    pats = {f"1.1.3.3.{i}": re.compile(rf"(?<![0-9a-z])1\.1\.3\.3\.{i}(?![0-9a-z])", re.I) for i in range(1, 7)}
    m = re.search(r"(1\.1\.3\.3\.[1-6])", en_name or "")
    if m:
        pat = pats.get(m.group(1))
        return df_src[j.str.contains(pat)].copy()
    return df_src.iloc[0:0].copy()

# â€”â€” åªæ‹¿ 1.1.3.3.[1-6] ä¸” æ•°é‡>0ï¼›æŒ‰æ•°é‡é™åºï¼Œå¤šçš„æ”¾å‰é¢
if ("è‹±æ–‡åç§°" not in df_1133.columns) or ("æ•°é‡" not in df_1133.columns):
    st.error("å†…éƒ¨è¡¨ df_1133 ç¼ºå°‘ 'è‹±æ–‡åç§°' æˆ– 'æ•°é‡' åˆ—ï¼Œè¯·æ£€æŸ¥ build_1133_subtable çš„è¾“å‡ºã€‚")
else:
    rows_need = (
        df_1133[
            df_1133["è‹±æ–‡åç§°"].astype(str).str.match(r"^1\.1\.3\.3\.[1-6]\b", na=False) &
            (pd.to_numeric(df_1133["æ•°é‡"], errors="coerce").fillna(0) > 0)
        ]
        .sort_values("æ•°é‡", ascending=False)
        .copy()
    )

    if rows_need.empty:
        st.info("å½“å‰ 1.1.3.3.1~1.1.3.3.6 æ²¡æœ‰æ•°é‡>0 çš„æ¡ç›®å¯æ·±å…¥åˆ†æã€‚")
    else:
        for idx, r in rows_need.iterrows():
            en_name = str(r["è‹±æ–‡åç§°"])
            zh_name = str(r.get("è´¨é‡é—®é¢˜", ""))
            sub_df = _subset_1133_item(df_code, en_name)

            with st.expander(f"ã€{en_name}ã€‘{zh_name}ï½œè®°å½• {int(r['æ•°é‡'])}ï¼Œè´¹ç”¨ {money(float(r.get('è´¹ç”¨', 0)))}",
                             expanded=(idx == rows_need.index[0])):
                a1, a2, a3 = build_tables(sub_df, year=year, month=month_for_fleet)

                _base1 = pd.DataFrame(columns=["å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"])
                _base2 = pd.DataFrame(columns=["å…·ä½“å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ¸©æ§å‹å·","ç‰©æ–™ç¼–ç ","æ€»è®¡","åœ¨ä¿é‡","æ¯”ä¾‹(%)"])
                _base3 = pd.DataFrame(columns=["æ¸©æ§å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"])

                render_sortable_table("æŒ‰ç³»åˆ—", (a1 if not a1.empty else _base1),
                                      order_cols=("å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"))

                render_sortable_table("æŒ‰å…·ä½“å‹å·", (a2 if not a2.empty else _base2),
                      order_cols=("å…·ä½“å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ¸©æ§å‹å·","ç‰©æ–™ç¼–ç ","æ€»è®¡","åœ¨ä¿é‡","æ¯”ä¾‹(%)"))


                render_sortable_table("æŒ‰æ¸©æ§å‹å·", (a3 if not a3.empty else _base3),
                                      order_cols=("æ¸©æ§å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"))

# ================= åŸå§‹æ˜ç»†ï¼ˆå‘½ä¸­ 1.1.3.3 çš„è®°å½•ï¼‰ =================
with st.expander("åŸå§‹æ˜ç»†ï¼ˆå‘½ä¸­ 1.1.3.3 çš„è®°å½•ï¼‰", expanded=False):
    # â€”â€” ç»Ÿä¸€æŠŠ 231221 / 202405 / 2024-5-6 â€¦ è½¬æˆ YYYY-MM-DD
    def _norm_date_text(raw: pd.Series) -> pd.Series:
        s = raw.astype(str).str.strip()
        out = pd.Series("", index=s.index, dtype="object")

        # 8ä½ï¼šYYYYMMDD
        m8 = s.str.fullmatch(r"\d{8}", na=False)
        if m8.any():
            dt8 = pd.to_datetime(s[m8], format="%Y%m%d", errors="coerce")
            out.loc[m8] = dt8.dt.strftime("%Y-%m-%d")

        # 6ä½ï¼šä¼˜å…ˆ YYMMDDï¼ˆå¦‚ 231221ï¼‰ï¼›ä»… (19|20)YYYYMMï¼ˆå¦‚ 202405ï¼‰æŒ‰ YYYYMMâ†’è¡¥01æ—¥
        m6 = s.str.fullmatch(r"\d{6}", na=False)
        if m6.any():
            s6 = s[m6]
            is_yyyymm = s6.str.match(r"(19|20)\d{2}(0[1-9]|1[0-2])$")
            idx_y4 = s6.index[is_yyyymm.fillna(False)]
            if len(idx_y4) > 0:
                dt_a = pd.to_datetime(s6.loc[idx_y4] + "01", format="%Y%m%d", errors="coerce")
                out.loc[idx_y4] = dt_a.dt.strftime("%Y-%m-%d")
            idx_y2 = s6.index[~is_yyyymm.fillna(False)]
            if len(idx_y2) > 0:
                y = "20" + s6.loc[idx_y2].str.slice(0, 2)
                m = s6.loc[idx_y2].str.slice(2, 4)
                d = s6.loc[idx_y2].str.slice(4, 6)
                dt_b = pd.to_datetime(y + m + d, format="%Y%m%d", errors="coerce")
                out.loc[idx_y2] = dt_b.dt.strftime("%Y-%m-%d")

        # å…¶ä½™äº¤ç»™ to_datetime
        rest = (out == "")
        if rest.any():
            dt = pd.to_datetime(s[rest], errors="coerce", infer_datetime_format=True)
            out.loc[rest] = dt.dt.strftime("%Y-%m-%d")

        # å¤±è´¥ä¿ç•™åŸå€¼
        failed = out.isna() | (out == "NaT") | (out == "")
        if failed.any():
            out.loc[failed] = s.loc[failed]
        return out

    # åŸºè¡¨
    df_view = df_code.copy()

    # â€”â€” ä¸â€œåŸå§‹ Excel è¡¨æ˜ å°„â€å…³è”ï¼Œè¡¥ã€åŸå§‹ç”Ÿäº§æ—¥æœŸã€‘ã€åŸå§‹åºåˆ—å·ã€‘
    RAW_PROD_CANDS   = ["ç”Ÿäº§æ—¥æœŸ","ç”Ÿäº§æ—¥","ProductionDate","ProdDate","åˆ¶é€ æ—¥æœŸ","å‡ºå‚æ—¥æœŸ"]
    RAW_SERIAL_CANDS = ["åºåˆ—å·","S/N","SN","Serial No","SerialNo","Serial","åºåˆ—å·SN"]
    DEDUP_KEYS = [
        "å·¥å•å·","ç´¢èµ”å·","CaseNo","TicketNo",
        "S/N","Serial No","SN","Serial","SerialNo",
        "åºåˆ—å·","åºåˆ—å·SN"
    ]

    def _pick_first(df, cands):
        for c in cands:
            if c in df.columns:
                return c
        return None

    raw_hist = _load_raw_excel_store()
    if not raw_hist.empty:
        join_keys = [k for k in DEDUP_KEYS if (k in df_view.columns) and (k in raw_hist.columns)]
        raw_prod_col   = _pick_first(raw_hist, RAW_PROD_CANDS)
        raw_serial_col = _pick_first(raw_hist, RAW_SERIAL_CANDS)

        if join_keys and (raw_prod_col or raw_serial_col):
            take_cols = [k for k in join_keys]
            if raw_prod_col   and raw_prod_col   not in take_cols: take_cols.append(raw_prod_col)
            if raw_serial_col and raw_serial_col not in take_cols: take_cols.append(raw_serial_col)

            patch = raw_hist.loc[:, take_cols].drop_duplicates().copy()

            # ä¸æ”¹ join key çš„åˆ—åï¼›ä»…å¤åˆ¶å‡ºâ€œåŸå§‹*â€åˆ—
            if raw_prod_col:
                if raw_prod_col in join_keys:
                    patch["åŸå§‹ç”Ÿäº§æ—¥æœŸ"] = _norm_date_text(patch[raw_prod_col])
                else:
                    patch = patch.rename(columns={raw_prod_col: "åŸå§‹ç”Ÿäº§æ—¥æœŸ"})
                    patch["åŸå§‹ç”Ÿäº§æ—¥æœŸ"] = _norm_date_text(patch["åŸå§‹ç”Ÿäº§æ—¥æœŸ"])
            if raw_serial_col:
                if raw_serial_col in join_keys:
                    patch["åŸå§‹åºåˆ—å·"] = patch[raw_serial_col]
                else:
                    patch = patch.rename(columns={raw_serial_col: "åŸå§‹åºåˆ—å·"})

            df_view = df_view.merge(patch, on=join_keys, how="left", suffixes=("", "_rawdup"))
            st.caption("ï¼ˆå·²ä»ğŸ“ åŸå§‹ Excel è¡¨æ˜ å°„æŒ‰ %s å…³è”è¡¥å…¥ï¼š%sï¼‰" % (
                ", ".join(join_keys),
                "ã€".join([c for c in ["åŸå§‹ç”Ÿäº§æ—¥æœŸ","åŸå§‹åºåˆ—å·"] if c in df_view.columns]) or "æ— "
            ))
        else:
            st.caption("ï¼ˆåŸå§‹åº“å¯ç”¨ï¼Œä½†æœªæ‰¾åˆ°å…±åŒä¸»é”®æˆ–åŸå§‹â€œç”Ÿäº§æ—¥æœŸ/åºåˆ—å·â€åˆ—ï¼Œæ˜¾ç¤ºç°æœ‰åˆ—ï¼‰")
    else:
        st.caption("ï¼ˆæœªæ‰¾åˆ°ğŸ“ åŸå§‹ Excel è¡¨æ˜ å°„ï¼Œæ˜¾ç¤ºç°æœ‰åˆ—ï¼‰")

    # â€”â€” è‹¥æ²¡ä»åŸå§‹åº“å–åˆ°ï¼Œä¹Ÿå°è¯•ç”¨å½“å‰è¡¨ä¸­çš„å€™é€‰åˆ—ç”Ÿæˆâ€œåŸå§‹ç”Ÿäº§æ—¥æœŸâ€
    if "åŸå§‹ç”Ÿäº§æ—¥æœŸ" not in df_view.columns:
        date_src = next((c for c in ["åŸå§‹ç”Ÿäº§æ—¥æœŸ","ç”Ÿäº§æ—¥æœŸ","ç”Ÿäº§æ—¥","productiondate","proddate","åˆ¶é€ æ—¥æœŸ","å‡ºå‚æ—¥æœŸ","Date"] if c in df_view.columns), None)
        if date_src:
            df_view["åŸå§‹ç”Ÿäº§æ—¥æœŸ"] = _norm_date_text(df_view[date_src])
        else:
            df_view["åŸå§‹ç”Ÿäº§æ—¥æœŸ"] = ""

    # â€”â€” æ–°å¢ç»Ÿä¸€â€œåºåˆ—å·â€åˆ—ï¼ˆä¼˜å…ˆç”¨â€œåŸå§‹åºåˆ—å·â€ï¼Œå¦åˆ™å›é€€åˆ°å¸¸è§åˆ—ï¼‰
    SERIAL_CANDS_SHOW = ["åŸå§‹åºåˆ—å·","åºåˆ—å·","S/N","SN","Serial No","SerialNo","Serial","åºåˆ—å·SN"]
    serial_src = next((c for c in SERIAL_CANDS_SHOW if c in df_view.columns), None)
    df_view["åºåˆ—å·"] = df_view[serial_src].astype(str) if serial_src else ""

    # â€”â€” å±•ç¤ºåˆ—é¡ºåº
    base_cols = ["Category1","Category2","TAG1","TAG2","TAG3","TAG4","CostUSD","PaidQty","IsWarranty","Completed"]
    base_cols = [c for c in base_cols if c in df_view.columns]
    show_cols = ["åŸå§‹ç”Ÿäº§æ—¥æœŸ","åºåˆ—å·"] + base_cols
    st.dataframe(df_view.loc[:, show_cols], use_container_width=True)

    st.download_button(
        "ä¸‹è½½ CSVï¼ˆåŸå§‹æ˜ç»†ï¼‰",
        data=df_view.loc[:, show_cols].to_csv(index=False, encoding="utf-8-sig"),
        file_name="ctrl_1133_raw_details.csv",
        mime="text/csv",
        use_container_width=True
    )
