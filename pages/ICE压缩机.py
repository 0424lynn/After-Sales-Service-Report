# -*- coding: utf-8 -*-
# ICEå‹ç¼©æœºé…ä»¶åˆ†æï¼ˆ2.1.4.5ï¼‰â€” å®Œæ•´ç‰ˆï¼ˆå¼ºåˆ¶éšè—ä¾§æ  + å…¼å®¹å¤šç‰ˆæœ¬ï¼‰

# ================== å¼ºåˆ¶éšè—ä¾§æ ï¼ˆæ›´å¼ºå…¼å®¹ç‰ˆï¼‰ ==================
import streamlit as st
import streamlit.components.v1 as components

try:
    st.set_page_config(
        page_title="ICEå‹ç¼©æœºé…ä»¶åˆ†æï¼ˆ2.1.4.5ï¼‰",
        layout="wide",
        initial_sidebar_state="collapsed",
    )
except Exception:
    pass

st.markdown(
    """
<style>
aside[aria-label="sidebar"], aside[aria-label="Sidebar"], aside[class*="sidebar"],
[data-testid="stSidebar"], [data-testid^="stSidebar"], [data-testid*="Sidebar"],
[data-testid="stSidebarNav"], [data-testid="stSidebarContent"],
[data-testid="stSidebarCollapsedControl"], [data-testid*="Collapse"],
[data-testid*="collapsed"], nav[aria-label="Sidebar navigation"] {
  display:none !important; width:0 !important; min-width:0 !important; max-width:0 !important;
  visibility:hidden !important; pointer-events:none !important; opacity:0 !important;
}
div.block-container { padding-left:1rem !important; padding-right:1rem !important; margin-left:0 !important; }
section.main, div.main, [data-testid="stAppViewContainer"] { margin-left:0 !important; }
header [data-testid="baseButton-headerNoPadding"],
header [data-testid*="sidebar"],
button[title="Open sidebar"], button[aria-label="Open sidebar"],
[data-testid="collapsedControl"], [data-testid="stSidebarCollapsedControl"] {
  display:none !important; visibility:hidden !important; pointer-events:none !important; opacity:0 !important;
}
</style>
""",
    unsafe_allow_html=True,
)

components.html(
    """
<script>
(function(){
  function nuke(){
    const sels = [
      'aside[aria-label="sidebar"]','aside[aria-label="Sidebar"]','aside[class*="sidebar"]',
      '[data-testid="stSidebar"]','[data-testid^="stSidebar"]','[data-testid*="Sidebar"]',
      '[data-testid="stSidebarNav"]','[data-testid="stSidebarContent"]','[data-testid="stSidebarCollapsedControl"]',
      '[data-testid*="Collapse"]','[data-testid*="collapsed"]','nav[aria-label="Sidebar navigation"]'
    ];
    for(const s of sels){
      document.querySelectorAll(s).forEach(el=>{
        el.style.display='none';
        el.style.width='0'; el.style.minWidth='0'; el.style.maxWidth='0';
        el.style.visibility='hidden'; el.style.pointerEvents='none'; el.style.opacity='0';
      });
    }
    const bc = document.querySelector('div.block-container');
    if(bc){ bc.style.paddingLeft='1rem'; bc.style.paddingRight='1rem'; }
  }
  nuke();
  new MutationObserver(nuke).observe(document.body, { subtree:true, childList:true, attributes:true });
  setInterval(nuke, 500);
})();
</script>
""",
    height=1,
    scrolling=False,
)

# ================= åŸºç¡€ä¾èµ– =================
import pandas as pd
import numpy as np
import re, json
from pathlib import Path
from urllib.parse import unquote

# ================= é¡µé¢æŠ¬å¤´ =================
st.title("ICEå‹ç¼©æœºé…ä»¶åˆ†æ 2.1.4.5")

# ================= æŒä¹…åŒ–è·¯å¾„ï¼ˆåˆ¶å†°æœº *_ice ä¸“ç”¨ï¼‰ =================
STORE_PARQUET     = Path("data_store_ice.parquet")
STORE_CSV         = Path("data_store_ice.csv")
MODEL_FLEET_JSON  = Path("model_fleet_counts_ice.json")   # å‹å·ç³»åˆ—åœ¨ä¿é‡ï¼ˆICEï¼‰
SPEC_FLEET_JSON   = Path("spec_fleet_counts_ice.json")    # å…·ä½“å‹å·åœ¨ä¿é‡ï¼ˆICEï¼Œå¯é€‰ï¼Œä¸ç”¨äºâ€œæŒ‰å…·ä½“å‹å·â€çš„åœ¨ä¿é‡ï¼‰
RAW_EXCEL_STORE   = Path("raw_excel_store_ice.parquet")

def _load_raw_excel_store() -> pd.DataFrame:
    if RAW_EXCEL_STORE.exists():
        try:
            return pd.read_parquet(RAW_EXCEL_STORE)
        except Exception:
            try:
                return pd.read_csv(RAW_EXCEL_STORE.with_suffix(".csv"), dtype=str)
            except Exception:
                pass
    return pd.DataFrame()

# === ç»Ÿä¸€å…¼å®¹ï¼šå…·ä½“å‹å·åœ¨ä¿é‡ï¼ˆæœ¬é¡µâ€œæŒ‰å…·ä½“å‹å·â€ä»æ˜ å°„åˆ°ç³»åˆ—åœ¨ä¿é‡ï¼‰ ===
def normalize_model_key(s: str) -> str:
    s = "" if s is None else str(s)
    s = s.replace("\u3000"," ")
    s = re.sub(r"\s+"," ",s).strip()
    return s.upper()

def _load_spec_fleet_any():
    if not SPEC_FLEET_JSON.exists(): return [],{}
    try:
        data = json.loads(SPEC_FLEET_JSON.read_text(encoding="utf-8"))
    except Exception:
        return [],{}
    if isinstance(data, dict) and "triples" in data:
        triples = data["triples"]
    elif isinstance(data, dict):
        triples = [{"a":k,"b":"", "fleet":v} for k,v in data.items()]
    elif isinstance(data, list):
        triples = data
    else:
        triples = []
    mp={}
    for r in triples:
        a = normalize_model_key(r.get("a",""))
        b = normalize_model_key(r.get("b",""))
        f = int(pd.to_numeric(r.get("fleet",0), errors="coerce") or 0)
        if a: mp[a]=f
        if b: mp[b]=f
    return triples, mp

if "spec_fleet_triples" not in st.session_state or "spec_fleet_map" not in st.session_state:
    triples, mp = _load_spec_fleet_any()
    st.session_state.spec_fleet_triples = triples
    st.session_state.spec_fleet_map = mp

def lookup_spec_fleet(model_name: str) -> int:
    return int(st.session_state.spec_fleet_map.get(normalize_model_key(model_name), 0))

# ================= å·¥å…·å‡½æ•°ï¼ˆè½»é‡æ¸…æ´—ï¼‰ =================
def ensure_cols(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return pd.DataFrame(columns=[
            "Date","Category1","Category2","TAG1","TAG2","TAG3","TAG4",
            "CostUSD","PaidQty","IsWarranty","Completed","Year","Month","Quarter","_SrcYM"
        ])
    mapping={}
    for c in df.columns:
        lc=str(c).strip().lower()
        if lc in ["æ—¥æœŸ","date","created_at","å‘ç”Ÿæ—¥æœŸ","ç”Ÿäº§æ—¥æœŸ"]: mapping[c]="Date"
        elif lc in ["åˆ†ç±»1","category1","å¤§ç±»"]: mapping[c]="Category1"
        elif lc in ["åˆ†ç±»2","category2","å°ç±»"]: mapping[c]="Category2"
        elif lc in ["tag1","tag 1","tag-1"]: mapping[c]="TAG1"
        elif lc in ["tag2","tag 2","tag-2"]: mapping[c]="TAG2"
        elif lc in ["tag3","tag 3","tag-3"]: mapping[c]="TAG3"
        elif lc in ["tag4","tag 4","tag-4"]: mapping[c]="TAG4"
        elif lc in ["cost","costusd","amount","è´¹ç”¨","é‡‘é¢","fee","cost(usd)","cost usd"]: mapping[c]="CostUSD"
        elif lc in ["paidqty","paid_qty","å·²ä»˜æ¬¾æ•°é‡"]: mapping[c]="PaidQty"
        elif lc in ["iswarranty","warranty","æ˜¯å¦æ‰¿ä¿"]: mapping[c]="IsWarranty"
        elif lc in ["completed","æ˜¯å¦å®Œæˆ","ç»´ä¿®çŠ¶æ€","çŠ¶æ€"]: mapping[c]="Completed"
    if mapping: df=df.rename(columns=mapping)
    for col,default in [("Category1",""),("Category2",""),("TAG1",""),("TAG2",""),("TAG3",""),("TAG4",""),
                        ("CostUSD",0.0),("PaidQty",0),("IsWarranty",False),("Completed",False)]:
        if col not in df.columns: df[col]=default
    df["CostUSD"]=pd.to_numeric(df["CostUSD"], errors="coerce").fillna(0.0)
    df["PaidQty"]=pd.to_numeric(df["PaidQty"], errors="coerce").fillna(0).astype(int)
    if "Year" in df.columns:  df["Year"]=pd.to_numeric(df["Year"], errors="coerce")
    if "Month" in df.columns: df["Month"]=pd.to_numeric(df["Month"], errors="coerce")
    return df

def _clean_text(s: str) -> str:
    s = ("" if pd.isna(s) else str(s)).lower().replace("\u3000"," ")
    s = re.sub(r"[\s\-_\/]+"," ", s).strip()
    return s

def get_param(name: str, default=None, cast=int):
    try:
        v = st.query_params.get(name, default)
    except Exception:
        qp = st.experimental_get_query_params()
        v = (qp.get(name,[default]) or [default])[0]
    if v is None: return default
    if cast is None: return v
    try: return cast(v)
    except Exception: return default

def get_param_str(name: str, default=None):
    try:
        v = st.query_params.get(name, default)
    except Exception:
        qp = st.experimental_get_query_params()
        v = (qp.get(name,[default]) or [default])[0]
    if isinstance(v,str): return unquote(v)
    return default

def load_store_df_from_disk()->pd.DataFrame:
    if STORE_PARQUET.exists():
        try: return pd.read_parquet(STORE_PARQUET)
        except Exception: pass
    if STORE_CSV.exists():
        try: return pd.read_csv(STORE_CSV)
        except Exception: pass
    return pd.DataFrame()

def get_store_df()->pd.DataFrame:
    if "store_df" in st.session_state and isinstance(st.session_state["store_df"], pd.DataFrame):
        return ensure_cols(st.session_state["store_df"].copy())
    return ensure_cols(load_store_df_from_disk())

def money(v)->str:
    try: return f"${float(v):,.0f}"
    except Exception: return "$0"

def _fmt_pct(v, digits=2):
    try:
        if v is None or (isinstance(v,float) and np.isnan(v)): return ""
        return f"{float(v):.{digits}f}%"
    except Exception:
        return ""

# ================= å‚æ•°ä¸æ•°æ®è¯»å– =================
code  = get_param_str("code", default="2.1.4.5")  # â† å‹ç¼©æœº Compressor
year  = get_param("year", default=None, cast=int)
month = get_param("month", default=None, cast=int)

months_param = get_param_str("months", default=None)
q_param      = get_param_str("q", default=None)

df_all = get_store_df()
if df_all.empty:
    st.warning("æœªè·å–åˆ°ä»»ä½•æ•°æ®ï¼šè¯·å…ˆåœ¨â€œåˆ¶å†°æœºæ•°æ®â€é¡µé¢ä¸Šä¼ æ•°æ®ï¼›æˆ–ç¡®è®¤ data_store_ice.parquet / data_store_ice.csv æ˜¯å¦å­˜åœ¨ã€‚")
    st.stop()

yy = pd.to_numeric(df_all.get("Year"),  errors="coerce")
mm = pd.to_numeric(df_all.get("Month"), errors="coerce")

if year is None:
    if yy.notna().any():
        year = int(yy.dropna().max())
    else:
        year = 2025

sel_months = None
if months_param:
    try:
        sel_months = [int(x) for x in re.split(r"[,\s]+", months_param) if x]
    except Exception:
        sel_months = None
if (sel_months is None) and (month is not None):
    sel_months = [int(month)]
if (sel_months is None) and q_param:
    _q_map = {"Q1":[1,2,3], "Q2":[4,5,6], "Q3":[7,8,9], "Q4":[10,11,12]}
    sel_months = _q_map.get(str(q_param).upper(), None)
if sel_months is None:
    mm_this_year = pd.to_numeric(df_all.loc[yy == year, "Month"], errors="coerce")
    if mm_this_year.notna().any():
        sel_months = [int(mm_this_year.dropna().max())]
    else:
        sel_months = [1]

month_for_fleet = int(sorted(sel_months)[-1])

mask_year   = (yy == int(year))
mask_months = mm.isin([int(m) for m in sel_months])
scope_df    = df_all[mask_year & mask_months].copy()

_set = set(sel_months)
if _set == {1,2,3}:
    scope_text = f"{year} Q1"
elif _set == {4,5,6}:
    scope_text = f"{year} Q2"
elif _set == {7,8,9}:
    scope_text = f"{year} Q3"
elif _set == {10,11,12}:
    scope_text = f"{year} Q4"
elif len(sel_months) == 1:
    scope_text = f"{year}-{int(sel_months[0]):02d}"
else:
    scope_text = f"{year} æœˆä»½ï¼š{','.join(str(m) for m in sel_months)}"

if scope_df.empty:
    st.info(f"{scope_text} æ²¡æœ‰å¯ç»Ÿè®¡æ•°æ®ã€‚")
    st.stop()

joined_all = scope_df.astype(str).agg(" ".join, axis=1).map(_clean_text)
pat_code   = re.compile(rf"(?<![0-9a-z]){re.escape(code)}(?![0-9a-z])", re.I)
mask_code  = joined_all.str.contains(pat_code)
df_code    = scope_df[mask_code].copy()

st.caption(f"ç»Ÿè®¡å£å¾„ï¼š{scope_text} | ç¼ºé™·ç ï¼š{code}ï¼ˆCompressor / å‹ç¼©æœºï¼‰")
if df_code.empty:
    st.warning("è¯¥å£å¾„ä¸‹æœªå‘½ä¸­ä»»ä½• 2.1.4.5ï¼ˆå‹ç¼©æœºï¼‰ç›¸å…³è®°å½•ã€‚")
    st.stop()

# ================= é¡¶éƒ¨æŠ¬å¤´æ¡ =================
def render_topbar(_code: str, _scope_text: str, df_scope: pd.DataFrame):
    paid = pd.to_numeric(df_scope.get("CostUSD", 0), errors="coerce").fillna(0)
    qty  = len(df_scope)
    cost = float(paid[paid>0].sum())
    avg  = float(paid[paid>0].mean()) if (paid>0).any() else 0.0
    col1,col2,col3,col4 = st.columns([1.2,1,1,1])
    with col1:
        st.markdown(f"""
        <div style="padding:12px 16px;border-radius:14px;background:#0f172a;color:#fff;">
          <div style="font-size:13px;opacity:.7;">ç¼ºé™·ç  / ç»Ÿè®¡å£å¾„</div>
          <div style="font-size:20px;font-weight:700;line-height:1.2;margin-top:2px;">{_code}</div>
          <div style="font-size:13px;margin-top:2px;">{_scope_text}</div>
        </div>
        """, unsafe_allow_html=True)
    with col2: st.metric("è®°å½•æ•°", f"{qty}")
    with col3: st.metric("å·²ä»˜æ¬¾æ€»è´¹ç”¨", money(cost))
    with col4: st.metric("å•å‡å·²ä»˜æ¬¾è´¹ç”¨", money(avg))

render_topbar(code, scope_text, df_code)
st.markdown("---")

# ================= 2.1.4.5.xï¼ˆCompressor å­é¡¹ï¼‰åˆ†é¡¹ =================
def build_2145_subtable(df_in: pd.DataFrame) -> pd.DataFrame:
    join = df_in.astype(str).agg(" ".join, axis=1).str.lower().str.replace("\u3000"," ", regex=False)
    join = join.str.replace(r"[\s\-_\/]+"," ", regex=True).str.strip()

    # è‡ªåŠ¨è¯†åˆ« 2.1.4.5.x
    subcode_matches = join.str.extractall(r"(?<![0-9a-z])(2\.1\.4\.5\.[0-9a-z]+)(?![0-9a-z])", flags=re.I)[0]
    unique_subs = sorted(set(subcode_matches.str.lower().unique().tolist())) if not subcode_matches.empty else []

    rows=[]
    mask_any_sub = np.zeros(len(df_in), dtype=bool)
    for sub in unique_subs:
        pat = re.compile(rf"(?<![0-9a-z]){re.escape(sub)}(?![0-9a-z])", re.I)
        m   = join.str.contains(pat)
        mask_any_sub |= m.values
        qty = int(m.sum())
        fee = float(pd.to_numeric(df_in.loc[m,"CostUSD"], errors="coerce").fillna(0).sum())
        rows.append({"ç¼–ç ": sub.upper(), "ä¸­æ–‡æè¿°": "å‹ç¼©æœºå­é¡¹", "æ•°é‡": qty, "è´¹ç”¨": fee})

    # é¡¶å±‚ 2.1.4.5ï¼ˆä¸å«ä»»ä½• .5.xï¼‰
    p_top = re.compile(r"(?<![0-9a-z])2\.1\.4\.5(?![0-9a-z])", re.I)
    m_top_only = join.str.contains(p_top) & (~mask_any_sub)
    qty_top = int(m_top_only.sum())
    fee_top = float(pd.to_numeric(df_in.loc[m_top_only,"CostUSD"], errors="coerce").fillna(0).sum())
    rows.insert(0, {"ç¼–ç ":"2.1.4.5","ä¸­æ–‡æè¿°":"å‹ç¼©æœºï¼ˆæœªç»†åˆ†ï¼‰","æ•°é‡":qty_top,"è´¹ç”¨":fee_top})

    df_out = pd.DataFrame(rows)
    total_row = {"ç¼–ç ":"æ€»è®¡","ä¸­æ–‡æè¿°":"","æ•°é‡":int(df_out["æ•°é‡"].sum()),"è´¹ç”¨":float(df_out["è´¹ç”¨"].sum())}
    df_out = pd.concat([df_out, pd.DataFrame([total_row])], ignore_index=True)
    return df_out

df_2145 = build_2145_subtable(df_code)
st.markdown("### 2.1.4.5.x åˆ†é¡¹ï¼ˆCompressor / å‹ç¼©æœºï¼‰")
if not df_2145.empty:
    show = df_2145.copy(); show["è´¹ç”¨"] = show["è´¹ç”¨"].map(lambda v: f"${float(v):,.0f}")
    st.dataframe(show, use_container_width=True)
    st.download_button(
        "ä¸‹è½½ CSVï¼ˆ2.1.4.5 åˆ†é¡¹ï¼‰",
        data=df_2145.to_csv(index=False, encoding="utf-8-sig"),
        file_name=f"ice_compressor_2145_breakdown_{scope_text.replace(' ','_')}.csv",
        mime="text/csv", use_container_width=True
    )
else:
    st.info("æš‚æ—  2.1.4.5 ç›¸å…³è®°å½•ã€‚")

# ================= ç»Ÿè®¡ï¼ˆæŒ‰ç³»åˆ— / æŒ‰å…·ä½“å‹å·ï¼‰ =================
USE_MONTH_CAND = [
    "å·²ä½¿ç”¨ä¿ä¿®æ—¶é•¿","å·²ä½¿ç”¨ä¿ä¿®æœˆæ•°","ä¿ä¿®å·²ä½¿ç”¨æ—¶é•¿","å·²ä½¿ç”¨æœˆä»½","ä¿ä¿®ä½¿ç”¨æœˆæ•°",
    "ä½¿ç”¨æœˆæ•°","ä½¿ç”¨æœˆ","ServiceMonths","months_in_use","use_months"
]
SERIES_PRI_CAND = ["å‹å·å½’ç±»","å‹å·ç³»åˆ—","series","model_series"]
SERIES_SEC_CAND = ["æœºå‹","äº§å“å‹å·","MODEL","Model"]
SPEC_MODEL_CAND = ["å‹å·","å…·ä½“å‹å·","æœºå‹æ˜ç»†","MODEL","Model","Part Model","PartModel","Part"]

# â€”â€” ICE å‹å·ç³»åˆ—ï¼ˆå¦‚ YR140 / YR280 ...ï¼‰
ICE_MODEL_CATEGORY_MAP = {
    "YR140":  "åˆ¶å†°æœº-140",
    "YR280":  "åˆ¶å†°æœº-280",
    "YR450":  "åˆ¶å†°æœº-450",
    "YR800":  "åˆ¶å†°æœº-800",
    "CYR400": "å†°æ¡¶-400",
    "CYR700": "å†°æ¡¶-700",
    "HD350":  "åˆ¶å†°æœº-350",
}
ICE_MODEL_ORDER = ["YR140","YR280","YR450","YR800","CYR400","CYR700","HD350"]

ALIASES = {
    "YR140": "YR140", "YR-140": "YR140", "YR 140": "YR140",
    "YR280": "YR280", "YR-280": "YR280", "YR 280": "YR280",
    "YR450": "YR450", "YR-450": "YR450", "YR 450": "YR450",
    "YR800": "YR800", "YR-800": "YR800", "YR 800": "YR800",
    "CYR400": "CYR400", "CYR-400": "CYR400", "CYR 400": "CYR400",
    "CYR700": "CYR700", "CYR-700": "CYR700", "CYR 700": "CYR700",
    "HD350": "HD350", "HD-350": "HD350", "HD 350": "HD350",
}
def resolve_model_key(raw: str) -> str:
    s=(raw or "").strip().replace("\u3000"," ")
    s_norm=re.sub(r"[\s\-_\/]+"," ", s).strip()
    key_up=s_norm.upper().replace(" ","")
    for k,v in ALIASES.items():
        if key_up==k.upper().replace(" ",""): return v
    toks=s_norm.split()
    if len(toks)>1: return " ".join(t.upper() for t in toks)
    return s_norm.upper()

# â€”â€” å…·ä½“å‹å· â†’ ç³»åˆ—é”®ï¼ˆç”¨äºâ€œæŒ‰å…·ä½“å‹å·â€çš„åœ¨ä¿é‡æ¥è‡ªç³»åˆ—ï¼‰
def spec_to_series_key(spec: str) -> str:
    s_raw = (spec or "").upper()
    s = re.sub(r"[\s\\-_/]", "", s_raw)
    # ä¼˜å…ˆé•¿åŒ¹é…ï¼Œé¿å… YR1400 è¯¯åŒ¹é… YR140
    for k in sorted(ICE_MODEL_ORDER, key=len, reverse=True):
        if k.replace("-", "") in s:
            return k
    m = re.match(r"^(YR|CYR|HD)\s*-?\s*(\d{3})", s_raw, re.I)
    if m:
        return (m.group(1) + m.group(2)).upper().replace(" ", "").replace("-", "")
    return resolve_model_key(spec)

def _pick_col(df: pd.DataFrame, cands: list):
    for c in cands:
        if c in df.columns: return c
    norm={re.sub(r"[\s_]+","",str(c).lower()):c for c in df.columns}
    for want in cands:
        k=re.sub(r"[\s_]+","",str(want).lower())
        if k in norm: return norm[k]
    return None

def load_model_fleet():
    if MODEL_FLEET_JSON.exists():
        try: return json.loads(MODEL_FLEET_JSON.read_text(encoding="utf-8"))
        except Exception: pass
    return {}

def get_fleet_month(fleet: dict, year: int=None, month: int=None)->dict:
    if not fleet: return {k:0 for k in ICE_MODEL_CATEGORY_MAP.keys()}
    if year is None or month is None:
        try:
            yy=max(int(y) for y in fleet.keys())
            mm=max(int(m) for m in fleet[str(yy)].keys())
            year,month=yy,mm
        except Exception:
            return {k:0 for k in ICE_MODEL_CATEGORY_MAP.keys()}
    y,m=str(int(year)),str(int(month))
    return {k:int(fleet.get(y,{}).get(m,{}).get(k,0)) for k in ICE_MODEL_CATEGORY_MAP.keys()}

def _bucket_series(months: pd.Series):
    m=pd.to_numeric(months, errors="coerce").where(lambda x: x>0)
    return pd.cut(m, bins=[0,4,8,np.inf],
                  labels=["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"],
                  include_lowest=True, right=True)

def build_tables(df_subset: pd.DataFrame, *, year=None, month=None):
    months_col = _pick_col(df_subset, USE_MONTH_CAND)
    series_col = _pick_col(df_subset, SERIES_PRI_CAND) or _pick_col(df_subset, SERIES_SEC_CAND)
    spec_col   = _pick_col(df_subset, SPEC_MODEL_CAND)

    if months_col is None:
        return pd.DataFrame(), pd.DataFrame()

    if series_col is None and spec_col is not None:
        tmp = df_subset[spec_col].astype(str).str.upper().str.extract(r"^([A-Z]{2,4})")
        df_subset = df_subset.copy()
        df_subset["__SERIES__"] = tmp[0]
        series_col = "__SERIES__"

    m = pd.to_numeric(df_subset[months_col], errors="coerce")
    valid_mask = m.notna() & (m>0)
    df_valid = df_subset[valid_mask].copy()
    if df_valid.empty:
        return pd.DataFrame(), pd.DataFrame()
    df_valid["__bucket__"] = _bucket_series(df_valid[months_col])

    # è¡¨1ï¼šæŒ‰ç³»åˆ—
    tbl1=pd.DataFrame()
    if series_col is not None:
        g = pd.pivot_table(df_valid, index=series_col, columns="__bucket__", values="Date",
                           aggfunc="count", fill_value=0)
        for c in ["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"]:
            if c not in g.columns: g[c]=0
        g = g[["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"]]
        g["æ€»è®¡"]=g.sum(axis=1)
        g.reset_index(inplace=True)
        g.rename(columns={series_col:"å‹å·ç³»åˆ—"}, inplace=True)

        fleet=load_model_fleet()
        month_fleet=get_fleet_month(fleet, year, month)
        def _fleet_lookup(s):
            key=resolve_model_key(s)
            return int(month_fleet.get(key,0))
        g["åœ¨ä¿é‡"]=g["å‹å·ç³»åˆ—"].map(_fleet_lookup).fillna(0).astype(int)
        g["é—®é¢˜æ¯”ä¾‹(%)"]=np.where(g["åœ¨ä¿é‡"]>0, g["æ€»è®¡"]/g["åœ¨ä¿é‡"]*100.0, np.nan)

        order_map={k:i for i,k in enumerate(ICE_MODEL_ORDER)}
        g["__ord__"]=g["å‹å·ç³»åˆ—"].map(order_map).fillna(9999)
        g=g.sort_values(["__ord__","æ€»è®¡"], ascending=[True,False]).drop(columns="__ord__")
        tbl1=g

    # è¡¨2ï¼šæŒ‰å…·ä½“å‹å· â€”â€” åœ¨ä¿é‡ = å…·ä½“å‹å·â†’ç³»åˆ—é”®â†’series fleet
    tbl2=pd.DataFrame()
    if spec_col is not None:
        g2 = pd.pivot_table(df_valid, index=spec_col, columns="__bucket__", values="Date",
                            aggfunc="count", fill_value=0)
        for c in ["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"]:
            if c not in g2.columns: g2[c]=0
        g2 = g2[["çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰"]]
        g2["æ€»è®¡"]=g2.sum(axis=1)
        g2.reset_index(inplace=True)
        g2.rename(columns={spec_col:"å…·ä½“å‹å·"}, inplace=True)

        fleet = load_model_fleet()
        month_fleet = get_fleet_month(fleet, year, month)
        def _spec_fleet_lookup(spec_name: str) -> int:
            series_key = spec_to_series_key(spec_name)
            return int(month_fleet.get(series_key, 0))

        g2["åœ¨ä¿é‡"]=g2["å…·ä½“å‹å·"].map(_spec_fleet_lookup).fillna(0).astype(int)
        g2["æ¯”ä¾‹(%)"]=np.where(g2["åœ¨ä¿é‡"]>0, g2["æ€»è®¡"]/g2["åœ¨ä¿é‡"]*100.0, np.nan)
        g2=g2.sort_values("æ€»è®¡", ascending=False)
        tbl2=g2

    return tbl1, tbl2

# â€”â€” æ¸²æŸ“ç»Ÿè®¡è¡¨
t1, t2 = build_tables(df_code, year=year, month=month_for_fleet)
base1 = pd.DataFrame(columns=["å‹å·ç³»åˆ—","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"])
base2 = pd.DataFrame(columns=["å…·ä½“å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","æ¯”ä¾‹(%)"])

def render_sortable_table(title: str, df: pd.DataFrame, *, order_cols):
    cols=[c for c in order_cols if c in df.columns]
    view=df.loc[:, cols].copy() if cols else df.copy()
    for pct_col in ["é—®é¢˜æ¯”ä¾‹(%)","æ¯”ä¾‹(%)"]:
        if pct_col in view.columns:
            view[pct_col] = view[pct_col].map(lambda x: "" if pd.isna(x) else f"{float(x):.2f}%")
    st.subheader(title)
    st.caption("æç¤ºï¼šç‚¹å‡»åˆ—å¤´å¯æ’åºï¼›å†æ¬¡ç‚¹å‡»åˆ‡æ¢å‡/é™åºï¼›æŒ‰ä½ Shift æ”¯æŒå¤šåˆ—æ’åºã€‚")
    st.dataframe(view, use_container_width=True)

render_sortable_table("å‹ç¼©æœºï¼ˆæŒ‰å‹å·ç³»åˆ—ï¼‰", (t1 if not t1.empty else base1),
    order_cols=("å‹å·ç³»åˆ—","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"))
render_sortable_table("å‹ç¼©æœºï¼ˆæŒ‰å…·ä½“å‹å·ï¼‰", (t2 if not t2.empty else base2),
    order_cols=("å…·ä½“å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","æ¯”ä¾‹(%)"))

# ===== åˆ†é¡¹æ·±å…¥åˆ†æï¼ˆä»…æ•°é‡>0ï¼Œé»˜è®¤åªå±•å¼€ç¬¬ä¸€é¡¹ï¼‰=====
st.markdown("## åˆ†é¡¹æ·±å…¥åˆ†æï¼ˆä»…æ•°é‡>0ï¼‰")

def _clean_join(df_):
    j = df_.astype(str).agg(" ".join, axis=1).str.lower().str.replace("\u3000", " ", regex=False)
    return j.str.replace(r"[\s\-_\/]+", " ", regex=True).str.strip()

def _subset_2145_item(df_src: pd.DataFrame, sub_code: str)->pd.DataFrame:
    if df_src is None or df_src.empty: return df_src.iloc[0:0].copy()
    j=_clean_join(df_src)
    sub = (sub_code or "").strip()
    if not sub or not re.match(r"^2\.1\.4\.5\.[0-9a-z]+$", sub, re.I):
        return df_src.iloc[0:0].copy()
    pat=re.compile(rf"(?<![0-9a-z]){re.escape(sub)}(?![0-9a-z])", re.I)
    return df_src[j.str.contains(pat)].copy()

rows_need = (
    df_2145[
        df_2145["ç¼–ç "].astype(str).str.match(r"^2\.1\.4\.5\.[0-9a-z]+$", na=False) &
        (pd.to_numeric(df_2145["æ•°é‡"], errors="coerce").fillna(0) > 0)
    ]
    .sort_values("æ•°é‡", ascending=False)
    .copy()
)

if rows_need.empty:
    st.info("å½“å‰ 2.1.4.5.x æ²¡æœ‰æ•°é‡>0 çš„æ¡ç›®å¯æ·±å…¥åˆ†æã€‚")
else:
    for idx, r in rows_need.iterrows():
        sub_code = str(r["ç¼–ç "])
        zh_name  = str(r.get("ä¸­æ–‡æè¿°","å‹ç¼©æœºå­é¡¹"))
        sub_df = _subset_2145_item(df_code, sub_code)
        with st.expander(f"ã€{sub_code}ã€‘{zh_name}ï½œè®°å½• {int(r['æ•°é‡'])}ï¼Œè´¹ç”¨ {money(float(r.get('è´¹ç”¨',0)))}",
                         expanded=(idx==rows_need.index[0])):
            a1, a2 = build_tables(sub_df, year=year, month=month_for_fleet)
            _b1 = pd.DataFrame(columns=["å‹å·ç³»åˆ—","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"])
            _b2 = pd.DataFrame(columns=["å…·ä½“å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","æ¯”ä¾‹(%)"])
            render_sortable_table("æŒ‰å‹å·ç³»åˆ—", (a1 if not a1.empty else _b1),
                order_cols=("å‹å·ç³»åˆ—","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","é—®é¢˜æ¯”ä¾‹(%)"))
            render_sortable_table("æŒ‰å…·ä½“å‹å·", (a2 if not a2.empty else _b2),
                order_cols=("å…·ä½“å‹å·","çŸ­æœŸï¼ˆ1-4æœˆï¼‰","ä¸­æœŸï¼ˆ5-8æœˆï¼‰","é•¿æœŸï¼ˆ9-24æœˆï¼‰","æ€»è®¡","åœ¨ä¿é‡","æ¯”ä¾‹(%)"))

# ================= åŸå§‹æ˜ç»†ï¼ˆå‘½ä¸­ 2.1.4.5 çš„è®°å½•ï¼‰ =================
with st.expander("åŸå§‹æ˜ç»†ï¼ˆå‘½ä¸­ 2.1.4.5 çš„è®°å½•ï¼‰", expanded=False):

    def _norm_date_text(raw: pd.Series) -> pd.Series:
        s = raw.astype(str).str.strip()
        out = pd.Series("", index=s.index, dtype="object")

        m8 = s.str.fullmatch(r"\d{8}", na=False)
        if m8.any():
            dt8 = pd.to_datetime(s[m8], format="%Y%m%d", errors="coerce")
            out.loc[m8] = dt8.dt.strftime("%Y-%m-%d")

        m6 = s.str.fullmatch(r"\d{6}", na=False)
        if m6.any():
            s6 = s[m6]
            is_yyyymm = s6.str.match(r"(19|20)\d{2}(0[1-9]|1[0-2])$")
            idx_y4 = s6.index[is_yyyymm.fillna(False)]
            if len(idx_y4) > 0:
                dt_a = pd.to_datetime(s6.loc[idx_y4] + "01", format="%Y%m%d", errors="coerce")
                out.loc[idx_y4] = dt_a.dt.strftime("%Y-%m-%d")
            idx_y2 = s6.index[~is_yyyymm.fillna(False)]
            if len(idx_y2) > 0:
                y = "20" + s6.loc[idx_y2].str.slice(0, 2)
                m = s6.loc[idx_y2].str.slice(2, 4)
                d = s6.loc[idx_y2].str.slice(4, 6)
                dt_b = pd.to_datetime(y + m + d, format="%Y%m%d", errors="coerce")
                out.loc[idx_y2] = dt_b.dt.strftime("%Y-%m-%d")

        rest = (out == "")
        if rest.any():
            dt = pd.to_datetime(s[rest], errors="coerce", infer_datetime_format=True)
            out.loc[rest] = dt.dt.strftime("%Y-%m-%d")

        failed = out.isna() | (out == "NaT") | (out == "")
        if failed.any():
            out.loc[failed] = s.loc[failed]
        return out

    df_view = df_code.copy()

    RAW_PROD_CANDS   = ["ç”Ÿäº§æ—¥æœŸ","ç”Ÿäº§æ—¥","ProductionDate","ProdDate","åˆ¶é€ æ—¥æœŸ","å‡ºå‚æ—¥æœŸ"]
    RAW_SERIAL_CANDS = ["åºåˆ—å·","S/N","SN","Serial No","SerialNo","Serial","åºåˆ—å·SN"]
    DEDUP_KEYS = [
        "å·¥å•å·","ç´¢èµ”å·","CaseNo","TicketNo",
        "S/N","Serial No","SN","Serial","SerialNo",
        "åºåˆ—å·","åºåˆ—å·SN"
    ]

    def _pick_first(df, cands):
        for c in cands:
            if c in df.columns:
                return c
        return None

    raw_hist = _load_raw_excel_store()
    if not raw_hist.empty:
        join_keys = [k for k in DEDUP_KEYS if (k in df_view.columns) and (k in raw_hist.columns)]
        raw_prod_col   = _pick_first(raw_hist, RAW_PROD_CANDS)
        raw_serial_col = _pick_first(raw_hist, RAW_SERIAL_CANDS)

        if join_keys and (raw_prod_col or raw_serial_col):
            take_cols = [k for k in join_keys]
            if raw_prod_col   and raw_prod_col   not in take_cols: take_cols.append(raw_prod_col)
            if raw_serial_col and raw_serial_col not in take_cols: take_cols.append(raw_serial_col)

            patch = raw_hist.loc[:, take_cols].drop_duplicates().copy()

            if raw_prod_col:
                if raw_prod_col in join_keys:
                    patch["åŸå§‹ç”Ÿäº§æ—¥æœŸ"] = _norm_date_text(patch[raw_prod_col])
                else:
                    patch = patch.rename(columns={raw_prod_col: "åŸå§‹ç”Ÿäº§æ—¥æœŸ"})
                    patch["åŸå§‹ç”Ÿäº§æ—¥æœŸ"] = _norm_date_text(patch["åŸå§‹ç”Ÿäº§æ—¥æœŸ"])
            if raw_serial_col:
                if raw_serial_col in join_keys:
                    patch["åŸå§‹åºåˆ—å·"] = patch[raw_serial_col]
                else:
                    patch = patch.rename(columns={raw_serial_col: "åŸå§‹åºåˆ—å·"})

            df_view = df_view.merge(patch, on=join_keys, how="left", suffixes=("", "_rawdup"))
            st.caption("ï¼ˆå·²ä»ğŸ“ åŸå§‹ Excel è¡¨æ˜ å°„ï¼ˆICEï¼‰æŒ‰ %s å…³è”è¡¥å…¥ï¼š%sï¼‰" % (
                ", ".join(join_keys),
                "ã€".join([c for c in ["åŸå§‹ç”Ÿäº§æ—¥æœŸ","åŸå§‹åºåˆ—å·"] if c in df_view.columns]) or "æ— "
            ))
        else:
            st.caption("ï¼ˆåŸå§‹åº“å¯ç”¨ï¼Œä½†æœªæ‰¾åˆ°å…±åŒä¸»é”®æˆ–åŸå§‹â€œç”Ÿäº§æ—¥æœŸ/åºåˆ—å·â€åˆ—ï¼Œæ˜¾ç¤ºç°æœ‰åˆ—ï¼‰")
    else:
        st.caption("ï¼ˆæœªæ‰¾åˆ°ğŸ“ åŸå§‹ Excel è¡¨æ˜ å°„ï¼ˆICEï¼‰ï¼Œæ˜¾ç¤ºç°æœ‰åˆ—ï¼‰")

    if "åŸå§‹ç”Ÿäº§æ—¥æœŸ" not in df_view.columns:
        date_src = next((c for c in ["åŸå§‹ç”Ÿäº§æ—¥æœŸ","ç”Ÿäº§æ—¥æœŸ","ç”Ÿäº§æ—¥","productiondate","proddate","åˆ¶é€ æ—¥æœŸ","å‡ºå‚æ—¥æœŸ","Date"] if c in df_view.columns), None)
        if date_src:
            df_view["åŸå§‹ç”Ÿäº§æ—¥æœŸ"] = _norm_date_text(df_view[date_src])
        else:
            df_view["åŸå§‹ç”Ÿäº§æ—¥æœŸ"] = ""

    SERIAL_CANDS_SHOW = ["åŸå§‹åºåˆ—å·","åºåˆ—å·","S/N","SN","Serial No","SerialNo","Serial","åºåˆ—å·SN"]
    serial_src = next((c for c in SERIAL_CANDS_SHOW if c in df_view.columns), None)
    df_view["åºåˆ—å·"] = df_view[serial_src].astype(str) if serial_src else ""

    base_cols = ["Category1","Category2","TAG1","TAG2","TAG3","TAG4","CostUSD","PaidQty","IsWarranty","Completed"]
    base_cols = [c for c in base_cols if c in df_view.columns]
    show_cols = ["åŸå§‹ç”Ÿäº§æ—¥æœŸ","åºåˆ—å·"] + base_cols
    st.dataframe(df_view.loc[:, show_cols], use_container_width=True)

    st.download_button(
        "ä¸‹è½½ CSVï¼ˆåŸå§‹æ˜ç»†ï¼‰",
        data=df_view.loc[:, show_cols].to_csv(index=False, encoding="utf-8-sig"),
        file_name="ice_compressor_2145_raw_details.csv",
        mime="text/csv",
        use_container_width=True
    )
