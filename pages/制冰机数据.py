# -*- coding: utf-8 -*-
# === åˆ¶å†°æœºæ•°æ®ï¼ˆç©ºæ•°æ®ç‰ˆï¼Œæ¨¡æ¿ä¸å†°ç®±æ•°æ®ä¸€è‡´ï¼›å­˜å‚¨æ–‡ä»¶ç‹¬ç«‹ *_iceï¼Œç¡®ä¿èµ·å§‹å³ä¸ºç©ºï¼‰ ===

import streamlit as st
from auth import require_login, current_user, is_admin, logout_button

# === ä¸´æ—¶å…ç™»å½•ï¼ˆè°ƒè¯•ç”¨ï¼‰==========================================
import os, re, sys, json, hashlib, pathlib
from pathlib import Path
from urllib.parse import quote, unquote
from typing import List

import pandas as pd
import numpy as np
import streamlit.components.v1 as _components
from urllib.parse import quote as _urlquote

def _get_debug_flag_from_url() -> bool:
    try:
        qp = st.query_params
        val = qp.get("debug", "0")
        if isinstance(val, list):
            val = (val[0] if val else "0")
    except Exception:
        try:
            qp = st.experimental_get_query_params()
            val = (qp.get("debug", ["0"]) or ["0"])[0]
        except Exception:
            val = "0"
    return str(val).strip() in {"1", "true", "yes", "on"}

DEBUG_NO_LOGIN = (
    os.getenv("DEBUG_NO_LOGIN", "0").lower() in {"1", "true", "yes", "on"}
    or _get_debug_flag_from_url()
)

if DEBUG_NO_LOGIN:
    def _debug_user():
        return {"username": "debug", "name": "è°ƒè¯•æ¨¡å¼", "role": "admin"}

    require_login = (lambda *a, **k: None)
    current_user  = _debug_user
    is_admin      = (lambda: True)
    logout_button = (lambda *a, **k: None)
    try:
        st.toast("ğŸ”“ å·²å¯ç”¨ã€è°ƒè¯•å…ç™»å½•ã€ï¼Œä¸Šçº¿å‰è¯·å…³é—­ã€‚")
    except Exception:
        pass
# ================================================================

# === BEGIN: å½»åº•ä»ä¾§æ ç§»é™¤â€œåˆ†æ/é…ä»¶åˆ†æ/ICEé…ä»¶é¡µâ€ï¼ˆå…¥å£é¡µå£å¾„ï¼‰ ===
def _get_root_script_path():
    try:
        from streamlit.runtime.scriptrunner import get_script_run_ctx
        ctx = get_script_run_ctx()
        if ctx:
            for attr in ("main_script_path", "script_path"):
                p = getattr(ctx, attr, None)
                if p:
                    return p
    except Exception:
        pass
    return os.path.abspath(sys.argv[0])

def remove_analysis_pages_from_sidebar(*, extra_basenames=(), name_regex=r".*åˆ†æ$"):
    """å¿…é¡»ç”¨å…¥å£è„šæœ¬çš„ get_pages(root) æ‰èƒ½ä»æºå¤´ç§»é™¤ä¾§æ é¡¹"""
    try:
        from streamlit.source_util import get_pages
    except Exception:
        return
    root_script = _get_root_script_path()
    pages = get_pages(root_script) or {}
    if not pages:
        return

    rx = re.compile(name_regex, flags=re.I) if name_regex else None
    need_hide = {
        # â€”â€” æ—§é¡µé¢ï¼ˆå†°ç®±åˆ†æï¼‰
        "é…ä»¶åˆ†æ.py", "peijianfenxi.py",
        "é£æœºåˆ†æ.py", "æ¸©æ§å™¨åˆ†æ.py", "å‹ç¼©æœºåˆ†æ.py",
        "å¤–éƒ¨æ¼æ°´åˆ†æ.py", "æ³„æ°Ÿåˆ†æ.py",

        # â€”â€” ICE ä¸“ç”¨é¡µé¢ï¼ˆä¸­æ–‡æ–‡ä»¶åï¼‰
        "iceæ¸©æ§æ¿.py", "iceå‹ç¼©æœº.py", "iceè°ƒå¼åšå†°.py",
        "iceåŒ–éœœæ¢å¤´.py", "iceæ°´æ³µ.py", "iceæ°´ä½æ¢å¤´.py", "iceè’¸å‘å™¨æŸå.py",

        # â€”â€” ICE ä¸“ç”¨é¡µé¢ï¼ˆè‹±æ–‡æˆ–é©¼å³°ï¼‰
        "ice_controlboard.py", "ice_compressor.py", "ice_icethicknessdebug.py",
        "ice_harvestprobe.py", "ice_waterpump.py", "ice_waterlevelprobe.py", "ice_evaporator.py",
        "ICE_ControlBoard.py", "ICE_Compressor.py", "ICE_IceThicknessDebug.py",
        "ICE_HarvestProbe.py", "ICE_WaterPump.py", "ICE_WaterLevelProbe.py", "ICE_Evaporator.py",
        "ICEæ¸©æ§æ¿.py", "ICEå‹ç¼©æœº.py", "ICEè°ƒå¼åšå†°.py",
        "ICEåŒ–éœœæ¢å¤´.py", "ICEæ°´æ³µ.py", "ICEæ°´ä½æ¢å¤´.py", "ICEè’¸å‘å™¨æŸå.py",
    }
    need_hide |= {str(x).strip().lower() for x in extra_basenames if str(x).strip()}

    for k, d in list(pages.items()):
        page_name = str(d.get("page_name", "")).strip()
        base = os.path.basename(str(d.get("script_path", "")).replace("\\", "/")).lower()
        if base in need_hide or (rx and rx.fullmatch(page_name)):
            pages.pop(k, None)

# â€”â€” ç«‹åˆ»è°ƒç”¨ï¼ˆå¿…é¡»åœ¨ä»»ä½• set_page_config ä¹‹å‰ï¼‰
remove_analysis_pages_from_sidebar(
    extra_basenames=(
        "é…ä»¶åˆ†æ.py", "peijianfenxi.py",
        "é£æœºåˆ†æ.py", "æ¸©æ§å™¨åˆ†æ.py", "å‹ç¼©æœºåˆ†æ.py",
        "å¤–éƒ¨æ¼æ°´åˆ†æ.py", "æ³„æ°Ÿåˆ†æ.py",
        "ICEæ¸©æ§æ¿.py", "ICEå‹ç¼©æœº.py", "ICEè°ƒå¼åšå†°.py",
        "ICEåŒ–éœœæ¢å¤´.py", "ICEæ°´æ³µ.py", "ICEæ°´ä½æ¢å¤´.py", "ICEè’¸å‘å™¨æŸå.py",
        "ICE_ControlBoard.py", "ICE_Compressor.py", "ICE_IceThicknessDebug.py",
        "ICE_HarvestProbe.py", "ICE_WaterPump.py", "ICE_WaterLevelProbe.py", "ICE_Evaporator.py",
    ),
    name_regex=r".*åˆ†æ$",
)
# === END ===

# ============== é¡µé¢é…ç½®ï¼ˆæ”¹åä¸ºâ€œåˆ¶å†°æœºæ•°æ®â€ï¼‰ ==============
st.set_page_config(page_title="åˆ¶å†°æœºæ•°æ®", layout="wide", initial_sidebar_state="expanded")
st.title("åˆ¶å†°æœºæ•°æ®")
require_login()

# ============== è·³è½¬è¾…åŠ©ï¼ˆå…¥å£é¡µå£å¾„ï¼Œä¿®å¤ __file__ é—®é¢˜ï¼‰ ==============
def _find_page_url(target_tail: str):
    """ç”¨å…¥å£è„šæœ¬é¡µè¡¨æŸ¥ç›®æ ‡æ–‡ä»¶å¯¹åº”çš„ URLï¼›æ‰¾ä¸åˆ°å°±è¿”å› None"""
    try:
        from streamlit.source_util import get_pages
    except Exception:
        return None
    try:
        pages = get_pages(_get_root_script_path()) or {}
        target_tail_norm = re.sub(r"[\\/]+", "/", str(target_tail)).lower()
        for _, data in pages.items():
            sp = data.get("script_path", "")
            sp_norm = re.sub(r"[\\/]+", "/", str(sp)).lower()
            if sp_norm.endswith(target_tail_norm) or os.path.basename(sp_norm) == os.path.basename(target_tail_norm):
                url = data.get("url_pathname")
                if url:
                    return url
                page_name = data.get("page_name")
                if page_name:
                    return "/" + str(page_name)
        return None
    except Exception:
        return None

# â€”â€” è´¨é‡ç¼ºé™·ç¼–ç  â†’ å­é¡µæ–‡ä»¶åï¼ˆåŒæ—¶å…¼å®¹ä¸­è‹±æ–‡æ–‡ä»¶åï¼‰
_FORCE_CODE2PAGE = {
    "2.1.4.7":  "ICEæ¸©æ§æ¿.py",
    "2.1.4.5":  "ICEå‹ç¼©æœº.py",
    "2.1.5.1":  "ICEè°ƒå¼åšå†°.py",
    "2.1.4.8":  "ICEåŒ–éœœæ¢å¤´.py",
    "2.1.4.4":  "ICEæ°´æ³µ.py",
    "2.1.4.9":  "ICEæ°´ä½æ¢å¤´.py",
    "2.1.4.17": "ICEè’¸å‘å™¨æŸå.py",
    # å¯é€‰è‹±æ–‡åŒ–ï¼ˆè‹¥ä½ çš„æ–‡ä»¶åæ”¹æˆè‹±æ–‡ï¼‰
    # "2.1.4.7":  "ICE_ControlBoard.py",
    # ...
}

def _guess_url_from_filename(target: str) -> str:
    base = os.path.splitext(os.path.basename(str(target)))[0]
    base = re.sub(r"^\d+[_\-\s]*", "", base)
    return f"/{base}"

def page_url_by_code(caller_file: str, code: str) -> str:
    key = str(code or "").strip()
    target = _FORCE_CODE2PAGE.get(key)
    if not target:
        return None
    url = _find_page_url(target)
    if url:
        return url
    return _guess_url_from_filename(target)

def hide_analysis_pages_in_sidebar(caller_file: str, *, debug=False):
    ALLOW_NAMES = {"åˆ¶å†°æœºæ•°æ®"}  # å…è®¸â€œåˆ¶å†°æœºæ•°æ®â€åœ¨ä¾§æ æ˜¾ç¤º
    HIDE_NAME_PATTERNS = [
        r"åˆ†æ$", r"åˆ†æé¡µé¢", r"é…ä»¶åˆ†æ",
        r"é£æœºåˆ†æ", r"æ¸©æ§å™¨åˆ†æ", r"å‹ç¼©æœºåˆ†æ",
        r"å¤–éƒ¨æ¼æ°´åˆ†æ", r"æ³„æ°Ÿåˆ†æ",
        r"analysis$"
    ]
    HIDE_URL_TAILS = [
        # â€”â€” æ—§åˆ†æé¡µ
        "/é…ä»¶åˆ†æ", "/é£æœºåˆ†æ", "/æ¸©æ§å™¨åˆ†æ", "/å‹ç¼©æœºåˆ†æ", "/å¤–éƒ¨æ¼æ°´åˆ†æ", "/æ³„æ°Ÿåˆ†æ",
        "/peijianfenxi", "/fengjifenxi", "/wenkongqifenxi", "/yasuoji", "/waibuloushui", "/xiefen",
        # â€”â€” ICE ä¸“ç”¨é¡µé¢ï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰
        "/ICEæ¸©æ§æ¿", "/ICEå‹ç¼©æœº", "/ICEè°ƒå¼åšå†°",
        "/ICEåŒ–éœœæ¢å¤´", "/ICEæ°´æ³µ", "/ICEæ°´ä½æ¢å¤´", "/ICEè’¸å‘å™¨æŸå",
        "/ICE_ControlBoard", "/ICE_Compressor", "/ICE_IceThicknessDebug",
        "/ICE_HarvestProbe", "/ICE_WaterPump", "/ICE_WaterLevelProbe", "/ICE_Evaporator",
    ]
    enc_tails = []
    for t in HIDE_URL_TAILS:
        enc = "/".join(_urlquote(p, safe="") for p in t.split("/"))
        enc_tails.extend({t, enc, t+"/", enc+"/"})
    HREFS = list(sorted(set(enc_tails)))
    payload = {"allow_names": sorted(ALLOW_NAMES), "name_regexes": HIDE_NAME_PATTERNS, "href_tails": HREFS, "debug": bool(debug)}
    js = f"""
    <script>
    (function() {{
      const CONF = { json.dumps(payload, ensure_ascii=False) };
      const allow = new Set(CONF.allow_names || []);
      const nameRes = (CONF.name_regexes || []).map(p => new RegExp(p));
      const hrefTails = new Set(CONF.href_tails || []);
      function normPath(href) {{
        try {{ return new URL(href, window.location.origin).pathname || ""; }}
        catch {{ return href || ""; }}
      }}
      function shouldHideByText(txt) {{
        if (!txt) return false;
        const t = txt.trim();
        if (allow.has(t)) return false;
        return nameRes.some(r => r.test(t));
      }}
      function shouldHideByHref(href) {{
        if (!href) return false;
        const p = normPath(href);
        for (const tail of hrefTails) {{
          if (!tail) continue;
          if (p.endsWith(tail) || p.includes(tail + "/") || p.includes(tail + "?")) return true;
        }}
        return false;
      }}
      function kill(el) {{ if (!el) return; el.style.setProperty('display','none','important'); el.setAttribute('data-hidden-by','bf-hide'); }}
      function scan(root) {{
        const sidebar = document.querySelector('aside[data-testid="stSidebar"]')
                      || document.querySelector('section[data-testid="stSidebar"]')
                      || document.querySelector('[data-testid="stSidebar"]')
                      || document.querySelector('nav[aria-label="Sidebar navigation"]')
                      || (root || document);
        if (!sidebar) return;
        sidebar.querySelectorAll('a[href]').forEach(a => {{
          const href = a.getAttribute('href') || '';
          const txt  = (a.textContent || '').trim();
          if (shouldHideByText(txt) || shouldHideByHref(href)) {{
            const li = a.closest('li') || a.parentElement; kill(li || a);
          }}
        }});
        sidebar.querySelectorAll('*:not(a)').forEach(el => {{
          const txt = (el.textContent || '').trim();
          if (shouldHideByText(txt)) {{
            const li = el.closest('li') || el.closest('[data-testid="stSidebarNav"]') || el.parentElement;
            kill(li || el);
          }}
        }});
      }}
      let tick = 0;
      const timer = setInterval(() => {{ scan(document); tick++; if (tick > 60) clearInterval(timer); }}, 300);
      scan(document);
      const mo = new MutationObserver(() => scan(document));
      mo.observe(document.body, {{ childList: true, subtree: true }});
      if (CONF.debug) console.log('[bf-hide:ready]', CONF);
    }})();
    </script>
    """
    _components.html(js, height=0)

hide_analysis_pages_in_sidebar(__file__, debug=False)

# ============== å¸¸é‡/é…ç½®ï¼ˆåˆ¶å†°æœºï¼‰ ==============
# â€”â€” è´¨é‡æ˜ç»†å›ºå®šæ¸…å•ï¼ˆæŒ‰ä½ ç»™çš„è¡¨é€æ¡å¯¹åº”ï¼‰
FIXED_DEFECTS = [
    {"code": "2.1.4.7",  "en": "Control bord",                           "cn": "æ¸©æ§æ¿"},
    {"code": "2.1.5.1",  "en": "Debug",                                   "cn": "è°ƒè¯•å†°åš"},
    {"code": "2.1.8.1",  "en": "Door Hinge Broken",                       "cn": "ç‰©ç†-é—¨è½´æ–­è£‚"},
    {"code": "2.1.4.4",  "en": "Water Pump",                              "cn": "æ°´æ³µ"},
    {"code": "2.1.4.1",  "en": "Leaking Refrigerant",                     "cn": "åˆ¶å†·å‰‚æ³„æ¼"},
    {"code": "2.1.4.9",  "en": "Water probe",                             "cn": "æ°´ä½æ¢å¤´"},
    {"code": "2.1.4.2",  "en": "Inlet Water Valve",                       "cn": "è¿›æ°´é˜€"},
    {"code": "2.1.4.8",  "en": "Harvest Probe",                           "cn": "åŒ–éœœæ¢å¤´"},
    {"code": "2.1.8.8",  "en": "Water Curtain Hinge Broken",              "cn": "æ°´å¸˜æ¿"},
    {"code": "2.1.4.5",  "en": "Compressor",                              "cn": "å‹ç¼©æœº"},
    {"code": "2.1.4.17", "en": "evaporator",                              "cn": "ç‰©ç†-è’¸å‘å™¨æŸå"},
    {"code": "2.1.9.1",  "en": "Leaking water form bin bottom",           "cn": "æ°´ç®±åº•éƒ¨æ¼æ°´"},
    {"code": "2.1.9.4",  "en": "The drain is clogged",                    "cn": "æ’æ°´ç®¡å µä½"},
    {"code": "2.1.8.5",  "en": "Water Trough",                            "cn": "ç‰©ç†-æ°´æ§½æŸå"},
    {"code": "2.1.6.1",  "en": "Fan Motor working with noise",            "cn": "é£æœºå™ªéŸ³"},
    {"code": "2.1.4.18", "en": "Drain Valve",                             "cn": "æ’æ°´é˜€"},
    {"code": "2.1.4.11", "en": "Loose wiring harness connection",         "cn": "ä¸åˆ¶å†·-çº¿æŸæ¾åŠ¨"},
    {"code": "2.1.4.16", "en": "Water Curtain stuck by ice",              "cn": "æ°´å¸˜æ¿"},
    {"code": "2.1.9.3",  "en": "Water leakage at the hose connection",    "cn": "æ¥æ°´ç®¡è¿æ¥å¤„æ¼æ°´"},
    {"code": "2.1.8.3",  "en": "Ice Harvest Probe",                       "cn": "ç‰©ç†æŸå-æ¢å¤´"},
    {"code": "2.1.9.2",  "en": "Leaking water in the front",              "cn": "å‰é¢æ¼æ°´"},
    {"code": "2.1.8.6",  "en": "Thumb Screw falls off",                   "cn": "æ°´æ§½èºä¸è„±è½"},
    {"code": "2.1.4.18", "en": "Solenoid valve",                          "cn": "ç”µç£é˜€"},
    {"code": "2.1.4.17", "en": "Water Curtain sensor",                    "cn": "é—¨ç£å¼€å…³"},
    {"code": "2.1.6.3",  "en": "Loose screws/hit something",              "cn": "èºä¸æ¾åŠ¨/æ‰“åˆ°å¼‚ç‰©"},
    {"code": "2.1.4.15", "en": "condenser fan",                           "cn": "å†·å‡é£æœº"},
    {"code": "2.1.6.2",  "en": "Water pump working with noise",           "cn": "ç»ç’ƒé—¨ç»ç’ƒä¹‹é—´å‡éœ²/èµ·é›¾"},
]

# æ³¨æ„ï¼šä¸Šé¢ç§»é™¤äº†ä½ åŸå…ˆé‡å¤çš„ 2.1.4.17ï¼ˆé¿å…ä¸è’¸å‘å™¨é‡å¤ï¼‰

# â€”â€” å‹å·ç³»åˆ—ç»´åº¦ï¼ˆæŒ‰åœ¨ä¿æ•°é‡å£å¾„ï¼‰
ICE_MODEL_CATEGORY_MAP = {
    "YR140":  "åˆ¶å†°æœº-140",
    "YR280":  "åˆ¶å†°æœº-280",
    "YR450":  "åˆ¶å†°æœº-450",
    "YR800":  "åˆ¶å†°æœº-800",
    "CYR400": "å†°æ¡¶-400",
    "CYR700": "å†°æ¡¶-700",
    "HD350":  "åˆ¶å†°æœº-350",
}
ICE_MODEL_ORDER = ["åˆè®¡", "YR140","YR280","YR450","YR800","CYR400","CYR700","HD350"]
ALIASES = {

    "Ice Machine-140": "YR140",
    "Ice Machine-280": "YR280",
    "Ice Machine-450": "YR450",
    "Ice Machine-800": "YR800",
    "Ice Machine-350": "HD350",
    "Ice machine-CYR400P": "CYR400",
    "Ice machine-CYR700P": "CYR700",
}

YEARS_FIXED = list(range(2025, 2031))

# â€”â€” æŒä¹…åŒ–æ–‡ä»¶åå…¨éƒ¨ç‹¬ç«‹ *_ice
STORE_PARQUET = Path("data_store_ice.parquet")
STORE_CSV     = Path("data_store_ice.csv")
TARGETS_JSON  = Path("targets_config_ice.json")
MODEL_FLEET_JSON  = Path("model_fleet_counts_ice.json")
RAW_EXCEL_STORE = Path("raw_excel_store_ice.parquet")

# ============== æ•°æ®/æ–‡ä»¶å­˜å– ==============
def _load_raw_excel_store() -> pd.DataFrame:
    if RAW_EXCEL_STORE.exists():
        try:
            return pd.read_parquet(RAW_EXCEL_STORE)
        except Exception:
            try:
                return pd.read_csv(RAW_EXCEL_STORE.with_suffix(".csv"), dtype=str)
            except Exception:
                pass
    return pd.DataFrame()

def _save_raw_excel_store(df: pd.DataFrame):
    try:
        df.to_parquet(RAW_EXCEL_STORE, index=False)
    except Exception:
        df.to_csv(RAW_EXCEL_STORE.with_suffix(".csv"), index=False, encoding="utf-8-sig")

def _clear_raw_excel_history():
    """æ¸…ç©ºåŸå§‹ Excel ä¸Šä¼ å†å²ï¼ˆå†…å­˜ + ç£ç›˜æ–‡ä»¶ï¼‰"""
    st.session_state["excel_raw_history"] = pd.DataFrame()
    try: RAW_EXCEL_STORE.unlink(missing_ok=True)
    except Exception: pass
    try: RAW_EXCEL_STORE.with_suffix(".csv").unlink(missing_ok=True)
    except Exception: pass

def load_store_df()->pd.DataFrame:
    if STORE_PARQUET.exists():
        try: return pd.read_parquet(STORE_PARQUET)
        except Exception: pass
    if STORE_CSV.exists():
        try: return pd.read_csv(STORE_CSV)
        except Exception: pass
    return pd.DataFrame()

def save_store_df(df: pd.DataFrame):
    try: df.to_parquet(STORE_PARQUET, index=False)
    except Exception: df.to_csv(STORE_CSV, index=False, encoding="utf-8-sig")

def load_targets()->dict:
    if TARGETS_JSON.exists():
        try: return json.loads(TARGETS_JSON.read_text(encoding="utf-8"))
        except Exception: pass
    return {"target_year_rate":5.0,"q1_t":0.0,"q2_t":0.0,"q3_t":0.0,"q4_t":0.0,"year_t":5.0}

def save_targets(cfg: dict):
    try: TARGETS_JSON.write_text(json.dumps(cfg, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception: pass

def load_model_fleet()->dict:
    if MODEL_FLEET_JSON.exists():
        try: return json.loads(MODEL_FLEET_JSON.read_text(encoding="utf-8"))
        except Exception: pass
    return {}

def save_model_fleet(d: dict):
    try: MODEL_FLEET_JSON.write_text(json.dumps(d, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception: pass

def ensure_fleet_month(fleet: dict, year: int, month: int)->dict:
    y, m = str(year), str(month)
    fleet.setdefault(y, {})
    fleet[y].setdefault(m, {k:0 for k in ICE_MODEL_ORDER if k!="åˆè®¡"})
    return fleet

def get_fleet_month(fleet: dict, year: int, month: int)->dict:
    y, m = str(year), str(month)
    return {k:int(fleet.get(y,{}).get(m,{}).get(k,0)) for k in ICE_MODEL_ORDER if k!="åˆè®¡"}

def set_fleet_month(fleet: dict, year: int, month: int, updates: dict)->dict:
    fleet = ensure_fleet_month(fleet, year, month)
    y, m = str(year), str(month)
    for mdl, v in updates.items():
        if mdl in ICE_MODEL_CATEGORY_MAP:
            fleet[y][m][mdl] = int(max(0, v))
    return fleet

# ============== å­—æ®µ/è§£æè¾…åŠ© ==============
CATEGORY_SCHEMA = {
    "è´¨é‡é—®é¢˜": ["Atosa"],
    "éè´¨é‡é—®é¢˜": ["åˆè®¡","å®‰è£…/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","æ²¡å®‰è£…å‡€æ°´å™¨/ä½¿ç”¨é”™è¯¯","ç»´ä¿®å·¥æœªå‘ç°é—®é¢˜","å®¢æˆ·ä»˜é’±","è„å µ/æ’æ°´ç®¡å µ"],
    "å‡ºä¿": ["åªå¯„é…ä»¶"],
    "å¾…å®š": ["æœªæ”¶åˆ°è´¦å•/å…¶ä»–äººä»˜æ¬¾"]
}
KEYWORD_RULES = [
    {"patterns":[r"2\.1\.a"],"cat1":"è´¨é‡é—®é¢˜","cat2":"Atosa","paidqty":1,"iswarranty":True},
    {"patterns":[r"\batosa\b"],"cat1":"è´¨é‡é—®é¢˜","cat2":"Atosa","paidqty":1,"iswarranty":True},
    {"patterns":[r"(?<!\d)2\.2(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"å®‰è£…/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.4\.3(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"å®‰è£…/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.4\.2(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"å®‰è£…/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.4\.5(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"æ²¡å®‰è£…å‡€æ°´å™¨/ä½¿ç”¨é”™è¯¯","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.4\.8(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"æ²¡å®‰è£…å‡€æ°´å™¨/ä½¿ç”¨é”™è¯¯","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.4\.11(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"æ²¡å®‰è£…å‡€æ°´å™¨/ä½¿ç”¨é”™è¯¯","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.4\.7(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"ç»´ä¿®å·¥æœªå‘ç°é—®é¢˜","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.4\.9(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"å®¢æˆ·ä»˜é’±","paidqty":0,"iswarranty":False},
    # å…è®¸è‹±æ–‡æè¿°å‘½ä¸­ä»“åº“ç»´ä¿®ç±»ï¼ˆç§»é™¤ä½ åŸå…ˆé‚£æ¡å‰ç¼€â€œ1â€çš„è¯¯å†™ï¼‰
    {"patterns":[r"repair(?:ing)?\s+in\s+(?:the\s+)?warehouse(?:s)?\.?"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"è„å µ/æ’æ°´ç®¡å µ","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.4\.4(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"è„å µ/æ’æ°´ç®¡å µ","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.4\.6(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"è„å µ/æ’æ°´ç®¡å µ","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.3(?!\d)"],"cat1":"å‡ºä¿","cat2":"åªå¯„é…ä»¶","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)2\.5(?!\d)"],"cat1":"å¾…å®š","cat2":"æœªæ”¶åˆ°è´¦å•/å…¶ä»–äººä»˜æ¬¾","paidqty":0,"iswarranty":False},
]
TEXT_COLUMNS_FOR_MATCH = [
    "TAG1","TAG2","TAG3","TAG4","Category1","Category2",
    "é—®é¢˜æè¿°","æè¿°","åŸå› ","å¤‡æ³¨","çŠ¶æ€","æ ‡é¢˜","Summary","Notes",
    "ç¼–ç ","Code","DefectCode","é—®é¢˜","Problem"
]

def fmt_money(x):
    try: return f"${x:,.0f}"
    except Exception: return "$0"

def _clean_text(s: str)->str:
    s = ("" if pd.isna(s) else str(s)).lower().replace("\u3000", " ")
    s = re.sub(r"[\s\-_\/]+", " ", s)
    return s.strip()

_MMYYYY_ANY = re.compile(r'(?:^|\D)(?P<mm>0[1-9]|1[0-2])(?P<yyyy>20\d{2})(?:\D|$)')

def _extract_year_month(df: pd.DataFrame, date_col_name: str=None):
    if df.empty: return
    if date_col_name is None or date_col_name not in df.columns:
        date_col_name = df.columns[0]
    s = df[date_col_name].astype(str)
    m = s.str.extract(_MMYYYY_ANY)
    mm = pd.to_numeric(m["mm"], errors="coerce").astype("Int64")
    yy = pd.to_numeric(m["yyyy"], errors="coerce").astype("Int64")
    mm = mm.where((mm>=1)&(mm<=12), pd.NA)
    df["_SrcYM"] = (m["mm"].fillna("") + m["yyyy"].fillna("")).where(m["mm"].notna(), "")
    df["Year"] = yy
    df["Month"]= mm
    df["Date"] = pd.to_datetime(dict(year=yy.astype("float"), month=mm.astype("float"), day=1), errors="coerce")
    q = pd.Series(pd.NA, index=df.index, dtype="Int64")
    ok = df["Month"].notna()
    q.loc[ok] = ((df.loc[ok,"Month"].astype(int)-1)//3+1).astype("Int64")
    df["Quarter"]= q

def ensure_cols(df: pd.DataFrame, date_col_name: str=None)->pd.DataFrame:
    if df.empty:
        return pd.DataFrame(columns=["Date","Category1","Category2","TAG1","TAG2","TAG3","TAG4","CostUSD","PaidQty","IsWarranty","Completed","Year","Month","Quarter","_SrcYM"])
    mapping = {}
    for c in df.columns:
        lc = str(c).strip().lower()
        if lc in ["æ—¥æœŸ","date","created_at","å‘ç”Ÿæ—¥æœŸ","ç”Ÿäº§æ—¥æœŸ"]: mapping[c] = "Date"
        elif lc in ["åˆ†ç±»1","category1","å¤§ç±»"]: mapping[c] = "Category1"
        elif lc in ["åˆ†ç±»2","category2","å°ç±»"]: mapping[c] = "Category2"
        elif lc in ["tag1","tag 1","tag-1"]: mapping[c] = "TAG1"
        elif lc in ["tag2","tag 2","tag-2"]: mapping[c] = "TAG2"
        elif lc in ["tag3","tag 3","tag-3"]: mapping[c] = "TAG3"
        elif lc in ["tag4","tag 4","tag-4"]: mapping[c] = "TAG4"
        elif lc in ["cost","costusd","amount","amount_usd","è´¹ç”¨","é‡‘é¢","fee","cost(usd)","cost usd"]: mapping[c] = "CostUSD"
        elif lc in ["å·²ä»˜æ¬¾æ•°é‡","paidqty","paid_qty"]: mapping[c] = "PaidQty"
        elif lc in ["æ˜¯å¦æ‰¿ä¿","iswarranty","warranty"]: mapping[c] = "IsWarranty"
        elif lc in ["æ˜¯å¦å®Œæˆ","completed","iscompleted","ç»´ä¿®çŠ¶æ€","çŠ¶æ€"]: mapping[c] = "Completed"
    if mapping: df = df.rename(columns=mapping)
    if df.columns.duplicated().any():
       df = df.loc[:, ~df.columns.duplicated(keep="first")]
    for i in range(1,4+1):
        std = f"TAG{i}"
        if std not in df.columns:
            cand = [c for c in df.columns if re.fullmatch(rf"\s*tag[\s_-]*{i}\s*", str(c), flags=re.I)]
            if cand: df.rename(columns={cand[0]: std}, inplace=True)
    for col, default in [("Category1",""),("Category2",""),("TAG1",""),("TAG2",""),("TAG3",""),("TAG4",""),("CostUSD",0.0),("PaidQty",0),("IsWarranty",False),("Completed",False)]:
        if col not in df.columns: df[col] = default
    df["CostUSD"] = pd.to_numeric(df["CostUSD"], errors="coerce").fillna(0.0)
    df["PaidQty"] = pd.to_numeric(df["PaidQty"], errors="coerce").fillna(0).astype(int)
    if df["Completed"].dtype == object:
        df["Completed"] = df["Completed"].astype(str).str.contains(r"complete|å·²å®Œæˆ|1", case=False, na=False)
    else:
        df["Completed"] = df["Completed"].astype(bool)
    df["IsWarranty"] = df["IsWarranty"].astype(bool)
    need_parse = ("Year" not in df.columns) or ("Month" not in df.columns) or (pd.isna(pd.to_numeric(df.get("Year"), errors="coerce")).all()) or (pd.isna(pd.to_numeric(df.get("Month"), errors="coerce")).all())
    if need_parse: _extract_year_month(df, date_col_name)
    df = apply_keyword_overrides(df)
    return df

def apply_keyword_overrides(df: pd.DataFrame)->pd.DataFrame:
    if df.empty: return df
    joined_all = df.astype(str).agg(" ".join, axis=1).map(_clean_text)
    assigned = pd.Series(False, index=df.index)
    for rule in KEYWORD_RULES:
        pats = [re.compile(p, re.I) for p in rule["patterns"]]
        mask = ~assigned
        for p in pats: mask &= joined_all.str.contains(p)
        if mask.any():
            df.loc[mask,"Category1"] = rule["cat1"]
            df.loc[mask,"Category2"] = rule["cat2"]
            if "paidqty" in rule: df.loc[mask,"PaidQty"] = int(rule["paidqty"])
            if "iswarranty" in rule: df.loc[mask,"IsWarranty"] = bool(rule["iswarranty"])
            assigned |= mask
    return df

def compute_category_stats(df_year: pd.DataFrame):
    stats = {}
    if not df_year.empty:
        tmp = df_year.copy()
        tmp["_paid_flag"] = (pd.to_numeric(tmp["CostUSD"], errors="coerce").fillna(0)>0).astype(int)
        g = tmp.groupby(["Category1","Category2"], dropna=False).agg(æ•°é‡=("CostUSD","size"),è´¹ç”¨=("CostUSD","sum"),å·²ä»˜æ¬¾æ•°é‡=("_paid_flag","sum"))
        g["å¹³å‡è´¹ç”¨"] = g.apply(lambda r: (r["è´¹ç”¨"]/r["å·²ä»˜æ¬¾æ•°é‡"]) if r["å·²ä»˜æ¬¾æ•°é‡"]>0 else 0.0, axis=1)
        for (c1,c2), r in g.iterrows():
            stats[(str(c1),str(c2))] = (int(r["æ•°é‡"]), float(r["è´¹ç”¨"]), int(r["å·²ä»˜æ¬¾æ•°é‡"]), float(r["å¹³å‡è´¹ç”¨"]))
    _nonq = ["å®‰è£…/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","æ²¡å®‰è£…å‡€æ°´å™¨/ä½¿ç”¨é”™è¯¯","ç»´ä¿®å·¥æœªå‘ç°é—®é¢˜","è„å µ/æ’æ°´ç®¡å µ"]
    _big = "éè´¨é‡é—®é¢˜"; _q=_f=_p=0
    for s in _nonq:
        q,f,p,_ = stats.get((_big,s),(0,0.0,0,0.0))
        _q+=q; _f+=f; _p+=p
    _avg = (_f/_p) if _p>0 else 0.0
    stats[(_big,"åˆè®¡")] = (_q,_f,_p,_avg)
    for big, subs in CATEGORY_SCHEMA.items():
        for sub in subs:
            stats.setdefault((big,sub),(0,0.0,0,0.0))
    return stats

def render_category_table_html(stats: dict)->str:
    if not isinstance(stats, dict):
        stats = {}
    for big, subs in CATEGORY_SCHEMA.items():
        for sub in subs:
            stats.setdefault((big, sub), (0, 0.0, 0, 0.0))
    BG, HEAD_BG = "#0b1534", "#0a1a55"
    ROW_ALT, TEXT, SUBTEXT = "rgba(255,255,255,.03)", "#e8edf7", "#c8d0e8"
    BORDER, BORDER_SOFT, HILITE_BG = "rgba(255,255,255,.14)", "rgba(255,255,255,.10)", "rgba(255,255,255,.05)"
    th = """
    <thead><tr>
      <th style="text-align:left;">åˆ†ç±»1</th>
      <th style="text-align:left;">åˆ†ç±»2</th>
      <th style="text-align:right;">æ•°é‡</th>
      <th style="text-align:right;">è´¹ç”¨</th>
      <th style="text-align:right;">å·²ä»˜æ¬¾æ•°é‡</th>
      <th style="text-align:right;">å¹³å‡è´¹ç”¨</th>
    </tr></thead>"""
    rows_html = []
    for big, subs in CATEGORY_SCHEMA.items():
        rowspan = len(subs); first = True
        for sub in subs:
            qty, fee, paid, avg = stats.get((big, sub), (0, 0.0, 0, 0.0))
            tr = "<tr>"
            if first:
                tr += f'<td rowspan="{rowspan}" class="td-big"><b>{big}</b></td>'
                first = False
            if (big == "éè´¨é‡é—®é¢˜" and sub == "åˆè®¡"):
                tr += (
                    f'<td class="td-strong">{sub}</td>'
                    f'<td class="td-num td-strong">{qty}</td>'
                    f'<td class="td-num td-strong">{fmt_money(fee)}</td>'
                    f'<td class="td-num td-strong">{paid}</td>'
                    f'<td class="td-num td-strong">{fmt_money(avg)}</td>'
                )
            else:
                tr += (
                    f"<td>{sub}</td>"
                    f'<td class="td-num">{qty}</td>'
                    f'<td class="td-num">{fmt_money(fee)}</td>'
                    f'<td class="td-num">{paid}</td>'
                    f'<td class="td-num">{fmt_money(avg)}</td>'
                )
            tr += "</tr>"
            rows_html.append(tr)
    styles = f"""
    <style>
      .tbl-wrap {{ background:{BG}; border:1px solid {BORDER}; border-radius:14px; overflow:hidden; box-shadow: 0 4px 14px rgba(0,0,0,.3); }}
      table.tbl {{ width:100%; border-collapse:separate; border-spacing:0; font-size:14px; color:{TEXT}; }}
      .tbl thead th {{ background:{HEAD_BG}; color:{TEXT}; padding:10px 12px; border-bottom:1px solid {BORDER}; font-weight:700; white-space:nowrap; }}
      .tbl tbody td {{ padding:9px 12px; border-bottom:1px solid {BORDER_SOFT}; color:{SUBTEXT}; background:transparent; }}
      .tbl tbody tr:nth-child(even) td {{ background:{ROW_ALT}; }}
      .tbl .td-num {{ text-align:right; color:{TEXT}; }}
      .tbl .td-big {{ vertical-align:top; border-right:1px solid {BORDER}; color:{TEXT}; background:rgba(255,255,255,.02); min-width:120px; }}
      .tbl .td-strong {{ color:{TEXT}; background:{HILITE_BG}; font-weight:700; }}
    </style>
    """
    html = f"""{styles}<div class="tbl-wrap"><table class="tbl">{th}<tbody>{''.join(rows_html)}</tbody></table></div>"""
    return html

def build_monthly_numeric(df_year: pd.DataFrame, fleet_all: dict, current_year: int)->pd.DataFrame:
    months = range(1, 12+1)
    joined_year = (pd.Series(dtype=str) if df_year.empty else
                   df_year.astype(str).agg(" ".join, axis=1).map(_clean_text))

    rows = {
        "æœˆåº¦ç»´ä¿®é‡": [],
        "æœˆåº¦è´¨é‡ç»´ä¿®é‡": [],
        "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰": [],
        "æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰": [],
        "æœˆåº¦ä¿å†…æ•°é‡": [],
        "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%": [],
        "æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰": [],
        "æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰": [],
    }

    pat_21a  = re.compile(r"(?<![0-9a-z])2\.1\.a(?![0-9a-z])", re.I)
    pat_213x = re.compile(r"(?<![0-9a-z])2\.1\.3\.\d+(?![0-9a-z])", re.I)

    for m in months:
        if df_year.empty:
            total = 0
            quality_cnt = 0
            fees4 = 0.0
            paid4 = 0
        else:
            dfm = df_year[df_year["Month"] == m]
            total = len(dfm)
            if total > 0:
                cat_quality = dfm["Category1"].astype(str).eq("è´¨é‡é—®é¢˜")
                text_block  = joined_year.loc[dfm.index]
                text_hits   = text_block.str.contains(pat_21a, na=False) | text_block.str.contains(pat_213x, na=False)
                quality_cnt = int((cat_quality | text_hits).sum())
            else:
                quality_cnt = 0

            stats_m = compute_category_stats(dfm)
            def _pick(c1, c2):
                return stats_m.get((c1, c2), (0, 0.0, 0, 0.0))
            _, fee_atosa,      paid_atosa,      _ = _pick("è´¨é‡é—®é¢˜", "Atosa")
            _, fee_nonq_sum,   paid_nonq_sum,   _ = _pick("éè´¨é‡é—®é¢˜", "åˆè®¡")
            _, fee_out,        paid_out,        _ = _pick("å‡ºä¿", "åªå¯„é…ä»¶")
            _, fee_pending,    paid_pending,    _ = _pick("å¾…å®š", "æœªæ”¶åˆ°è´¦å•/å…¶ä»–äººä»˜æ¬¾")

            fees4 = float(fee_atosa + fee_nonq_sum + fee_out + fee_pending)
            paid4 = int(paid_atosa + paid_nonq_sum + paid_out + paid_pending)

        avg_cost = (fees4 / paid4) if paid4 > 0 else 0.0
        month_fleet = get_fleet_month(fleet_all, int(current_year), int(m))
        warranty_cnt = int(sum(month_fleet.values()))
        est_cost = avg_cost * quality_cnt
        rate_pct = (quality_cnt / warranty_cnt * 100.0) if warranty_cnt > 0 else 0.0

        rows["æœˆåº¦ç»´ä¿®é‡"].append(total)
        rows["æœˆåº¦è´¨é‡ç»´ä¿®é‡"].append(quality_cnt)
        rows["å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"].append(avg_cost)
        rows["æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"].append(est_cost)
        rows["æœˆåº¦ä¿å†…æ•°é‡"].append(warranty_cnt)
        rows["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"].append(rate_pct)
        rows["æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰"].append(fees4)
        rows["æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰"].append(paid4)

    pv = pd.DataFrame(rows).T
    pv = pv.reindex([
        "æœˆåº¦ç»´ä¿®é‡",
        "æœˆåº¦è´¨é‡ç»´ä¿®é‡",
        "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰",
        "æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰",
        "æœˆåº¦ä¿å†…æ•°é‡",
        "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%",
        "æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰",
        "æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰",
    ])
    pv.columns = [f"{m}æœˆ" for m in months]
    for c in pv.columns:
        pv[c] = pd.to_numeric(pv[c], errors="coerce").fillna(0)
    return pv

def build_monthly_display(pv_numeric: pd.DataFrame)->pd.DataFrame:
    pv = pv_numeric.copy()
    for r in ["å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰","æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"]:
        pv.loc[r] = pv.loc[r].map(fmt_money)
    pv.loc["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"] = pv.loc["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"].map(lambda x: f"{x:.2f}%")
    for r in ["æœˆåº¦ç»´ä¿®é‡","æœˆåº¦è´¨é‡ç»´ä¿®é‡","æœˆåº¦ä¿å†…æ•°é‡"]:
        pv.loc[r] = pv.loc[r].astype(int)
    pv = pv.drop(index=["æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰","æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰"], errors="ignore")
    return pv

def build_quarter_from_monthly(pv_numeric: pd.DataFrame, *, fleet_mode: str = "avg")->pd.DataFrame:
    q_cols = {
        "Q1": ["1æœˆ","2æœˆ","3æœˆ"],
        "Q2": ["4æœˆ","5æœˆ","6æœˆ"],
        "Q3": ["7æœˆ","8æœˆ","9æœˆ"],
        "Q4": ["10æœˆ","11æœˆ","12æœˆ"],
    }
    q_num = pd.DataFrame(index=pv_numeric.index, columns=list(q_cols.keys())+["å…¨å¹´"], dtype=float)
    for q, cols in q_cols.items():
        q_num[q] = pv_numeric[cols].sum(axis=1, numeric_only=True)
    q_num["å…¨å¹´"] = pv_numeric.sum(axis=1, numeric_only=True)

    fee_row  = "æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰"
    paid_row = "æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰"
    avg_row  = "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"
    if fee_row in pv_numeric.index and paid_row in pv_numeric.index and avg_row in pv_numeric.index:
        for q, cols in q_cols.items():
            fees_q  = float(pv_numeric.loc[fee_row,  cols].sum())
            paid_q  = float(pv_numeric.loc[paid_row, cols].sum())
            q_num.loc[avg_row, q] = (fees_q / paid_q) if paid_q > 0 else 0.0
        fees_y = float(pv_numeric.loc[fee_row].sum())
        paid_y = float(pv_numeric.loc[paid_row].sum())
        q_num.loc[avg_row, "å…¨å¹´"] = (fees_y / paid_y) if paid_y > 0 else 0.0

    rename = {
        "æœˆåº¦ç»´ä¿®é‡": "å­£åº¦ç»´ä¿®é‡",
        "æœˆåº¦è´¨é‡ç»´ä¿®é‡": "å­£åº¦è´¨é‡ç»´ä¿®é‡",
        "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰": "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰",
        "æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰": "å­£åº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰",
        "æœˆåº¦ä¿å†…æ•°é‡": "å­£åº¦ä¿å†…æ•°é‡",
        "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%": "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%",
        fee_row: fee_row,
        paid_row: paid_row,
    }
    q_num.index = [rename.get(i, i) for i in q_num.index]

    if "å­£åº¦ä¿å†…æ•°é‡" in q_num.index and "æœˆåº¦ä¿å†…æ•°é‡" in pv_numeric.index:
        if fleet_mode.lower() == "avg":
            for q, cols in q_cols.items():
                q_num.loc["å­£åº¦ä¿å†…æ•°é‡", q] = float(pv_numeric.loc["æœˆåº¦ä¿å†…æ•°é‡", cols].mean())
            q_num.loc["å­£åº¦ä¿å†…æ•°é‡", "å…¨å¹´"] = float(pv_numeric.loc["æœˆåº¦ä¿å†…æ•°é‡"].mean())

    q_show = q_num.copy()
    for r in ["å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰", "å­£åº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"]:
        if r in q_show.index:
            q_show.loc[r] = q_show.loc[r].map(lambda v: f"${v:,.0f}")
    if "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%" in q_show.index:
        q_show.loc["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"] = q_show.loc["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"].map(lambda v: f"{float(v):.2f}%")
    for r in ["å­£åº¦ç»´ä¿®é‡", "å­£åº¦è´¨é‡ç»´ä¿®é‡", "å­£åº¦ä¿å†…æ•°é‡"]:
        if r in q_show.index:
            q_show.loc[r] = q_show.loc[r].astype(int)

    q_show = q_show.drop(index=[rename[fee_row], rename[paid_row]], errors="ignore")
    return q_show

# ============== ä¾§æ ï¼ˆä¸Šä¼ /æ¸…ç©ºä»…ç®¡ç†å‘˜ï¼‰ ==============
with st.sidebar:
    logout_button()
    u = current_user() or {"username":"æœªç™»å½•","name":"è®¿å®¢","role":"viewer"}
    st.markdown(f"**å½“å‰ç”¨æˆ·**ï¼š{u.get('name','')}ï¼ˆ{u.get('username','')} / {u.get('role','')}ï¼‰")

    persisted_file = ensure_cols(load_store_df())
    st.session_state["store_df"] = ensure_cols(persisted_file.copy())

    if is_admin():
        st.markdown("---")
        st.subheader("ğŸ” ç®¡ç†å‘˜åŒº")

        up = st.file_uploader("ä¸Šä¼ æ•°æ®ï¼ˆCSV/XLSXï¼‰", type=["csv","xlsx","xls"])

        def _read_any(up_file):
            if up_file is None: return pd.DataFrame()
            name = up_file.name.lower()
            try:
                if name.endswith((".xlsx",".xls")):
                    df0 = pd.read_excel(up_file, sheet_name=0, header=0, dtype=str)
                else:
                    df0 = pd.read_csv(up_file, dtype=str, encoding="utf-8-sig")
            except UnicodeDecodeError:
                df0 = pd.read_csv(up_file, dtype=str, encoding="gbk", errors="ignore")
            except Exception as e:
                st.error(f"è¯»å–å¤±è´¥ï¼š{e}"); return pd.DataFrame()
            return df0

        df_raw = _read_any(up)

        raw_store = _load_raw_excel_store()
        if "excel_raw_history" not in st.session_state:
            st.session_state["excel_raw_history"] = raw_store.copy()
        if not df_raw.empty:
            df_raw_add = df_raw.copy()
            df_raw_add["__SourceFile"] = getattr(up, "name", "") if up is not None else ""
            df_raw_add["__ImportedAt"] = pd.Timestamp.now(tz=None)
            st.session_state["excel_raw_history"] = pd.concat(
                [st.session_state["excel_raw_history"], df_raw_add], ignore_index=True
            )
            _save_raw_excel_store(st.session_state["excel_raw_history"])

        date_col_name = (list(df_raw.columns)[0] if not df_raw.empty else None)
        st.session_state["date_col_name"] = date_col_name
        df = ensure_cols(df_raw, date_col_name=date_col_name)

        def _bytes_md5(b: bytes)->str:
            h=hashlib.md5(); h.update(b); return h.hexdigest()
        upload_md5=None
        if up is not None:
            try: upload_md5=_bytes_md5(up.getvalue())
            except Exception: upload_md5=None
        is_new_upload=False
        if upload_md5:
            last_md5=st.session_state.get("_last_upload_md5_ice")
            if last_md5!=upload_md5:
                is_new_upload=True
                st.session_state["_last_upload_md5_ice"]=upload_md5

        if not df.empty:
            df = df.copy()
            df["SourceFile"] = getattr(up, "name", "") if up is not None else ""
            df["ImportedAt"] = pd.Timestamp.now(tz=None)

        merge_mode = "ä»…è¿½åŠ ï¼ˆä¸å»é‡ï¼‰"
        st.caption("åˆå¹¶ç­–ç•¥ï¼šä»…è¿½åŠ ï¼ˆä¸å»é‡ï¼‰")

        if is_new_upload and not df.empty:
            merged = ensure_cols(pd.concat([persisted_file, df], ignore_index=True))
            save_store_df(merged)
            persisted = merged
        else:
            persisted = persisted_file

        st.session_state["store_df"] = ensure_cols(persisted.copy())
        st.caption(f"å·²å­˜æ•°æ®é‡ï¼š{len(st.session_state['store_df'])} æ¡ï¼ˆåˆå¹¶ç­–ç•¥ï¼š{merge_mode}ï¼‰")

        if not st.session_state["store_df"].empty:
            tmp=st.session_state["store_df"].copy()
            tmp["Year"]=pd.to_numeric(tmp["Year"], errors="coerce")
            tmp["Month"]=pd.to_numeric(tmp["Month"], errors="coerce")
            ym_count=(tmp.dropna(subset=["Year","Month"]).astype({"Year":int,"Month":int})
                      .groupby(["Year","Month"]).size().reset_index(name="æ•°é‡").sort_values(["Year","Month"]))
            with st.expander("ğŸ“Š Year/Month æ•°é‡åˆ†å¸ƒï¼ˆé»˜è®¤æ”¶èµ·ï¼‰", expanded=False):
                st.dataframe(ym_count, use_container_width=True, height=200)

        st.markdown("---")
        with st.expander("ğŸ“ åŸå§‹ Excel å†å²ç»´æŠ¤", expanded=False):
            st.caption("è¿™é‡Œåªå½±å“ã€åŸå§‹ Excel è¡¨æ˜ å°„ã€ç”¨åˆ°çš„å†å²ï¼Œä¸å½±å“å·²å…¥åº“çš„åˆ†ææ•°æ®ã€‚")
            if st.button("æ¸…ç©ºåŸå§‹ Excel ä¸Šä¼ å†å²", type="primary", use_container_width=True):
                _clear_raw_excel_history()
                st.success("å·²æ¸…ç©ºã€åŸå§‹ Excel ä¸Šä¼ å†å²ã€ï¼ˆå†…å­˜ + ç£ç›˜ï¼‰ã€‚")
                st.rerun()

        st.subheader("ğŸ§¹ æ•°æ®æ¸…ç©ºï¼ˆç®¡ç†å‘˜ï¼‰")
        clear_mode = st.radio("é€‰æ‹©æ¸…ç©ºèŒƒå›´", ["æ¸…ç©ºæ‰€é€‰ å¹´ä»½+æœˆä»½","æ¸…ç©ºæ‰€é€‰ å¹´ä»½ï¼ˆæ•´å¹´ï¼‰","æ¸…ç©ºå…¨éƒ¨æ•°æ®","ä»…æ¸…ç©ºå¹´åº¦ç›®æ ‡é…ç½®"], index=0)
        confirm = st.checkbox("æˆ‘å·²ç¡®è®¤è¦æ‰§è¡Œæ¸…ç©ºæ“ä½œ")
        if st.button("æ‰§è¡Œæ¸…ç©º", type="primary", use_container_width=True, disabled=not confirm):
            df_all = st.session_state.get("store_df", pd.DataFrame()).copy()
            if clear_mode=="ä»…æ¸…ç©ºå¹´åº¦ç›®æ ‡é…ç½®":
                save_targets({"target_year_rate":5.0,"q1_t":0.0,"q2_t":0.0,"q3_t":0.0,"q4_t":0.0,"year_t":5.0})
                for k,v in {"target_year_rate":5.0,"q1_t":0.0,"q2_t":0.0,"q3_t":0.0,"q4_t":0.0,"year_t":5.0}.items():
                    st.session_state[k]=v
                st.success("å·²æ¸…ç©ºå¹´åº¦ç›®æ ‡é…ç½®ã€‚")
            else:
                if clear_mode=="æ¸…ç©ºå…¨éƒ¨æ•°æ®":
                    df_all = pd.DataFrame(columns=ensure_cols(pd.DataFrame()).columns)
                    _clear_raw_excel_history()
                elif clear_mode=="æ¸…ç©ºæ‰€é€‰ å¹´ä»½ï¼ˆæ•´å¹´ï¼‰":
                    y_ser = pd.to_numeric(df_all.get("Year", pd.Series(dtype="Int64")), errors="coerce")
                    df_all = df_all[~(y_ser==int(st.session_state.get("year", 2025)))].reset_index(drop=True)
                elif clear_mode=="æ¸…ç©ºæ‰€é€‰ å¹´ä»½+æœˆä»½":
                    y_ser = pd.to_numeric(df_all.get("Year"), errors="coerce")
                    m_ser = pd.to_numeric(df_all.get("Month"), errors="coerce")
                    months_to_clear = st.session_state.get("selected_period_months", [1])
                    df_all = df_all[~((y_ser==int(st.session_state.get("year", 2025))) & (m_ser.isin(months_to_clear)))].reset_index(drop=True)
                save_store_df(ensure_cols(df_all))
                st.session_state["store_df"]=ensure_cols(df_all.copy())
                st.success("å·²å®Œæˆæ¸…ç©ºå¹¶ä¿å­˜ã€‚")

    # ===== æ‰€æœ‰äººå¯è§ï¼šå¹´ä»½ / æœˆä»½(å­£åº¦)é€‰æ‹© & å¹´åº¦ç›®æ ‡é…ç½® =====
    df_all_ss = st.session_state.get("store_df", pd.DataFrame())
    years=YEARS_FIXED[:]
    if not df_all_ss.empty:
        _yy=pd.to_numeric(df_all_ss.get("Year", pd.Series(dtype="Int64")), errors="coerce")
        present_years=sorted(set(int(y) for y in _yy.dropna().astype(int).tolist() if y in years))
    else:
        present_years=[]
    default_year=(max(present_years) if present_years else 2025)
    default_year_idx=years.index(default_year)

    if not df_all_ss.empty:
        _yy2=pd.to_numeric(df_all_ss.get("Year", pd.Series(dtype="Int64")), errors="coerce")
        _mm2=pd.to_numeric(df_all_ss.get("Month", pd.Series(dtype="Int64")), errors="coerce")
        months_in_default=sorted(_mm2[(_yy2==default_year)].dropna().astype(int).unique().tolist())
    else:
        months_in_default=[]
    default_month=(max(months_in_default) if months_in_default else 1)

    year = st.selectbox("é€‰æ‹©å¹´ä»½", years, index=default_year_idx, key="year")

    PERIOD_OPTIONS = (
        [{"type": "M", "months": [m], "label": f"{m:02d}æœˆ"} for m in range(1, 13)]
        + [
            {"type": "Q", "months": [1, 2, 3],   "label": "ä¸€å­£åº¦ (01â€“03)"},
            {"type": "Q", "months": [4, 5, 6],   "label": "äºŒå­£åº¦ (04â€“06)"},
            {"type": "Q", "months": [7, 8, 9],   "label": "ä¸‰å­£åº¦ (07â€“09)"},
            {"type": "Q", "months": [10, 11, 12],"label": "å››å­£åº¦ (10â€“12)"},
        ]
    )
    _default_label = f"{int(default_month):02d}æœˆ"
    _default_idx = next((i for i, o in enumerate(PERIOD_OPTIONS) if o["label"] == _default_label), 0)

    period_sel = st.selectbox(
        "é€‰æ‹©æœˆä»½ / å­£åº¦",
        PERIOD_OPTIONS,
        index=_default_idx,
        format_func=lambda o: o["label"],
    )
    st.session_state["selected_period_months"] = period_sel["months"]
    st.session_state["selected_period_label"]  = period_sel["label"]
    st.session_state["selected_period_is_quarter"] = (period_sel["type"] == "Q")

# ç»Ÿè®¡å£å¾„ï¼šåªçœ‹ 2025~2030
df_all = ensure_cols(st.session_state.get("store_df", pd.DataFrame())).copy()
st.session_state["store_df_ready"] = True
st.session_state["store_df"] = ensure_cols(df_all.copy())

if df_all.empty:
    st.info("å½“å‰æ²¡æœ‰ä»»ä½•å¯ç­›é€‰çš„æ•°æ®ã€‚è¯·å…ˆç”±ç®¡ç†å‘˜ä¸Šä¼ ï¼ˆåˆ¶å†°æœºæ•°æ®å­˜å‚¨ä¸ºç‹¬ç«‹ *_ice æ–‡ä»¶ï¼Œé»˜è®¤ç©ºï¼‰ã€‚")
else:
    _year_series  = pd.to_numeric(df_all.get("Year",  pd.Series(dtype="Int64")), errors="coerce")
    mask_valid_year = _year_series.isin(YEARS_FIXED)
    df_all = df_all[mask_valid_year].reset_index(drop=True)

_year_series  = pd.to_numeric(df_all.get("Year",  pd.Series(dtype="Int64")), errors="coerce")
_month_series = pd.to_numeric(df_all.get("Month", pd.Series(dtype="Int64")), errors="coerce")

if not df_all.empty:
    with st.expander("ğŸ§ª è§£æè‡ªæ£€ï¼ˆé»˜è®¤æ”¶èµ·ï¼‰", expanded=False):
        valid = _year_series.notna() & _month_series.notna()
        st.write("æœ‰æ•ˆå¯ç­›é€‰çš„è¡Œæ•°ï¼š", int(valid.sum()))
        st.write("å½“å‰é€‰æ‹©ï¼ˆå¹´ä»½ä¼—æ•°ï¼‰ï¼š", f"{int(_year_series.mode().iloc[0]) if valid.any() else ''}")
        ym_dist = (pd.DataFrame({"Year": _year_series, "Month": _month_series})
                   .loc[(_year_series.notna()) & (_month_series.notna())]
                   .groupby(["Year","Month"]).size().reset_index(name="æ•°é‡").sort_values(["Year","Month"]))
        st.dataframe(ym_dist, use_container_width=True, height=180)

cur_year  = int(st.session_state.get("year", 2025))
_sel_months: List[int] = st.session_state.get("selected_period_months", [1])
_sel_label  = st.session_state.get("selected_period_label", f"{_sel_months[0]:02d}æœˆ")
_is_quarter = bool(st.session_state.get("selected_period_is_quarter", False))

m_ser = pd.to_numeric(df_all.get("Month", pd.Series(dtype="Int64")), errors="coerce")
y_ser = pd.to_numeric(df_all.get("Year",  pd.Series(dtype="Int64")), errors="coerce")
df_period = df_all[(y_ser == cur_year) & (m_ser.isin(_sel_months))].copy()

edit_month = int(sorted(_sel_months)[-1])

st.markdown(f"### åˆ†ç±»ç»Ÿè®¡ï¼ˆæŒ‰æ‰€é€‰æœŸé—´ï¼š{cur_year}å¹´ {_sel_label}ï¼‰")
if df_period.empty:
    st.warning("å½“å‰æ‰€é€‰æœŸé—´æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•æ•°æ®ã€‚")
else:
    st.markdown(render_category_table_html(compute_category_stats(df_period)), unsafe_allow_html=True)

df_year_only = df_all[y_ser == cur_year]
st.markdown(f"### {cur_year}å¹´åº¦ç›®æ ‡ç»´ä¿®ç‡ä¸º{int(load_targets()['target_year_rate']):d}%")
fleet = load_model_fleet()

pv_num  = build_monthly_numeric(df_year_only, fleet, int(cur_year))
pv_show = build_monthly_display(pv_num)
st.dataframe(pv_show, use_container_width=True)

st.markdown("### å­£åº¦ç»Ÿè®¡æ•°æ®ï¼ˆæ•´å¹´ï¼‰")
q_show = build_quarter_from_monthly(pv_num, fleet_mode="avg")
st.dataframe(q_show, use_container_width=True)

# ============== å‹å·è§£æï¼ˆä¸å†°ç®±é£æ ¼ä¸€è‡´ï¼Œå…¼å®¹ Ice Machine / CYRxxxP / çº¯æ•°å­—ï¼‰ ==============
def resolve_model_key(raw: str) -> str:
    s = (raw or "").strip().replace("\u3000", " ")
    # ç»Ÿä¸€åˆ†éš”ç¬¦
    s = re.sub(r"[\s\-_\/]+", " ", s, flags=re.I).strip()

    # å…ˆå°è¯•æŒ‰åˆ«åç›´æ¥åŒ¹é…ï¼ˆå¤§å°å†™/ç©ºæ ¼ä¸æ•æ„Ÿï¼‰
    key_up = s.upper().replace(" ", "")
    for k, v in ALIASES.items():
        if key_up == str(k).upper().replace(" ", ""):
            return v

    # å»æ‰å‰ç¼€ï¼šREFRIGERATION- / ICE MACHINE-
    s = re.sub(r"^\s*(REFRIGERATION|ICE\s*MACHINE)\s*[-_:ï¼š/\\]*", "", s, flags=re.I).strip()
    s0 = re.sub(r"[\s\-_\/]+", "", s, flags=re.I).upper()

    # CYR400P / CYR700P -> å»å°¾ç¼€ P
    s0 = re.sub(r"^CYR(400|700)P$", r"CYR\1", s0)

    # çº¯æ•°å­—ï¼š140/280/450/800/350
    if re.fullmatch(r"\d{3}", s0):
        if s0 == "350":
            return "HD350"
        elif s0 in {"140","280","450","800"}:
            return f"YR{s0}"

    # CYR æ¡¶ï¼ˆå®¹å¿åç¼€ï¼‰
    m = re.match(r"^CYR(400|700)", s0)
    if m:
        return f"CYR{m.group(1)}"

    # å…œåº•ï¼šå·²çŸ¥å‰ç¼€
    if s0.startswith("YR140"): return "YR140"
    if s0.startswith("YR280"): return "YR280"
    if s0.startswith("YR450"): return "YR450"
    if s0.startswith("YR800"): return "YR800"
    if s0.startswith("HD350") or s0.startswith("ICEBUCKET350"): return "HD350"

    # å…¶ä»–æœªè¯†åˆ«ï¼šè¿”å›æ ‡å‡†åŒ–å­—ç¬¦ä¸²ï¼ˆä¸ä¼šå…¥åº“ï¼Œå› ä¸ºä¸åœ¨ MAP é‡Œï¼‰
    return s0
def _parse_bulk_paste(txt: str) -> dict:
    """
    ä¸€è¡Œä¸€æ¡ï¼Œæ”¯æŒï¼š
      - YR140 1000
      - Ice Machine-280,  900
      - CYR400P 200å°
      - 350  1200        ï¼ˆâ†’ HD350ï¼‰
      - YR450\t800
    é€»è¾‘ï¼šå–è¡Œå°¾æ•°å­—ï¼ˆå®¹è®¸åƒåˆ†ä½/å°æ•°/å•ä½ï¼‰ï¼Œå‰åŠæ®µåšå‹å·å½’ä¸€ã€‚
    """
    updates = {}
    if not txt or not txt.strip():
        return updates

    tail_num = re.compile(r"(?P<num>\d[\d,\.]*)\s*$")  # æŠ“è¡Œå°¾æ•°å­—

    for raw_line in txt.strip().splitlines():
        line = str(raw_line).strip()
        if not line:
            continue
        # è·³è¿‡è¡¨å¤´ç±»è¡Œ
        if re.search(r"(å‹å·|series|åœ¨ä¿|æ•°é‡|åˆè®¡)", line, re.I):
            continue

        m = tail_num.search(line)
        if not m:
            continue

        num_str = m.group("num")
        model_part = line[:m.start()].strip()

        mdl = resolve_model_key(model_part)
        if mdl not in ICE_MODEL_CATEGORY_MAP:
            continue

        try:
            val = int(float(num_str.replace(",", "")))
        except Exception:
            continue

        updates[mdl] = updates.get(mdl, 0) + max(0, val)

    return updates



st.markdown("### å‹å·ç³»åˆ—ç»´åº¦ï¼ˆæŒ‰åœ¨ä¿æ•°é‡å£å¾„ï¼‰")
with st.expander("ğŸ“ å½•å…¥ï¼šå„å‹å·åœ¨ä¿æ•°é‡ï¼ˆæŒ‰æœˆï¼‰", expanded=False):
    st.caption(f"å½“å‰ä½œç”¨å¹´æœˆï¼š{cur_year}-{int(edit_month):02d}ï¼ˆè‹¥é€‰æ‹©å­£åº¦ï¼Œè¿™é‡Œé»˜è®¤ä½¿ç”¨è¯¥æœŸé—´æœ€åä¸€ä¸ªæœˆï¼‰")
    tab1, tab2 = st.tabs(["æ‰¹é‡ç²˜è´´ï¼ˆæ¨èï¼‰","é€ä¸ªè¾“å…¥"])
    with tab1:
        sample="å‹å·ç³»åˆ—\tå½“æœˆåœ¨ä¿æ•°é‡\nYR140\t1000\nYR280\t900\n..."
        txt=st.text_area("ä» Excel å¤åˆ¶ä¸¤åˆ—ï¼ˆå‹å·ç³»åˆ— + å½“æœˆåœ¨ä¿æ•°é‡ï¼‰åç²˜è´´åˆ°æ­¤å¤„ï¼š", height=180, placeholder=sample)
        col_l, col_r = st.columns([1,1])
        with col_l:
            if st.button("è§£æå¹¶å†™å…¥å½“æœˆåœ¨ä¿æ•°é‡", type="primary", use_container_width=True, key="btn_parse_fleet_month_ice"):
                upd=_parse_bulk_paste(txt)
                if not upd:
                    st.warning("æ²¡æœ‰è§£æåˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä¸ºä¸¤åˆ—ï¼ˆå‹å·ç³»åˆ— + å½“æœˆåœ¨ä¿æ•°é‡ï¼‰ï¼Œä¸”å‹å·åœ¨ ICE_MODEL_CATEGORY_MAP å†…ã€‚")
                else:
                    fleet=set_fleet_month(fleet, int(cur_year), int(edit_month), upd)
                    save_model_fleet(fleet)
                    st.success(f"å·²å†™å…¥ {len(upd)} ä¸ªå‹å·çš„å½“æœˆåœ¨ä¿æ•°é‡ã€‚")
                    st.rerun()
        with col_r:
            month_fleet=get_fleet_month(fleet, int(cur_year), int(edit_month))
            preview=pd.DataFrame({
                "å‹å·ç³»åˆ—":[m for m in ICE_MODEL_ORDER if m!="åˆè®¡"],
                f"å½“æœˆåœ¨ä¿æ•°é‡ï¼ˆ{cur_year}-{int(edit_month):02d}ï¼‰":[int(month_fleet.get(m,0)) for m in ICE_MODEL_ORDER if m!="åˆè®¡"],
                "ç±»åˆ«":[ICE_MODEL_CATEGORY_MAP.get(m,"") for m in ICE_MODEL_ORDER if m!="åˆè®¡"],
            })
            st.dataframe(preview, use_container_width=True, height=240)
    with tab2:
        month_fleet=get_fleet_month(fleet, int(cur_year), int(edit_month))
        cols=st.columns(3); changed=False
        for i, mdl in enumerate([m for m in ICE_MODEL_ORDER if m!="åˆè®¡"]):
            with cols[i%3]:
                cur=int(month_fleet.get(mdl,0))
                val=st.number_input(mdl, min_value=0, max_value=10_000_000, value=cur, step=1, key=f"fleet_ice_{cur_year}_{edit_month}_{mdl}")
                if val!=cur:
                    month_fleet[mdl]=int(val); changed=True
        if changed:
            fleet=set_fleet_month(fleet, int(cur_year), int(edit_month), month_fleet)
            save_model_fleet(fleet)
            st.success("å·²ä¿å­˜å½“æœˆåœ¨ä¿æ•°é‡ã€‚")

def _find_model_col(df0: pd.DataFrame):
    pri_candidates = ["å‹å·å½’ç±»","å‹å·ç³»åˆ—","series","model_series"]
    sec_candidates = ["æœºå‹","å…·ä½“å‹å·","äº§å“å‹å·","Part Model","PartModel","Part","MODEL","model","å‹å·"]
    for c in df0.columns:
        if str(c).strip().lower() in [n.lower() for n in pri_candidates]:
            return c
    for c in df0.columns:
        if str(c).strip().lower() in [n.lower() for n in sec_candidates]:
            return c
    return None

def build_model_table(df_all: pd.DataFrame, model_col: str, fleet_all: dict,
                      cur_year: int, sel_months: List[int], period_label: str,
                      use_avg_fleet: bool = False) -> pd.DataFrame:
    rows=[]; pat_21a = re.compile(r"(?<![0-9a-z])2\.1\.a(?![0-9a-z])", re.I)

    def _sum_fleet_months(fleet: dict, year: int, months: List[int]) -> dict:
        acc={k:0 for k in ICE_MODEL_ORDER if k!="åˆè®¡"}
        for m in months:
            mf = get_fleet_month(fleet, year, int(m))
            for mdl, v in mf.items():
                acc[mdl] = acc.get(mdl, 0) + int(v or 0)
        return acc

    if df_all.empty or (model_col is None):
        df_cur = pd.DataFrame(columns=list(df_all.columns)+["_model_norm","_is_21a","_paid"])
    else:
        y = pd.to_numeric(df_all.get("Year"), errors="coerce")
        m = pd.to_numeric(df_all.get("Month"), errors="coerce")
        df_cur = df_all[(y==int(cur_year)) & (m.isin(sel_months))].copy()

    if not df_cur.empty and model_col in df_cur.columns:
        known = list(ICE_MODEL_CATEGORY_MAP.keys())
        known_sorted = sorted(known, key=lambda k: len(k.replace(" ","")), reverse=True)
        known_nospace = {k.replace(" ",""):k for k in known}
        def normalize_series(x:str)->str:
            s=(x or "")
            s_up = re.sub(r"^\s*REFRIGERATION\s*[-_:ï¼š/\\]\s*", "", s.upper())
            s_up = re.sub(r"[\s\-_\/]+"," ", s_up).strip()
            s0   = re.sub(r"[\s\-_\/]+","", s_up)
            if s0 in known_nospace: return known_nospace[s0]
            for k in known_sorted:
                if s0.startswith(k.replace(" ","")): return k
            m0 = re.match(r"^([A-Z]{2,4})(\d.*)?$", s0)
            if m0 and m0.group(1) in known_nospace: return known_nospace[m0.group(1)]
            return ""
        df_cur["_model_norm"] = df_cur[model_col].astype(str).map(normalize_series)
        joined = df_cur.astype(str).agg(" ".join, axis=1).map(_clean_text)
        df_cur["_is_21a"] = joined.str.contains(pat_21a, regex=True)
        df_cur["_paid"]   = pd.to_numeric(df_cur.get("CostUSD", 0), errors="coerce").fillna(0) > 0
    else:
        df_cur = pd.DataFrame(columns=list(df_all.columns)+["_model_norm","_is_21a","_paid"])

    period_fleet_sum = _sum_fleet_months(fleet_all, cur_year, sel_months)
    n_months = max(1, len(sel_months))
    col_title = (f"åœ¨ä¿æ•°é‡ï¼ˆ{cur_year}å¹´ {period_label} å¹³å‡ï¼‰" if use_avg_fleet
                 else f"åœ¨ä¿æ•°é‡ï¼ˆ{cur_year}å¹´ {period_label} åˆè®¡ï¼‰")

    total_fleet_sum = total_qp = 0
    total_cost  = 0.0

    for mdl in ICE_MODEL_ORDER:
        if mdl == "åˆè®¡": continue
        fleet_sum = int(period_fleet_sum.get(mdl, 0))
        fleet_for_rate = int(round(fleet_sum / n_months)) if use_avg_fleet else fleet_sum
        total_fleet_sum += (fleet_sum if not use_avg_fleet else fleet_for_rate)

        if not df_cur.empty and "_model_norm" in df_cur.columns:
            mask_model = (df_cur["_model_norm"] == mdl)
            qual_cnt   = int((mask_model & df_cur["_is_21a"]).sum())
            month_cost = float(pd.to_numeric(df_cur.loc[mask_model & df_cur["_is_21a"] & df_cur["_paid"], "CostUSD"], errors="coerce").fillna(0).sum())
        else:
            qual_cnt = 0; month_cost = 0.0

        total_qp   += qual_cnt
        total_cost += month_cost
        rate = (qual_cnt / fleet_for_rate * 100.0) if fleet_for_rate > 0 else 0.0

        rows.append({
            "å‹å·ç³»åˆ—": mdl,
            "ç±»åˆ«": ICE_MODEL_CATEGORY_MAP.get(mdl, ""),
            col_title: fleet_for_rate,
            "è´¨é‡é—®é¢˜ï¼ˆæœŸé—´åˆè®¡ï¼‰": qual_cnt,
            "æœŸé—´ç»´ä¿®ç‡": f"{rate:.3f}%",
            "æœŸé—´ç»´ä¿®è´¹ç”¨åˆè®¡": fmt_money(month_cost),
        })

    total_rate = (total_qp / total_fleet_sum * 100.0) if total_fleet_sum > 0 else 0.0
    rows.insert(0, {
        "å‹å·ç³»åˆ—": "åˆè®¡", "ç±»åˆ«": "",
        col_title: total_fleet_sum,
        "è´¨é‡é—®é¢˜ï¼ˆæœŸé—´åˆè®¡ï¼‰": total_qp,
        "æœŸé—´ç»´ä¿®ç‡": f"{total_rate:.3f}%",
        "æœŸé—´ç»´ä¿®è´¹ç”¨åˆè®¡": fmt_money(total_cost),
    })
    return pd.DataFrame(rows)

model_col = _find_model_col(df_all) if not df_all.empty else None
model_table = build_model_table(
    df_all, model_col, fleet, int(cur_year),
    sel_months=_sel_months,
    period_label=_sel_label,
    use_avg_fleet=_is_quarter
)
st.dataframe(model_table, use_container_width=True)

# ============== å›ºå®šæ¸…å•èšåˆ + é“¾æ¥åˆ°é…ä»¶åˆ†æ ==============
def build_fixed_issue_table(df_scope: pd.DataFrame, mapping: list, *, drop_dupes: bool=False)->pd.DataFrame:
    if df_scope.empty:
        return pd.DataFrame(columns=["é¡¹ç›®ï¼ˆç¼–ç +è‹±æ–‡ï¼‰","é—®é¢˜ä¸­æ–‡å","æ•°é‡","è´¹ç”¨"])

    # ç›´æ¥æŒ‰å½’ä¸€åˆ†ç±»ï¼šè´¨é‡é—®é¢˜/Atosa
    mask_quality = (df_scope["Category1"].astype(str)=="è´¨é‡é—®é¢˜") & (df_scope["Category2"].astype(str)=="Atosa")
    if not mask_quality.any():
        return pd.DataFrame(columns=["é¡¹ç›®ï¼ˆç¼–ç +è‹±æ–‡ï¼‰","é—®é¢˜ä¸­æ–‡å","æ•°é‡","è´¹ç”¨"])

    df_21a = df_scope.loc[mask_quality].copy()

    text_cols = ["Category1","Category2","TAG1","TAG2","TAG3","TAG4","é—®é¢˜æè¿°","æè¿°","åŸå› ","å¤‡æ³¨","çŠ¶æ€","æ ‡é¢˜","Summary","Notes"]
    has_cols = [c for c in text_cols if c in df_21a.columns] or df_21a.columns.tolist()
    joined = df_21a[has_cols].astype(str).agg(" ".join, axis=1).str.lower()

    if drop_dupes:
        dedupe_keys = [c for c in ["Date","Category1","Category2","TAG1","TAG2","TAG3","TAG4","Summary","Notes"] if c in df_21a.columns]
        if dedupe_keys:
            df_21a["_dedupe_key"] = df_21a[dedupe_keys].astype(str).agg("|".join, axis=1)
            df_21a = df_21a.drop_duplicates(subset=["_dedupe_key"], keep="first")
            joined = df_21a[has_cols].astype(str).agg(" ".join, axis=1).str.lower()

    cost = pd.to_numeric(df_21a.get("CostUSD", 0), errors="coerce").fillna(0.0)
    paid_mask = (cost > 0)

    rows = []
    for item in mapping:
        code = item["code"].strip()
        en   = item["en"].strip()
        cn   = item["cn"].strip()
        code_pat = re.compile(rf"(?<![0-9a-z]){re.escape(code)}(?![0-9a-z])", re.I)
        m = joined.str.contains(code_pat)
        qty = int(m.sum())
        fee_val = float(cost[m & paid_mask].sum())
        rows.append({
            "é¡¹ç›®ï¼ˆç¼–ç +è‹±æ–‡ï¼‰": f"{code} {en}",
            "é—®é¢˜ä¸­æ–‡å": cn,
            "æ•°é‡": qty,
            "è´¹ç”¨": f"${fee_val:,.0f}",
            "_fee_val": fee_val,
            "_code": code
        })

    out = (pd.DataFrame(rows)
           .sort_values(["æ•°é‡","_fee_val"], ascending=[False, False])
           .reset_index(drop=True))
    return out

st.markdown("### è´¨é‡é—®é¢˜æ˜ç»†ï¼ˆå›ºå®šæ¸…å•ï¼Œè‡ªåŠ¨æ±‡æ€»ï¼‰")
scope = st.radio("ç»Ÿè®¡å£å¾„", ["æŒ‰æ‰€é€‰æœŸé—´ï¼ˆæœˆä»½/å­£åº¦ï¼‰","æŒ‰å…¨å¹´"], index=0, horizontal=True)
df_year_only = df_all[_year_series==cur_year]
if scope == "æŒ‰æ‰€é€‰æœŸé—´ï¼ˆæœˆä»½/å­£åº¦ï¼‰":
    df_scope = df_period
    title_suffix = f"{cur_year}å¹´ {_sel_label}"
    _dl_tag = _sel_label.replace(" ", "").replace("(", "").replace(")", "")
    download_name = f"å›ºå®šè´¨é‡é—®é¢˜æ¸…å•_åˆ¶å†°æœº_{cur_year}_{_dl_tag}.csv"
else:
    df_scope = df_year_only
    title_suffix = f"{cur_year}å…¨å¹´"
    download_name = f"å›ºå®šè´¨é‡é—®é¢˜æ¸…å•_åˆ¶å†°æœº_{cur_year}.csv"

st.session_state['store_df'] = ensure_cols(df_all.copy())

fixed_table = build_fixed_issue_table(df_scope, FIXED_DEFECTS)
if fixed_table.empty:
    st.info(f"{title_suffix} æ— æ•°æ®å¯ç»Ÿè®¡ã€‚")
else:
    _months_param = ",".join(str(m) for m in _sel_months)
    _q_name = None
    if set(_sel_months) == {1,2,3}:   _q_name = "Q1"
    elif set(_sel_months) == {4,5,6}: _q_name = "Q2"
    elif set(_sel_months) == {7,8,9}: _q_name = "Q3"
    elif set(_sel_months) == {10,11,12}: _q_name = "Q4"

    def _build_link(code: str) -> str:
        base = (page_url_by_code(__file__, str(code)) or "#")
        if _q_name:
            return f"{base}?code={quote(str(code))}&year={int(cur_year)}&months={_months_param}&q={_q_name}"
        else:
            return f"{base}?code={quote(str(code))}&year={int(cur_year)}&months={_months_param}"

    fixed_table["é…ä»¶åˆ†æ"] = fixed_table["_code"].apply(_build_link)

    st.caption(f"ç»Ÿè®¡å£å¾„ï¼š{title_suffix}")
    st.data_editor(
        fixed_table[["é¡¹ç›®ï¼ˆç¼–ç +è‹±æ–‡ï¼‰","é—®é¢˜ä¸­æ–‡å","æ•°é‡","è´¹ç”¨","é…ä»¶åˆ†æ"]],
        use_container_width=True, height=520, disabled=True,
        column_config={"é…ä»¶åˆ†æ": st.column_config.LinkColumn("é…ä»¶åˆ†æ", display_text="æ‰“å¼€é…ä»¶åˆ†æ")}
    )
    st.download_button(
        "ä¸‹è½½ CSV",
        data=fixed_table.drop(columns=["_fee_val","_code"], errors="ignore").to_csv(index=False, encoding="utf-8-sig"),
        file_name=download_name,
        mime="text/csv",
        use_container_width=True
    )

# ============== åŸå§‹ Excel è¡¨æ˜ å°„ï¼ˆåˆ¶å†°æœºä¸“ç”¨å†å²ï¼‰ ==============
def _filter_excel_by_mm_yyyy(df_hist: pd.DataFrame, y: int, m: int) -> pd.DataFrame:
    if df_hist is None or df_hist.empty:
        return pd.DataFrame(columns=(df_hist.columns if df_hist is not None else []))

    pat = re.compile(r'(?:^|\D)(?P<mm>0[1-9]|1[0-2])(?P<yyyy>20\d{2})(?:\D|$)')
    hits = []
    for col in df_hist.columns:
        if col in {"__SourceFile", "__ImportedAt"}:
            continue
        ext = df_hist[col].astype(str).str.extract(pat)
        if ext.empty or (ext.isna().all().all()):
            continue
        yy = pd.to_numeric(ext["yyyy"], errors="coerce")
        mm = pd.to_numeric(ext["mm"], errors="coerce")
        mask = (yy == int(y)) & (mm == int(m))
        if mask.any():
            hits.append(df_hist.loc[mask, df_hist.columns])

    if not hits:
        return pd.DataFrame(columns=df_hist.columns)

    out = pd.concat(hits, ignore_index=True)
    key_cols = [c for c in out.columns if not str(c).startswith("__")]
    if key_cols:
        sig = out[key_cols].astype(str).agg("|".join, axis=1).str.lower()
        out = out.loc[~sig.duplicated(keep="first")].reset_index(drop=True)
    return out

if is_admin():
    with st.expander("ğŸ“ åŸå§‹ Excel è¡¨æ˜ å°„ï¼ˆåŸæ ·æ˜¾ç¤ºâ€œç”Ÿäº§æ—¥æœŸâ€ï¼Œæ—  Year/Monthï¼‰", expanded=False):
        _hist = st.session_state.get("excel_raw_history", pd.DataFrame())
        if _hist is None or _hist.empty:
            st.info("æš‚æ— åŸå§‹ä¸Šä¼ å†å²ã€‚è¯·å…ˆä¸Šä¼  Excelï¼ˆåˆ¶å†°æœºä¸“ç”¨é€šé“ï¼Œæ–‡ä»¶ç‹¬ç«‹ä¿å­˜ï¼‰ã€‚")
        else:
            _excel_filtered = _filter_excel_by_mm_yyyy(_hist, int(cur_year), int(edit_month))
            st.caption(f"æ˜¾ç¤ºå£å¾„ï¼š{cur_year}-{edit_month:02d}ï¼ˆè‡ªåŠ¨ä»æ‰€æœ‰åˆ—ä¸­è¯†åˆ« MMYYYYï¼‰")

            if _excel_filtered.empty:
                st.info("è¯¥æœˆåœ¨åŸå§‹å†å²ä¸­æ²¡æœ‰åŒ¹é…åˆ°æ•°æ®ã€‚è¯·æ›´æ¢å¹´æœˆæˆ–æ£€æŸ¥æ•°æ®ä¸­çš„æ—¥æœŸæ–‡æœ¬æ˜¯å¦åŒ…å« MMYYYYã€‚")
            else:
                cols = [c for c in _excel_filtered.columns if c not in {"__SourceFile","__ImportedAt"}]
                cols += [c for c in ["__SourceFile","__ImportedAt"] if c in _excel_filtered.columns]
                _view = _excel_filtered[cols]

                def _fmt_prod_date_cell(v):
                    s = "" if pd.isna(v) else str(v).strip()
                    m6 = re.fullmatch(r"(\d{2})(\d{2})(\d{2})", s)
                    if m6:
                        yy, mm, dd = m6.groups()
                        return f"{2000 + int(yy)}/{mm}/{dd}"
                    m8 = re.fullmatch(r"(\d{4})(\d{2})(\d{2})", s)
                    if m8:
                        y0, mm, dd = m8.groups()
                        return f"{int(y0)}/{mm}/{dd}"
                    try:
                        dt = pd.to_datetime(s, errors="coerce")
                        if pd.isna(dt):
                            return v
                        return f"{dt.year}/{dt.month}/{dt.day}"
                    except Exception:
                        return v

                prod_cols = [c for c in _view.columns if re.search(r"ç”Ÿäº§\s*æ—¥æœŸ", str(c), re.I)]
                _view_display = _view.copy()
                for c in prod_cols:
                    _view_display[c] = _view_display[c].map(_fmt_prod_date_cell)

                _n = int(min(len(_view_display), 16))
                _h = int(46 + 28 * max(_n, 1))
                st.dataframe(_view_display, use_container_width=True, height=min(_h, 600))

# ============== è°ƒè¯•åŒºåŸŸï¼ˆ*_ice çŠ¶æ€ï¼‰ ==============
with st.expander("è°ƒè¯•ï¼šæœ¬æœˆå…³é”®å­—å‘½ä¸­ç»Ÿè®¡ï¼ˆå½“é€‰æ‹©å­£åº¦æ—¶ï¼Œè¿™é‡Œé»˜è®¤ç”¨è¯¥æœŸé—´æœ€åä¸€ä¸ªæœˆï¼‰", expanded=False):
    df_month_real = df_all[(_year_series==cur_year) & (_month_series==edit_month)]
    if not df_month_real.empty:
        joined=df_month_real.astype(str).agg(" ".join, axis=1).map(_clean_text)
        cnt_21a = int(joined.str.contains(re.compile(r"2\.1\.a", re.I)).sum())
        cnt_atosa=int(joined.str.contains(re.compile(r"\batosa\b", re.I)).sum())
        real_cat=df_month_real[(df_month_real["Category1"]=="è´¨é‡é—®é¢˜") & (df_month_real["Category2"]=="Atosa")]
        st.write({"2.1.a å‘½ä¸­æ•°(æ–‡æœ¬)":cnt_21a,"atosa å‘½ä¸­æ•°(æ–‡æœ¬)":cnt_atosa,"æœ€ç»ˆåˆ†ç±»åˆ°ã€è´¨é‡é—®é¢˜/Atosaã€":len(real_cat)})
    else:
        st.write("æœ¬æœˆæ— æ•°æ®")

with st.expander("è°ƒè¯•ï¼šæ¥æºä¸å£å¾„", expanded=False):
    if not df_all.empty:
        st.write("æ€»è®°å½•æ•°ï¼ˆå·²æŒ‰ 2025â€“2030 è¿‡æ»¤åï¼‰ï¼š", len(df_all))
        if "_SrcYM" in df_all.columns:
            st.write("_SrcYM åˆ†å¸ƒï¼ˆTop 10ï¼‰ï¼š"); st.write(df_all["_SrcYM"].value_counts().head(10))
        st.write("å½“æœˆè®°å½•æ•°ï¼š", len(df_all[(_year_series==cur_year)&(_month_series==edit_month)]), " | å…¨å¹´è®°å½•æ•°ï¼š", len(df_year_only))
        st.write("æœ€è¿‘ä¸€æ¬¡ä¸Šä¼ æ–‡ä»¶ MD5ï¼ˆåˆ¶å†°æœºé€šé“ï¼‰ï¼š", st.session_state.get("_last_upload_md5_ice","æ— "))
    else:
        st.write("æš‚æ— æ•°æ®")

with st.expander("ğŸ” è·³è½¬è‡ªæ£€", expanded=False):
    st.write("æ˜ å°„è¡¨ï¼š", {k: v for k, v in _FORCE_CODE2PAGE.items()})
    for code, target in _FORCE_CODE2PAGE.items():
        via_pages = _find_page_url(target)
        guessed   = _guess_url_from_filename(target)
        final     = page_url_by_code(__file__, code)
        st.write(f"{code} â†’ {target} â†’ get_pages: {via_pages} | guessed: {guessed} | final: {final}")
