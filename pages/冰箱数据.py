# -*- coding: utf-8 -*-
# å†°ç®±æ•°æ®ï¼ˆå®Œæ•´ç‰ˆï¼Œå«å­£åº¦æ”¯æŒ & å¤šå¤„æŠ¥é”™ä¿®å¤ï¼‰

# ==== é¡¶éƒ¨è¿½åŠ ï¼šæ–°ä¼šè¯ï¼ˆåˆ·æ–°/ç›´æ¥æ‰“å¼€å­é¡µï¼‰æ—¶ï¼Œå›åˆ°â€œå¯è§†åŒ–â€ ====
import streamlit as st

# è¯´æ˜ï¼š
# - Streamlit æ¯æ¬¡â€œç¡¬åˆ·æ–°/æ–°æ‰“å¼€æ ‡ç­¾é¡µâ€éƒ½ä¼šåˆ›å»ºæ–°çš„ä¼šè¯ï¼ˆsessionï¼‰ï¼Œæ­¤æ—¶ session_state ä¸ºç©ºã€‚
# - æˆ‘ä»¬ç”¨ä¸€ä¸ªæ ‡è®° _first_load_done æ¥è¯†åˆ«â€œæœ¬ä¼šè¯çš„ç¬¬ä¸€æ¬¡åŠ è½½â€ï¼š
#   1) å¦‚æœç”¨æˆ·åˆ·æ–°æˆ–ç›´æ¥æ‰“å¼€å­é¡µï¼ˆæ–°çš„ä¼šè¯ï¼‰ï¼Œæ ‡è®°ä¸å­˜åœ¨ -> ç«‹å³è·³å»â€œå¯è§†åŒ–â€ï¼Œå¹¶æŠŠæ ‡è®°è®¾ä¸º Trueã€‚
#   2) å¦‚æœæ˜¯ç«™å†…ç‚¹å‡»å¯¼èˆªï¼ˆä»åœ¨åŒä¸€ä¼šè¯ï¼‰ï¼Œæ ‡è®°å·²ç»å­˜åœ¨ -> ä¸è·³è½¬ï¼Œæ­£å¸¸åœç•™åœ¨å½“å‰å­é¡µã€‚
if "_first_load_done" not in st.session_state:
    st.session_state["_first_load_done"] = True
    try:
        st.switch_page("å¯è§†åŒ–.py")
    except Exception:
        try:
            st.switch_page("pages/å¯è§†åŒ–.py")
        except Exception:
            import streamlit.components.v1 as components
            components.html(
                "<script>window.parent.location.pathname = decodeURIComponent(window.parent.location.pathname).replace(/[^/]+$/, 'å¯è§†åŒ–');</script>",
                height=0,
            )
# ==== é¡¶éƒ¨è¿½åŠ ç»“æŸ ====

# === BEGIN: å½»åº•ä»ä¾§æ ç§»é™¤â€œåˆ†æâ€é¡µé¢ï¼ˆæ”¾æœ€é¡¶éƒ¨ï¼Œä¸”åœ¨ st.set_page_config ä¹‹å‰ï¼‰ ===
import os, re, sys

def _get_root_script_path():
    try:
        from streamlit.runtime.scriptrunner import get_script_run_ctx
        ctx = get_script_run_ctx()
        if ctx:
            for attr in ("main_script_path", "script_path"):
                p = getattr(ctx, attr, None)
                if p:
                    return p
    except Exception:
        pass
    return os.path.abspath(sys.argv[0])

def remove_analysis_pages_from_sidebar(*, extra_basenames=(), name_regex=r".*åˆ†æ$"):
    try:
        from streamlit.source_util import get_pages
    except Exception:
        return
    root_script = _get_root_script_path()
    pages = get_pages(root_script) or {}
    if not pages:
        return
    rx = re.compile(name_regex) if name_regex else None
    need_hide = {
        "é…ä»¶åˆ†æ.py", "peijianfenxi.py",
        "é£æœºåˆ†æ.py", "æ¸©æ§å™¨åˆ†æ.py", "å‹ç¼©æœºåˆ†æ.py",
        "å¤–éƒ¨æ¼æ°´åˆ†æ.py", "æ³„æ°Ÿåˆ†æ.py",
    }
    need_hide |= {str(x).strip() for x in extra_basenames if str(x).strip()}
    need_hide = {x.lower() for x in need_hide}
    for k, d in list(pages.items()):
        page_name = str(d.get("page_name", "")).strip()
        base = os.path.basename(str(d.get("script_path", "")).replace("\\", "/")).lower()
        if base in need_hide or (rx and rx.fullmatch(page_name)):
            pages.pop(k, None)

remove_analysis_pages_from_sidebar(
    extra_basenames=(
        "é…ä»¶åˆ†æ.py", "peijianfenxi.py",
        "é£æœºåˆ†æ.py", "æ¸©æ§å™¨åˆ†æ.py", "å‹ç¼©æœºåˆ†æ.py",
        "å¤–éƒ¨æ¼æ°´åˆ†æ.py", "æ³„æ°Ÿåˆ†æ.py",
    ),
    name_regex=r".*åˆ†æ$",
)
# === END ===

import json, hashlib, pathlib
from pathlib import Path
from urllib.parse import quote
from typing import List

import pandas as pd
import numpy as np
import streamlit as st
import streamlit.components.v1 as _components
from urllib.parse import quote as _urlquote

# ============== é¡µé¢é…ç½® ==============
st.set_page_config(page_title="å†°ç®±æ•°æ®", layout="wide", initial_sidebar_state="expanded")
st.title("å†°ç®±æ•°æ®")

# ============== è·³è½¬è¾…åŠ© ==============
def _find_page_url(target_tail: str):
    try:
        try:
            from streamlit.source_util import get_pages
        except Exception:
            return None
        pages = get_pages(__file__) or {}
        target_tail_norm = re.sub(r"[\\/]+", "/", str(target_tail)).lower()
        for _, data in pages.items():
            sp = data.get("script_path", "")
            sp_norm = re.sub(r"[\\/]+", "/", str(sp)).lower()
            if sp_norm.endswith(target_tail_norm) or os.path.basename(sp_norm) == os.path.basename(target_tail_norm):
                url = data.get("url_pathname")
                if url:
                    return url
                page_name = data.get("page_name")
                if page_name:
                    return "/" + str(page_name)
        return None
    except Exception:
        return None

# ==== å¼ºåˆ¶ï¼šç¼ºé™·ä¸»ç  -> æŒ‡å®šå·¦ä¾§é¡µé¢è„šæœ¬åï¼ˆæˆ–é¡µé¢åï¼‰====
_FORCE_CODE2PAGE = {
    "1.1.3.5": "é£æœºåˆ†æ.py",     # Fan Motor
    "1.1.3.3": "æ¸©æ§å™¨åˆ†æ.py",   # Temp Controller
    "1.1.3.2": "å‹ç¼©æœºåˆ†æ.py",   # Compressor
    "1.1.5.2": "å¤–éƒ¨æ¼æ°´åˆ†æ.py", # Outside Leak
    "1.1.3.1": "æ³„æ°Ÿåˆ†æ.py",     # Leaking Refrigerant
    "1.1.3.4": "è’¸å‘å™¨çº¿åœˆç»“å†°åˆ†æ.py",
}
def _guess_url_from_filename(target: str) -> str:
    base = os.path.splitext(os.path.basename(str(target)))[0]
    base = re.sub(r"^\d+[_\-\s]*", "", base)
    return f"/{base}"
def page_url_by_code(caller_file: str, code: str) -> str:
    key = str(code or "").strip()
    target = _FORCE_CODE2PAGE.get(key)
    if not target:
        return None
    url = _find_page_url(target)
    if url:
        return url
    return _guess_url_from_filename(target)

# â€”â€” ç”¨æ›´â€œæ ¸â€çš„æ–¹å¼å¼ºåˆ¶éšè—ä¾§æ â€œåˆ†æé¡µé¢â€
def hide_analysis_pages_in_sidebar(caller_file: str, *, debug=False):
    ALLOW_NAMES = {"å†°ç®±æ•°æ®"}
    HIDE_NAME_PATTERNS = [
        r"åˆ†æ$", r"åˆ†æé¡µé¢", r"é…ä»¶åˆ†æ",
        r"é£æœºåˆ†æ", r"æ¸©æ§å™¨åˆ†æ", r"å‹ç¼©æœºåˆ†æ",
        r"å¤–éƒ¨æ¼æ°´åˆ†æ", r"æ³„æ°Ÿåˆ†æ",
        r"analysis$"
    ]
    HIDE_URL_TAILS = [
        "/é…ä»¶åˆ†æ", "/é£æœºåˆ†æ", "/æ¸©æ§å™¨åˆ†æ", "/å‹ç¼©æœºåˆ†æ", "/å¤–éƒ¨æ¼æ°´åˆ†æ", "/æ³„æ°Ÿåˆ†æ",
        "/peijianfenxi", "/fengjifenxi", "/wenkongqifenxi", "/yasuoji", "/waibuloushui", "/xiefen"
    ]
    enc_tails = []
    for t in HIDE_URL_TAILS:
        enc = "/".join(_urlquote(p, safe="") for p in t.split("/"))
        enc_tails.extend({t, enc, t+"/", enc+"/"})
    HREFS = list(sorted(set(enc_tails)))
    payload = {"allow_names": sorted(ALLOW_NAMES), "name_regexes": HIDE_NAME_PATTERNS, "href_tails": HREFS, "debug": bool(debug)}
    js = f"""
    <script>
    (function() {{
      const CONF = { json.dumps(payload, ensure_ascii=False) };
      const allow = new Set(CONF.allow_names || []);
      const nameRes = (CONF.name_regexes || []).map(p => new RegExp(p));
      const hrefTails = new Set(CONF.href_tails || []);
      function normPath(href) {{
        try {{ return new URL(href, window.location.origin).pathname || ""; }}
        catch {{ return href || ""; }}
      }}
      function shouldHideByText(txt) {{
        if (!txt) return false;
        const t = txt.trim();
        if (allow.has(t)) return false;
        return nameRes.some(r => r.test(t));
      }}
      function shouldHideByHref(href) {{
        if (!href) return false;
        const p = normPath(href);
        for (const tail of hrefTails) {{
          if (!tail) continue;
          if (p.endsWith(tail) || p.includes(tail + "/") || p.includes(tail + "?")) return true;
        }}
        return false;
      }}
      function kill(el) {{ if (!el) return; el.style.setProperty('display','none','important'); el.setAttribute('data-hidden-by','bf-hide'); }}
      function scan(root) {{
        const sidebar = document.querySelector('aside[data-testid="stSidebar"]')
                      || document.querySelector('section[data-testid="stSidebar"]')
                      || document.querySelector('[data-testid="stSidebar"]')
                      || document.querySelector('nav[aria-label="Sidebar navigation"]')
                      || (root || document);
        if (!sidebar) return;
        sidebar.querySelectorAll('a[href]').forEach(a => {{
          const href = a.getAttribute('href') || '';
          const txt  = (a.textContent || '').trim();
          if (shouldHideByText(txt) || shouldHideByHref(href)) {{
            const li = a.closest('li') || a.parentElement; kill(li || a);
          }}
        }});
        sidebar.querySelectorAll('*:not(a)').forEach(el => {{
          const txt = (el.textContent || '').trim();
          if (shouldHideByText(txt)) {{
            const li = el.closest('li') || el.closest('[data-testid="stSidebarNav"]') || el.parentElement;
            kill(li || el);
          }}
        }});
      }}
      let tick = 0;
      const timer = setInterval(() => {{ scan(document); tick++; if (tick > 60) clearInterval(timer); }}, 300);
      scan(document);
      const mo = new MutationObserver(() => scan(document));
      mo.observe(document.body, {{ childList: true, subtree: true }});
      if (CONF.debug) console.log('[bf-hide:ready]', CONF);
    }})();
    </script>
    """
    _components.html(js, height=0)

hide_analysis_pages_in_sidebar(__file__, debug=False)

# ============== å¸¸é‡/é…ç½® ==============
FIXED_DEFECTS = [
    {"code":"1.1.3.3","en":"Temp Controller","cn":"æ¸©æ§å™¨"},
    {"code":"1.1.3.5","en":"Fan Motor","cn":"é£æœº"},
    {"code":"1.1.3.1","en":"Leaking Refrigerant","cn":"æ³„æ°Ÿ"},
    {"code":"1.1.3.2","en":"Compressor","cn":"å‹ç¼©æœº"},
    {"code":"1.1.5.2","en":"Outside","cn":"å¤–éƒ¨æ¼æ°´"},
    {"code":"1.1.3.6","en":"White Probe","cn":"ç™½è‰²æ¢å¤´"},
    {"code":"1.1.11.1","en":"Caster/Basement/Nut","cn":"è„šè½®/åº•è„š/èºæ¯"},
    {"code":"1.1.7.1","en":"Hinge/Spring Bar","cn":"é—¨é“°é“¾/é—¨å¼¹ç°§"},
    {"code":"1.1.11.2","en":"Gasket","cn":"é—¨å°æ¡"},
    {"code":"1.1.5.1","en":"Inside","cn":"å†…éƒ¨æ¼æ°´"},
    {"code":"1.1.7.2","en":"Foggy/Condensation between glass","cn":"ç»ç’ƒå¤¹å±‚èµ·é›¾/å‡éœ²"},
    {"code":"1.1.4.1","en":"Power Supply/Transformer","cn":"ç”µæºé€‚é…å™¨/å˜å‹å™¨"},
    {"code":"1.1.1.1","en":"Door","cn":"é—¨/é—¨ä½“é—®é¢˜"},
    {"code":"1.1.11.5","en":"Rail/Drawer Frame","cn":"æ»‘è½¨/æŠ½å±‰æ¡†æ¶"},
    {"code":"1.1.9.1","en":"Fan Motor working with noise","cn":"é£æœºè¿è¡Œæœ‰å™ªéŸ³"},
    {"code":"1.1.11.6","en":"Lock and Key","cn":"é”ä¸é’¥åŒ™"},
    {"code":"1.1.4.3","en":"LED Strip/LED Light","cn":"LED ç¯/ç¯æ¡"},
    {"code":"1.1.3.13","en":"loose wires","cn":"çº¿æŸæ¾åŠ¨"},
    {"code":"1.1.1.4","en":"Top/Bottom/Side Panels","cn":"ä¸Š/ä¸‹/ä¾§æ¿ï¼ˆé’¢ç½©ï¼‰"},
    {"code":"1.1.9.2","en":"Loose screws/hit something","cn":"èºä¸æ¾åŠ¨/æ’å‡»å¼‚ç‰©"},
    {"code":"1.1.1.5","en":"Power Cord","cn":"ç”µæºçº¿"},
    {"code":"1.1.2.1","en":"Power Switch","cn":"ç”µæºå¼€å…³"},
    {"code":"1.1.3.11","en":"F1 F2 Evap fan motor consistently running","cn":"F1/F2 è’¸å‘é£æœºæŒç»­è¿è½¬"},
    {"code":"1.1.11.8","en":"Lid","cn":"ç›–å­/ä¸Šç›–"},
    {"code":"1.1.3.7","en":"Blue Probe","cn":"è“è‰²æ¢å¤´"},
    {"code":"1.1.3.10","en":"Fan Motor stop by hitting something","cn":"é£æœºå¶ç‰‡è¢«å¼‚ç‰©å¡ä½"},
    {"code":"1.1.1.3","en":"Lid","cn":"ç›–å­ï¼ˆè¿è¾“ï¼‰"},
    {"code":"1.1.3.9","en":"Cap Tube Restriction","cn":"æ¯›ç»†ç®¡å µå¡"},
    {"code":"1.1.1.9","en":"Lock and Key","cn":"é”ä¸é’¥åŒ™"},
    {"code":"1.1.7.3","en":"Door ripped off with hinge assembly","cn":"é—¨ä½“ä¸é“°é“¾ç»„ä»¶è„±è½"},
    {"code":"1.1.3.8","en":"Soliened Valve","cn":"ç”µç£é˜€"},
    {"code":"1.1.4.2","en":"Light Switch","cn":"ç¯æ§å¼€å…³"},
    {"code":"1.1.2.2","en":"Wires Shortage","cn":"çº¿æçŸ­ç¼º/çŸ­æ¥"},
    {"code":"1.1.1.7","en":"Handle","cn":"æŠŠæ‰‹"},
    {"code":"1.1.10.1","en":"Wires Shortage","cn":"çº¿æçŸ­ç¼º/çŸ­æ¥"},
    {"code":"1.1.8.1","en":"Front Display","cn":"å‰ç½®æ˜¾ç¤ºå±"},
    {"code":"1.1.8.2","en":"Wire harness broken","cn":"çº¿æŸæŸå"},
    {"code":"1.1.1.12","en":"Power Switch","cn":"ç”µæºå¼€å…³"},
    {"code":"1.1.1.6","en":"Gasket","cn":"é—¨å°æ¡"},
    {"code":"1.1.7.4","en":"MCF8727 Door adjustment","cn":"MCF8727 é—¨ä½“è°ƒèŠ‚"},
    {"code":"1.1.1.2","en":"Hood","cn":"é¡¶ç½©/æŠ¤ç½©"},
    {"code":"1.1.3.12","en":"Cut off 2 inch cap tube and recharge freon","cn":"åˆ‡é™¤2è‹±å¯¸æ¯›ç»†ç®¡å¹¶è¡¥å……åˆ¶å†·å‰‚"},
    {"code":"1.1.11.4","en":"CO2 Distributor","cn":"COâ‚‚ åˆ†é…å™¨"},
    {"code":"1.1.9","en":"Noise","cn":"å™ªéŸ³"},
    {"code":"1.1.11.3","en":"Handle","cn":"æŠŠæ‰‹"},
    {"code":"1.1.b","en":"Replacement-Reason No.2 Unrepairable issue","cn":"æ›´æ¢åŸå› 2ï¼šæ— æ³•ç»´ä¿®"},
    {"code":"1.1.b","en":"Replacement-Reason No.6 Per Management","cn":"æ›´æ¢åŸå› 6ï¼šç®¡ç†å±‚å†³å®š"},
    {"code":"1.1.b","en":"Replacement-Reason No.7 DOA/Refuse Repair","cn":"åˆ°è´§å³æŸ/æ‹’ä¿®"},
    {"code":"1.1.b","en":"Replacement-Reason No.3 Too much costy","cn":"è´¹ç”¨è¿‡é«˜"},
    {"code":"1.1.6","en":"Iced Up(cooling fine)","cn":"ç»“å†°ï¼ˆåˆ¶å†·æ­£å¸¸ï¼‰"},
    {"code":"1.1.b","en":"Replacement-Reason No.4 Too many attempts","cn":"å°è¯•æ¬¡æ•°è¿‡å¤š"},
    {"code":"1.1.1.8","en":"CO2 Distributor","cn":"COâ‚‚ åˆ†é…å™¨"},
    {"code":"1.1.b","en":"Replacement-Reason No.1 No tech in 75 miles","cn":"75è‹±é‡Œå†…æ— æŠ€å¸ˆ"},
    {"code":"1.1.3.4","en":"Evap Coil/Evap Drain Ice Up","cn":"è’¸å‘å™¨çº¿åœˆ/æ’æ°´ç»“å†°"},
    {"code":"1.1.1.10","en":"Bracket,Right,Chopping Board","cn":"ç §æ¿å³æ”¯æ¶"},
    {"code":"1.1.1.11","en":"Chopping Board","cn":"ç §æ¿"},
    {"code":"1.1.11.7","en":"Bracket,Right,Chopping Board","cn":"ç §æ¿å³æ”¯æ¶"},
]

MODEL_CATEGORY_MAP = {
    "MBF":"å†°ç®±","MCF":"é™ˆåˆ—æŸœ","MSF":"æ²™æ‹‰å°","MGF":"å·¥ä½œå°","MPF":"ç»ç’ƒå°","CHEF BASE":"æŠ½å±‰å·¥ä½œå°",
    "MBC":"æ»‘ç›–å†·è—æŸœ","MBB":"å§å¼å§å°","SBB":"ç§»é—¨å§å°","MKC":"å•¤é…’æŸœ","MBGF":"æ»‘ç›–å†·å†»æŸœ",
    "AMC":"ç‰›å¥¶æŸœ","RDCS":"æ–¹å½¢å±•ç¤ºæŸœ","CRDC":"å¼§å½¢å±•ç¤ºæŸœ","CRDS":"å°é¢æ–¹å½¢å±•ç¤ºæŸœ","ATHOM":"é¥®æ–™æŸœ",
    "AOM":"ç«‹å¼é¥®æ–™æŸœ","MSCT":"é…æ–™å°",
}
MODEL_ORDER = ["åˆè®¡","MBF","MCF","MSF","MGF","MPF","CHEF BASE","MBC","MBB","SBB","MKC","MBGF","AMC","RDCS","CRDC","CRDS","ATHOM","AOM","MSCT"]
ALIASES = {"CHEFBASE":"CHEF BASE","CHEF-BASE":"CHEF BASE","CHEF_BASE":"CHEF BASE","CHEF BASE":"CHEF BASE"}

YEARS_FIXED = list(range(2025, 2031))
STORE_PARQUET = Path("data_store.parquet")
STORE_CSV     = Path("data_store.csv")
TARGETS_JSON  = Path("targets_config.json")
MODEL_FLEET_JSON  = Path("model_fleet_counts.json")
RAW_EXCEL_STORE = Path("raw_excel_store.parquet")

# ============== æ•°æ®/æ–‡ä»¶å­˜å– ==============
def _load_raw_excel_store() -> pd.DataFrame:
    if RAW_EXCEL_STORE.exists():
        try:
            return pd.read_parquet(RAW_EXCEL_STORE)
        except Exception:
            try:
                return pd.read_csv(RAW_EXCEL_STORE.with_suffix(".csv"), dtype=str)
            except Exception:
                pass
    return pd.DataFrame()

def _save_raw_excel_store(df: pd.DataFrame):
    try:
        df.to_parquet(RAW_EXCEL_STORE, index=False)
    except Exception:
        df.to_csv(RAW_EXCEL_STORE.with_suffix(".csv"), index=False, encoding="utf-8-sig")

def load_store_df()->pd.DataFrame:
    if STORE_PARQUET.exists():
        try: return pd.read_parquet(STORE_PARQUET)
        except Exception: pass
    if STORE_CSV.exists():
        try: return pd.read_csv(STORE_CSV)
        except Exception: pass
    return pd.DataFrame()

def save_store_df(df: pd.DataFrame):
    try: df.to_parquet(STORE_PARQUET, index=False)
    except Exception: df.to_csv(STORE_CSV, index=False, encoding="utf-8-sig")

def load_targets()->dict:
    if TARGETS_JSON.exists():
        try: return json.loads(TARGETS_JSON.read_text(encoding="utf-8"))
        except Exception: pass
    return {"target_year_rate":5.0,"q1_t":0.0,"q2_t":0.0,"q3_t":0.0,"q4_t":0.0,"year_t":5.0}

def save_targets(cfg: dict):
    try: TARGETS_JSON.write_text(json.dumps(cfg, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception: pass

def load_model_fleet()->dict:
    if MODEL_FLEET_JSON.exists():
        try: return json.loads(MODEL_FLEET_JSON.read_text(encoding="utf-8"))
        except Exception: pass
    return {}

def save_model_fleet(d: dict):
    try: MODEL_FLEET_JSON.write_text(json.dumps(d, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception: pass

def ensure_fleet_month(fleet: dict, year: int, month: int)->dict:
    y, m = str(year), str(month)
    fleet.setdefault(y, {})
    fleet[y].setdefault(m, {k:0 for k in MODEL_ORDER if k!="åˆè®¡"})
    return fleet

def get_fleet_month(fleet: dict, year: int, month: int)->dict:
    y, m = str(year), str(month)
    return {k:int(fleet.get(y,{}).get(m,{}).get(k,0)) for k in MODEL_ORDER if k!="åˆè®¡"}

def set_fleet_month(fleet: dict, year: int, month: int, updates: dict)->dict:
    fleet = ensure_fleet_month(fleet, year, month)
    y, m = str(year), str(month)
    for mdl, v in updates.items():
        if mdl in MODEL_CATEGORY_MAP:
            fleet[y][m][mdl] = int(max(0, v))
    return fleet

# ============== å­—æ®µ/è§£æè¾…åŠ© ==============
CATEGORY_SCHEMA = {
    "è´¨é‡é—®é¢˜": ["Atosa"],
    "éè´¨é‡é—®é¢˜": ["åˆè®¡","é‡å¤/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","æ¹¿åº¦å¤§/ä½¿ç”¨é”™è¯¯","ç»´ä¿®å·¥æœªå‘ç°é—®é¢˜","å®‰è£…é—®é¢˜/ä»“åº“ç»´ä¿®","è„å µ/æ’æ°´ç®¡å µ"],
    "å‡ºä¿": ["åªå¯„é…ä»¶"],
    "å¾…å®š": ["æœªæ”¶åˆ°è´¦å•/å…¶ä»–äººä»˜æ¬¾"]
}
KEYWORD_RULES = [
    {"patterns":[r"1\.1\.a"],"cat1":"è´¨é‡é—®é¢˜","cat2":"Atosa","paidqty":1,"iswarranty":True},
    {"patterns":[r"\batosa\b"],"cat1":"è´¨é‡é—®é¢˜","cat2":"Atosa","paidqty":1,"iswarranty":True},
    {"patterns":[r"(?<!\d)1\.2(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"é‡å¤/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.4\.2(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"é‡å¤/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.4\.1(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"é‡å¤/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.4\.8(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"æ¹¿åº¦å¤§/ä½¿ç”¨é”™è¯¯","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.4\.5(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"æ¹¿åº¦å¤§/ä½¿ç”¨é”™è¯¯","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.4\.7(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"ç»´ä¿®å·¥æœªå‘ç°é—®é¢˜","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.4\.3(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"å®‰è£…é—®é¢˜/ä»“åº“ç»´ä¿®","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?:\b1\W*)?repair(?:ing)?\s+in\s+(?:the\s+)?warehouse(?:s)?\.?"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"å®‰è£…é—®é¢˜/ä»“åº“ç»´ä¿®","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.4\.6(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"è„å µ/æ’æ°´ç®¡å µ","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.4\.4(?!\d)"],"cat1":"éè´¨é‡é—®é¢˜","cat2":"è„å µ/æ’æ°´ç®¡å µ","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.3(?!\d)"],"cat1":"å‡ºä¿","cat2":"åªå¯„é…ä»¶","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.5\.1(?!\d)"],"cat1":"å¾…å®š","cat2":"æœªæ”¶åˆ°è´¦å•/å…¶ä»–äººä»˜æ¬¾","paidqty":0,"iswarranty":False},
    {"patterns":[r"(?<!\d)1\.5\.2(?!\d)"],"cat1":"å¾…å®š","cat2":"æœªæ”¶åˆ°è´¦å•/å…¶ä»–äººä»˜æ¬¾","paidqty":0,"iswarranty":False},
]
TEXT_COLUMNS_FOR_MATCH = [
    "TAG1","TAG2","TAG3","TAG4","Category1","Category2",
    "é—®é¢˜æè¿°","æè¿°","åŸå› ","å¤‡æ³¨","çŠ¶æ€","æ ‡é¢˜","Summary","Notes",
    "ç¼–ç ","Code","DefectCode","é—®é¢˜","Problem"
]

def fmt_money(x):
    try: return f"${x:,.0f}"
    except Exception: return "$0"

def _clean_text(s: str)->str:
    s = ("" if pd.isna(s) else str(s)).lower().replace("\u3000", " ")
    s = re.sub(r"[\s\-_\/]+", " ", s)
    return s.strip()

_MMYYYY_ANY = re.compile(r'(?:^|\D)(?P<mm>0[1-9]|1[0-2])(?P<yyyy>20\d{2})(?:\D|$)')

def _extract_year_month(df: pd.DataFrame, date_col_name: str=None):
    if df.empty: return
    if date_col_name is None or date_col_name not in df.columns:
        date_col_name = df.columns[0]
    s = df[date_col_name].astype(str)
    m = s.str.extract(_MMYYYY_ANY)
    mm = pd.to_numeric(m["mm"], errors="coerce").astype("Int64")
    yy = pd.to_numeric(m["yyyy"], errors="coerce").astype("Int64")
    mm = mm.where((mm>=1)&(mm<=12), pd.NA)
    df["_SrcYM"] = (m["mm"].fillna("") + m["yyyy"].fillna("")).where(m["mm"].notna(), "")
    df["Year"] = yy
    df["Month"]= mm
    df["Date"] = pd.to_datetime(dict(year=yy.astype("float"), month=mm.astype("float"), day=1), errors="coerce")
    q = pd.Series(pd.NA, index=df.index, dtype="Int64")
    ok = df["Month"].notna()
    q.loc[ok] = ((df.loc[ok,"Month"].astype(int)-1)//3+1).astype("Int64")
    df["Quarter"]= q

def ensure_cols(df: pd.DataFrame, date_col_name: str=None)->pd.DataFrame:
    if df.empty:
        return pd.DataFrame(columns=["Date","Category1","Category2","TAG1","TAG2","TAG3","TAG4","CostUSD","PaidQty","IsWarranty","Completed","Year","Month","Quarter","_SrcYM"])
    mapping = {}
    for c in df.columns:
        lc = str(c).strip().lower()
        if lc in ["æ—¥æœŸ","date","created_at","å‘ç”Ÿæ—¥æœŸ","ç”Ÿäº§æ—¥æœŸ"]: mapping[c] = "Date"
        elif lc in ["åˆ†ç±»1","category1","å¤§ç±»"]: mapping[c] = "Category1"
        elif lc in ["åˆ†ç±»2","category2","å°ç±»"]: mapping[c] = "Category2"
        elif lc in ["tag1","tag 1","tag-1"]: mapping[c] = "TAG1"
        elif lc in ["tag2","tag 2","tag-2"]: mapping[c] = "TAG2"
        elif lc in ["tag3","tag 3","tag-3"]: mapping[c] = "TAG3"
        elif lc in ["tag4","tag 4","tag-4"]: mapping[c] = "TAG4"
        elif lc in ["cost","costusd","amount","amount_usd","è´¹ç”¨","é‡‘é¢","fee","cost(usd)","cost usd"]: mapping[c] = "CostUSD"
        elif lc in ["å·²ä»˜æ¬¾æ•°é‡","paidqty","paid_qty"]: mapping[c] = "PaidQty"
        elif lc in ["æ˜¯å¦æ‰¿ä¿","iswarranty","warranty"]: mapping[c] = "IsWarranty"
        elif lc in ["æ˜¯å¦å®Œæˆ","completed","iscompleted","ç»´ä¿®çŠ¶æ€","çŠ¶æ€"]: mapping[c] = "Completed"
    if mapping: df = df.rename(columns=mapping)
    if df.columns.duplicated().any():
       df = df.loc[:, ~df.columns.duplicated(keep="first")]
    for i in range(1,5):
        std = f"TAG{i}"
        if std not in df.columns:
            cand = [c for c in df.columns if re.fullmatch(rf"\s*tag[\s_-]*{i}\s*", str(c), flags=re.I)]
            if cand: df.rename(columns={cand[0]: std}, inplace=True)
    for col, default in [("Category1",""),("Category2",""),("TAG1",""),("TAG2",""),("TAG3",""),("TAG4",""),("CostUSD",0.0),("PaidQty",0),("IsWarranty",False),("Completed",False)]:
        if col not in df.columns: df[col] = default
    df["CostUSD"] = pd.to_numeric(df["CostUSD"], errors="coerce").fillna(0.0)
    df["PaidQty"] = pd.to_numeric(df["PaidQty"], errors="coerce").fillna(0).astype(int)
    if df["Completed"].dtype == object:
        df["Completed"] = df["Completed"].astype(str).str.contains(r"complete|å·²å®Œæˆ|1", case=False, na=False)
    else:
        df["Completed"] = df["Completed"].astype(bool)
    df["IsWarranty"] = df["IsWarranty"].astype(bool)
    need_parse = ("Year" not in df.columns) or ("Month" not in df.columns) or (pd.isna(pd.to_numeric(df.get("Year"), errors="coerce")).all()) or (pd.isna(pd.to_numeric(df.get("Month"), errors="coerce")).all())
    if need_parse: _extract_year_month(df, date_col_name)
    df = apply_keyword_overrides(df)
    return df

def apply_keyword_overrides(df: pd.DataFrame)->pd.DataFrame:
    if df.empty: return df
    joined_all = df.astype(str).agg(" ".join, axis=1).map(_clean_text)
    assigned = pd.Series(False, index=df.index)
    for rule in KEYWORD_RULES:
        pats = [re.compile(p, re.I) for p in rule["patterns"]]
        mask = ~assigned
        for p in pats: mask &= joined_all.str.contains(p)
        if mask.any():
            df.loc[mask,"Category1"] = rule["cat1"]
            df.loc[mask,"Category2"] = rule["cat2"]
            if "paidqty" in rule: df.loc[mask,"PaidQty"] = int(rule["paidqty"])
            if "iswarranty" in rule: df.loc[mask,"IsWarranty"] = bool(rule["iswarranty"])
            assigned |= mask
    return df

def compute_category_stats(df_year: pd.DataFrame):
    stats = {}
    if not df_year.empty:
        tmp = df_year.copy()
        tmp["_paid_flag"] = (pd.to_numeric(tmp["CostUSD"], errors="coerce").fillna(0)>0).astype(int)
        g = tmp.groupby(["Category1","Category2"], dropna=False).agg(æ•°é‡=("CostUSD","size"),è´¹ç”¨=("CostUSD","sum"),å·²ä»˜æ¬¾æ•°é‡=("_paid_flag","sum"))
        g["å¹³å‡è´¹ç”¨"] = g.apply(lambda r: (r["è´¹ç”¨"]/r["å·²ä»˜æ¬¾æ•°é‡"]) if r["å·²ä»˜æ¬¾æ•°é‡"]>0 else 0.0, axis=1)
        for (c1,c2), r in g.iterrows():
            stats[(str(c1),str(c2))] = (int(r["æ•°é‡"]), float(r["è´¹ç”¨"]), int(r["å·²ä»˜æ¬¾æ•°é‡"]), float(r["å¹³å‡è´¹ç”¨"]))
    _nonq = ["é‡å¤/å®¢æˆ·å–æ¶ˆ/è”ç³»ä¸åˆ°å®¢æˆ·","æ¹¿åº¦å¤§/ä½¿ç”¨é”™è¯¯","ç»´ä¿®å·¥æœªå‘ç°é—®é¢˜","å®‰è£…é—®é¢˜/ä»“åº“ç»´ä¿®","è„å µ/æ’æ°´ç®¡å µ"]
    _big = "éè´¨é‡é—®é¢˜"; _q=_f=_p=0
    for s in _nonq:
        q,f,p,_ = stats.get((_big,s),(0,0.0,0,0.0))
        _q+=q; _f+=f; _p+=p
    _avg = (_f/_p) if _p>0 else 0.0
    stats[(_big,"åˆè®¡")] = (_q,_f,_p,_avg)
    for big, subs in CATEGORY_SCHEMA.items():
        for sub in subs:
            stats.setdefault((big,sub),(0,0.0,0,0.0))
    return stats

def render_category_table_html(stats: dict)->str:
    if not isinstance(stats, dict):
        stats = {}
    for big, subs in CATEGORY_SCHEMA.items():
        for sub in subs:
            stats.setdefault((big, sub), (0, 0.0, 0, 0.0))
    BG, HEAD_BG = "#0b1534", "#0a1a55"
    ROW_ALT, TEXT, SUBTEXT = "rgba(255,255,255,.03)", "#e8edf7", "#c8d0e8"
    BORDER, BORDER_SOFT, HILITE_BG = "rgba(255,255,255,.14)", "rgba(255,255,255,.10)", "rgba(255,255,255,.05)"
    th = """
    <thead><tr>
      <th style="text-align:left;">åˆ†ç±»1</th>
      <th style="text-align:left;">åˆ†ç±»2</th>
      <th style="text-align:right;">æ•°é‡</th>
      <th style="text-align:right;">è´¹ç”¨</th>
      <th style="text-align:right;">å·²ä»˜æ¬¾æ•°é‡</th>
      <th style="text-align:right;">å¹³å‡è´¹ç”¨</th>
    </tr></thead>"""
    rows_html = []
    for big, subs in CATEGORY_SCHEMA.items():
        rowspan = len(subs); first = True
        for sub in subs:
            qty, fee, paid, avg = stats.get((big, sub), (0, 0.0, 0, 0.0))
            tr = "<tr>"
            if first:
                tr += f'<td rowspan="{rowspan}" class="td-big"><b>{big}</b></td>'
                first = False
            if (big == "éè´¨é‡é—®é¢˜" and sub == "åˆè®¡"):
                tr += (
                    f'<td class="td-strong">{sub}</td>'
                    f'<td class="td-num td-strong">{qty}</td>'
                    f'<td class="td-num td-strong">{fmt_money(fee)}</td>'
                    f'<td class="td-num td-strong">{paid}</td>'
                    f'<td class="td-num td-strong">{fmt_money(avg)}</td>'
                )
            else:
                tr += (
                    f"<td>{sub}</td>"
                    f'<td class="td-num">{qty}</td>'
                    f'<td class="td-num">{fmt_money(fee)}</td>'
                    f'<td class="td-num">{paid}</td>'
                    f'<td class="td-num">{fmt_money(avg)}</td>'
                )
            tr += "</tr>"
            rows_html.append(tr)
    styles = f"""
    <style>
      .tbl-wrap {{ background:{BG}; border:1px solid {BORDER}; border-radius:14px; overflow:hidden; box-shadow: 0 4px 14px rgba(0,0,0,.3); }}
      table.tbl {{ width:100%; border-collapse:separate; border-spacing:0; font-size:14px; color:{TEXT}; }}
      .tbl thead th {{ background:{HEAD_BG}; color:{TEXT}; padding:10px 12px; border-bottom:1px solid {BORDER}; font-weight:700; white-space:nowrap; }}
      .tbl tbody td {{ padding:9px 12px; border-bottom:1px solid {BORDER_SOFT}; color:{SUBTEXT}; background:transparent; }}
      .tbl tbody tr:nth-child(even) td {{ background:{ROW_ALT}; }}
      .tbl .td-num {{ text-align:right; color:{TEXT}; }}
      .tbl .td-big {{ vertical-align:top; border-right:1px solid {BORDER}; color:{TEXT}; background:rgba(255,255,255,.02); min-width:120px; }}
      .tbl .td-strong {{ color:{TEXT}; background:{HILITE_BG}; font-weight:700; }}
    </style>
    """
    html = f"""{styles}<div class="tbl-wrap"><table class="tbl">{th}<tbody>{''.join(rows_html)}</tbody></table></div>"""
    return html

def build_monthly_numeric(df_year: pd.DataFrame, fleet_all: dict, current_year: int)->pd.DataFrame:
    months = range(1, 12+1)
    joined_year = (pd.Series(dtype=str) if df_year.empty else
                   df_year.astype(str).agg(" ".join, axis=1).map(_clean_text))

    rows = {
        "æœˆåº¦ç»´ä¿®é‡": [],
        "æœˆåº¦è´¨é‡ç»´ä¿®é‡": [],
        "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰": [],
        "æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰": [],
        "æœˆåº¦ä¿å†…æ•°é‡": [],
        "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%": [],
        # ğŸ‘‡ æ–°å¢ä¸¤è¡Œï¼šæŒ‰åˆ†ç±»å£å¾„çš„æœˆåº¦è´¹ç”¨ä¸å·²ä»˜æ¬¾æ•°é‡ï¼ˆä»…ç”¨äºåç»­å­£åº¦åŠ æƒï¼‰
        "æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰": [],
        "æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰": [],
    }

    pat_11a  = re.compile(r"(?<![0-9a-z])1\.1\.a(?![0-9a-z])", re.I)
    pat_113x = re.compile(r"(?<![0-9a-z])1\.1\.3\.\d+(?![0-9a-z])", re.I)

    for m in months:
        if df_year.empty:
            total = 0
            quality_cnt = 0
            fees4 = 0.0
            paid4 = 0
        else:
            dfm = df_year[df_year["Month"] == m]

            # 1) æœˆåº¦æ€»å•é‡
            total = len(dfm)

            # 2) â€œè´¨é‡ç»´ä¿®é‡â€ä¸ä¿å†…å£å¾„ï¼Œä¸åŸé€»è¾‘ä¸€è‡´
            if total > 0:
                cat_quality = dfm["Category1"].astype(str).eq("è´¨é‡é—®é¢˜")
                text_block  = joined_year.loc[dfm.index]
                text_hits   = text_block.str.contains(pat_11a, na=False) | text_block.str.contains(pat_113x, na=False)
                quality_cnt = int((cat_quality | text_hits).sum())
            else:
                quality_cnt = 0

            # 3) **å…³é”®**ï¼šæŒ‰åˆ†ç±»å£å¾„å–å½“æœˆè´¹ç”¨ä¸å·²ä»˜æ¬¾æ•°é‡
            #    å£å¾„ = (è´¨é‡é—®é¢˜,Atosa) + (éè´¨é‡é—®é¢˜,åˆè®¡) + (å‡ºä¿,åªå¯„é…ä»¶) + (å¾…å®š,æœªæ”¶åˆ°è´¦å•/å…¶ä»–äººä»˜æ¬¾)
            stats_m = compute_category_stats(dfm)
            def _pick(c1, c2):
                # è¿”å› (æ•°é‡, è´¹ç”¨, å·²ä»˜æ¬¾æ•°é‡, å¹³å‡è´¹ç”¨)
                return stats_m.get((c1, c2), (0, 0.0, 0, 0.0))
            _, fee_atosa,      paid_atosa,      _ = _pick("è´¨é‡é—®é¢˜", "Atosa")
            _, fee_nonq_sum,   paid_nonq_sum,   _ = _pick("éè´¨é‡é—®é¢˜", "åˆè®¡")
            _, fee_out,        paid_out,        _ = _pick("å‡ºä¿", "åªå¯„é…ä»¶")
            _, fee_pending,    paid_pending,    _ = _pick("å¾…å®š", "æœªæ”¶åˆ°è´¦å•/å…¶ä»–äººä»˜æ¬¾")

            fees4 = float(fee_atosa + fee_nonq_sum + fee_out + fee_pending)
            paid4 = int(paid_atosa + paid_nonq_sum + paid_out + paid_pending)

        # 4) å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰= è¿™å››ç±»çš„ è´¹ç”¨ / å·²ä»˜æ¬¾æ•°é‡ï¼ˆåŠ æƒå¹³å‡çš„åˆ†å­åˆ†æ¯ï¼‰
        avg_cost = (fees4 / paid4) if paid4 > 0 else 0.0

        # 5) ä¿å†…æ•°é‡ & é¢„ä¼°ä¿å†…è´¹ç”¨ï¼ˆä¿æŒä½ ç°æœ‰å£å¾„ï¼‰
        month_fleet = get_fleet_month(fleet_all, int(current_year), int(m))
        warranty_cnt = int(sum(month_fleet.values()))
        est_cost = avg_cost * quality_cnt
        rate_pct = (quality_cnt / warranty_cnt * 100.0) if warranty_cnt > 0 else 0.0

        # â€”â€” å†™è¡Œ
        rows["æœˆåº¦ç»´ä¿®é‡"].append(total)
        rows["æœˆåº¦è´¨é‡ç»´ä¿®é‡"].append(quality_cnt)
        rows["å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"].append(avg_cost)
        rows["æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"].append(est_cost)
        rows["æœˆåº¦ä¿å†…æ•°é‡"].append(warranty_cnt)
        rows["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"].append(rate_pct)
        rows["æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰"].append(fees4)           # æ–°å¢éšè—è¡Œï¼ˆæ•°å€¼ï¼‰
        rows["æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰"].append(paid4)       # æ–°å¢éšè—è¡Œï¼ˆæ•°å€¼ï¼‰

    pv = pd.DataFrame(rows).T
    pv = pv.reindex([
        "æœˆåº¦ç»´ä¿®é‡",
        "æœˆåº¦è´¨é‡ç»´ä¿®é‡",
        "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰",
        "æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰",
        "æœˆåº¦ä¿å†…æ•°é‡",
        "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%",
        "æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰",             # æ”¾åœ¨æœ«å°¾ï¼Œä¾›åç»­å­£åº¦åŠ æƒç”¨
        "æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰",
    ])
    pv.columns = [f"{m}æœˆ" for m in months]
    for c in pv.columns:
        pv[c] = pd.to_numeric(pv[c], errors="coerce").fillna(0)
    return pv


def build_monthly_display(pv_numeric: pd.DataFrame)->pd.DataFrame:
    pv = pv_numeric.copy()
    for r in ["å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰","æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"]:
        pv.loc[r] = pv.loc[r].map(fmt_money)
    pv.loc["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"] = pv.loc["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"].map(lambda x: f"{x:.2f}%")
    for r in ["æœˆåº¦ç»´ä¿®é‡","æœˆåº¦è´¨é‡ç»´ä¿®é‡","æœˆåº¦ä¿å†…æ•°é‡"]:
        pv.loc[r] = pv.loc[r].astype(int)
         # ğŸ‘‡ éšè—è¾…åŠ©è¡Œ
    pv = pv.drop(index=["æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰","æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰"], errors="ignore")
    return pv
    

def build_quarter_from_monthly(pv_numeric: pd.DataFrame, *, fleet_mode: str = "avg")->pd.DataFrame:
    q_cols = {
        "Q1": ["1æœˆ","2æœˆ","3æœˆ"],
        "Q2": ["4æœˆ","5æœˆ","6æœˆ"],
        "Q3": ["7æœˆ","8æœˆ","9æœˆ"],
        "Q4": ["10æœˆ","11æœˆ","12æœˆ"],
    }

    # å…ˆåšå¸¸è§„æ±‚å’Œï¼ˆç”¨äºé™¤â€œå¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰â€ä»¥å¤–çš„å¤§å¤šæ•°è¡Œï¼‰
    q_num = pd.DataFrame(index=pv_numeric.index, columns=list(q_cols.keys())+["å…¨å¹´"], dtype=float)
    for q, cols in q_cols.items():
        q_num[q] = pv_numeric[cols].sum(axis=1, numeric_only=True)
    q_num["å…¨å¹´"] = pv_numeric.sum(axis=1, numeric_only=True)

    # â€”â€” ç”¨éšè—è¡ŒåšåŠ æƒå¹³å‡ï¼šå¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰
    fee_row  = "æœˆåº¦è´¹ç”¨ï¼ˆåˆ†ç±»å£å¾„ï¼‰"
    paid_row = "æœˆåº¦å·²ä»˜æ¬¾æ•°é‡ï¼ˆåˆ†ç±»å£å¾„ï¼‰"
    avg_row  = "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"
    if fee_row in pv_numeric.index and paid_row in pv_numeric.index and avg_row in pv_numeric.index:
        for q, cols in q_cols.items():
            fees_q  = float(pv_numeric.loc[fee_row,  cols].sum())
            paid_q  = float(pv_numeric.loc[paid_row, cols].sum())
            q_num.loc[avg_row, q] = (fees_q / paid_q) if paid_q > 0 else 0.0
        fees_y = float(pv_numeric.loc[fee_row].sum())
        paid_y = float(pv_numeric.loc[paid_row].sum())
        q_num.loc[avg_row, "å…¨å¹´"] = (fees_y / paid_y) if paid_y > 0 else 0.0

    # è¡Œåé‡å‘½å
    rename = {
        "æœˆåº¦ç»´ä¿®é‡": "å­£åº¦ç»´ä¿®é‡",
        "æœˆåº¦è´¨é‡ç»´ä¿®é‡": "å­£åº¦è´¨é‡ç»´ä¿®é‡",
        "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰": "å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰",
        "æœˆåº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰": "å­£åº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰",
        "æœˆåº¦ä¿å†…æ•°é‡": "å­£åº¦ä¿å†…æ•°é‡",
        "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%": "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%",
        fee_row: fee_row,
        paid_row: paid_row,
    }
    q_num.index = [rename.get(i, i) for i in q_num.index]

    # âœ… å…³é”®ï¼šè®©â€œå­£åº¦ä¿å†…æ•°é‡â€æŒ‰å£å¾„åˆ‡æ¢ï¼ˆä¸å‹å·ç³»åˆ—ç»´åº¦ä¿æŒä¸€è‡´ï¼‰
    # fleet_mode = "avg" è¡¨ç¤ºç”¨ã€Œæœˆå‡åœ¨ä¿æ•°é‡ã€ï¼Œ"sum" è¡¨ç¤ºã€Œå­£åº¦åˆè®¡ã€
    if "å­£åº¦ä¿å†…æ•°é‡" in q_num.index and "æœˆåº¦ä¿å†…æ•°é‡" in pv_numeric.index:
        if fleet_mode.lower() == "avg":
            # æ¯ä¸ªå­£åº¦ = å½“å­£ 3 ä¸ªæœˆâ€œæœˆåº¦ä¿å†…æ•°é‡â€çš„å¹³å‡ï¼›å…¨å¹´ = 12 ä¸ªæœˆå¹³å‡
            for q, cols in q_cols.items():
                q_num.loc["å­£åº¦ä¿å†…æ•°é‡", q] = float(pv_numeric.loc["æœˆåº¦ä¿å†…æ•°é‡", cols].mean())
            q_num.loc["å­£åº¦ä¿å†…æ•°é‡", "å…¨å¹´"] = float(pv_numeric.loc["æœˆåº¦ä¿å†…æ•°é‡"].mean())
        else:
            # é»˜è®¤ä¿ç•™åŸåˆè®¡å£å¾„ï¼ˆå·²ç»åœ¨å‰é¢ç”¨ sum ç®—è¿‡ï¼Œä¸éœ€è¦æ”¹ï¼‰
            pass

    # â€”â€” ç”Ÿæˆå±•ç¤ºç”¨å‰¯æœ¬ï¼ˆéšè—è¾…åŠ©è¡Œ & ç¾åŒ–ï¼‰
    q_show = q_num.copy()
    for r in ["å¹³å‡ç»´ä¿®å•è´¹ç”¨ï¼ˆç¾å…ƒï¼‰", "å­£åº¦é¢„ä¼°ä¿å†…ç»´ä¿®è´¹ç”¨ï¼ˆç¾å…ƒï¼‰"]:
        if r in q_show.index:
            q_show.loc[r] = q_show.loc[r].map(lambda v: f"${v:,.0f}")
    if "æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%" in q_show.index:
        q_show.loc["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"] = q_show.loc["æŠ˜ç®—ä¿å†…ç»´ä¿®ç‡%"].map(lambda v: f"{float(v):.2f}%")
    for r in ["å­£åº¦ç»´ä¿®é‡", "å­£åº¦è´¨é‡ç»´ä¿®é‡", "å­£åº¦ä¿å†…æ•°é‡"]:
        if r in q_show.index:
            q_show.loc[r] = q_show.loc[r].astype(int)

    q_show = q_show.drop(index=[rename[fee_row], rename[paid_row]], errors="ignore")
    return q_show



# ============== ä¾§æ ï¼ˆä¸Šä¼ /æ¸…ç©º/ç›®æ ‡ï¼‰ ==============
with st.sidebar:
    up = st.file_uploader("ä¸Šä¼ æ•°æ®ï¼ˆCSV/XLSXï¼‰", type=["csv","xlsx","xls"])

    def _read_any(up_file):
        if up_file is None: return pd.DataFrame()
        name = up_file.name.lower()
        try:
            if name.endswith((".xlsx",".xls")):
                df0 = pd.read_excel(up_file, sheet_name=0, header=0, dtype=str)
            else:
                df0 = pd.read_csv(up_file, dtype=str, encoding="utf-8-sig")
        except UnicodeDecodeError:
            df0 = pd.read_csv(up_file, dtype=str, encoding="gbk", errors="ignore")
        except Exception as e:
            st.error(f"è¯»å–å¤±è´¥ï¼š{e}"); return pd.DataFrame()
        return df0

    df_raw = _read_any(up)

    # â€”â€” åŸå§‹ Excel å†å²ï¼ˆç´¯ç§¯ä¿å­˜ï¼‰
    raw_store = _load_raw_excel_store()
    if "excel_raw_history" not in st.session_state:
        st.session_state["excel_raw_history"] = raw_store.copy()
    if not df_raw.empty:
        df_raw_add = df_raw.copy()
        df_raw_add["__SourceFile"] = getattr(up, "name", "") if up is not None else ""
        df_raw_add["__ImportedAt"] = pd.Timestamp.now(tz=None)
        st.session_state["excel_raw_history"] = pd.concat(
            [st.session_state["excel_raw_history"], df_raw_add], ignore_index=True
        )
        _save_raw_excel_store(st.session_state["excel_raw_history"])

    date_col_name = (list(df_raw.columns)[0] if not df_raw.empty else None)
    st.session_state["date_col_name"] = date_col_name
    df = ensure_cols(df_raw, date_col_name=date_col_name)

    def _bytes_md5(b: bytes)->str:
        h=hashlib.md5(); h.update(b); return h.hexdigest()
    upload_md5=None
    if up is not None:
        try: upload_md5=_bytes_md5(up.getvalue())
        except Exception: upload_md5=None
    is_new_upload=False
    if upload_md5:
        last_md5=st.session_state.get("_last_upload_md5")
        if last_md5!=upload_md5:
            is_new_upload=True
            st.session_state["_last_upload_md5"]=upload_md5

    persisted_file = ensure_cols(load_store_df())

    # ç»™å½“å‰ä¸Šä¼ çš„æ ‡å‡†åŒ–æ•°æ®æ‰“ä¸Šæ¥æº
    if not df.empty:
        df = df.copy()
        df["SourceFile"] = getattr(up, "name", "") if up is not None else ""
        df["ImportedAt"] = pd.Timestamp.now(tz=None)

    merge_mode = "ä»…è¿½åŠ ï¼ˆä¸å»é‡ï¼‰"
    st.caption("åˆå¹¶ç­–ç•¥ï¼šä»…è¿½åŠ ï¼ˆä¸å»é‡ï¼‰")

    if is_new_upload and not df.empty:
        merged = ensure_cols(pd.concat([persisted_file, df], ignore_index=True))
        save_store_df(merged)
        persisted = merged
    else:
        persisted = persisted_file

    st.session_state["store_df"] = ensure_cols(persisted.copy())
    st.caption(f"å·²å­˜æ•°æ®é‡ï¼š{len(st.session_state['store_df'])} æ¡ï¼ˆåˆå¹¶ç­–ç•¥ï¼š{merge_mode}ï¼‰")

    if not st.session_state["store_df"].empty:
        tmp=st.session_state["store_df"].copy()
        tmp["Year"]=pd.to_numeric(tmp["Year"], errors="coerce")
        tmp["Month"]=pd.to_numeric(tmp["Month"], errors="coerce")
        ym_count=(tmp.dropna(subset=["Year","Month"]).astype({"Year":int,"Month":int})
                  .groupby(["Year","Month"]).size().reset_index(name="æ•°é‡").sort_values(["Year","Month"]))
        with st.expander("ğŸ“Š Year/Month æ•°é‡åˆ†å¸ƒï¼ˆé»˜è®¤æ”¶èµ·ï¼‰", expanded=False):
            st.dataframe(ym_count, use_container_width=True, height=200)

    df_all_ss = st.session_state.get("store_df", pd.DataFrame())
    years=YEARS_FIXED[:]
    if not df_all_ss.empty:
        _yy=pd.to_numeric(df_all_ss.get("Year", pd.Series(dtype="Int64")), errors="coerce")
        present_years=sorted(set(int(y) for y in _yy.dropna().astype(int).tolist() if y in years))
    else:
        present_years=[]
    default_year=(max(present_years) if present_years else 2025)
    default_year_idx=years.index(default_year)

    if not df_all_ss.empty:
        _yy2=pd.to_numeric(df_all_ss.get("Year", pd.Series(dtype="Int64")), errors="coerce")
        _mm2=pd.to_numeric(df_all_ss.get("Month", pd.Series(dtype="Int64")), errors="coerce")
        months_in_default=sorted(_mm2[(_yy2==default_year)].dropna().astype(int).unique().tolist())
    else:
        months_in_default=[]
    default_month=(max(months_in_default) if months_in_default else 1)
    default_month_idx=default_month-1

    # å¹´ä»½é€‰æ‹©
    year = st.selectbox("é€‰æ‹©å¹´ä»½", years, index=default_year_idx)

    # â€”â€” æœˆä»½/å­£åº¦äºŒåˆä¸€é€‰é¡¹
    PERIOD_OPTIONS = (
        [{"type": "M", "months": [m], "label": f"{m:02d}æœˆ"} for m in range(1, 13)]
        + [
            {"type": "Q", "months": [1, 2, 3],   "label": "ä¸€å­£åº¦ (01â€“03)"},
            {"type": "Q", "months": [4, 5, 6],   "label": "äºŒå­£åº¦ (04â€“06)"},
            {"type": "Q", "months": [7, 8, 9],   "label": "ä¸‰å­£åº¦ (07â€“09)"},
            {"type": "Q", "months": [10, 11, 12],"label": "å››å­£åº¦ (10â€“12)"},
        ]
    )
    _default_m = default_month if 1 <= default_month <= 12 else 1
    _default_label = f"{_default_m:02d}æœˆ"
    _default_idx = next((i for i, o in enumerate(PERIOD_OPTIONS) if o["label"] == _default_label), 0)

    period_sel = st.selectbox(
        "é€‰æ‹©æœˆä»½ / å­£åº¦",
        PERIOD_OPTIONS,
        index=_default_idx,
        format_func=lambda o: o["label"],
    )
    st.session_state["selected_period_months"] = period_sel["months"]
    st.session_state["selected_period_label"]  = period_sel["label"]
    st.session_state["selected_period_is_quarter"] = (period_sel["type"] == "Q")

    tcfg = load_targets()
    st.session_state.setdefault("target_year_rate", tcfg["target_year_rate"])
    st.session_state.setdefault("q1_t", tcfg["q1_t"])
    st.session_state.setdefault("q2_t", tcfg["q2_t"])
    st.session_state.setdefault("q3_t", tcfg["q3_t"])
    st.session_state.setdefault("q4_t", tcfg["q4_t"])
    st.session_state.setdefault("year_t", tcfg["year_t"])
    st.number_input("å¹´åº¦æ‰¿ä¿å†…ç»´ä¿®ç‡ç›®æ ‡ï¼ˆ%ï¼‰", 0.0, 100.0, float(st.session_state["target_year_rate"]), 0.5, key="target_year_rate")
    st.number_input("Q1 ç›®æ ‡ï¼ˆ%ï¼‰", 0.0, 100.0, float(st.session_state["q1_t"]), 0.5, key="q1_t")
    st.number_input("Q2 ç›®æ ‡ï¼ˆ%ï¼‰", 0.0, 100.0, float(st.session_state["q2_t"]), 0.5, key="q2_t")
    st.number_input("Q3 ç›®æ ‡ï¼ˆ%ï¼‰", 0.0, 100.0, float(st.session_state["q3_t"]), 0.5, key="q3_t")
    st.number_input("Q4 ç›®æ ‡ï¼ˆ%ï¼‰", 0.0, 100.0, float(st.session_state["q4_t"]), 0.5, key="q4_t")
    st.number_input("å…¨å¹´ç›®æ ‡ï¼ˆ%ï¼‰", 0.0, 100.0, float(st.session_state["year_t"]), 0.5, key="year_t")
    save_targets({"target_year_rate":st.session_state["target_year_rate"],"q1_t":st.session_state["q1_t"],"q2_t":st.session_state["q2_t"],"q3_t":st.session_state["q3_t"],"q4_t":st.session_state["q4_t"],"year_t":st.session_state["year_t"]})

    st.markdown("---")
    st.subheader("ğŸ§¹ æ•°æ®æ¸…ç©º")
    clear_mode = st.radio("é€‰æ‹©æ¸…ç©ºèŒƒå›´", ["æ¸…ç©ºæ‰€é€‰ å¹´ä»½+æœˆä»½","æ¸…ç©ºæ‰€é€‰ å¹´ä»½ï¼ˆæ•´å¹´ï¼‰","æ¸…ç©ºå…¨éƒ¨æ•°æ®","ä»…æ¸…ç©ºå¹´åº¦ç›®æ ‡é…ç½®"], index=0, help="æ¸…ç©ºåä¼šå†™å›æœ¬åœ° data_store.parquet/csvï¼›æ“ä½œä¸å¯æ’¤å›ã€‚")
    confirm = st.checkbox("æˆ‘å·²ç¡®è®¤è¦æ‰§è¡Œæ¸…ç©ºæ“ä½œ")
    if st.button("æ‰§è¡Œæ¸…ç©º", type="primary", use_container_width=True, disabled=not confirm):
        df_all = st.session_state.get("store_df", pd.DataFrame()).copy()
        if clear_mode=="ä»…æ¸…ç©ºå¹´åº¦ç›®æ ‡é…ç½®":
            save_targets({"target_year_rate":5.0,"q1_t":0.0,"q2_t":0.0,"q3_t":0.0,"q4_t":0.0,"year_t":5.0})
            for k,v in {"target_year_rate":5.0,"q1_t":0.0,"q2_t":0.0,"q3_t":0.0,"q4_t":0.0,"year_t":5.0}.items():
                st.session_state[k]=v
            st.success("å·²æ¸…ç©ºå¹´åº¦ç›®æ ‡é…ç½®ã€‚")
        else:
            if clear_mode=="æ¸…ç©ºå…¨éƒ¨æ•°æ®":
                df_all = pd.DataFrame(columns=ensure_cols(pd.DataFrame()).columns)
            elif clear_mode=="æ¸…ç©ºæ‰€é€‰ å¹´ä»½ï¼ˆæ•´å¹´ï¼‰":
                y_ser = pd.to_numeric(df_all.get("Year", pd.Series(dtype="Int64")), errors="coerce")
                df_all = df_all[~(y_ser==int(year))].reset_index(drop=True)
            elif clear_mode=="æ¸…ç©ºæ‰€é€‰ å¹´ä»½+æœˆä»½":
                y_ser = pd.to_numeric(df_all.get("Year"), errors="coerce")
                m_ser = pd.to_numeric(df_all.get("Month"), errors="coerce")
                months_to_clear = st.session_state.get("selected_period_months", [1])
                df_all = df_all[~((y_ser==int(year)) & (m_ser.isin(months_to_clear)))].reset_index(drop=True)
            save_store_df(ensure_cols(df_all))
            st.session_state["store_df"]=ensure_cols(df_all.copy())
            st.success("å·²å®Œæˆæ¸…ç©ºå¹¶ä¿å­˜ã€‚")

# ç»Ÿè®¡å£å¾„ï¼šåªçœ‹ 2025~2030
df_all = ensure_cols(st.session_state.get("store_df", pd.DataFrame())).copy()
st.session_state["store_df_ready"] = True
st.session_state["store_df"] = ensure_cols(df_all.copy())

if df_all.empty:
    st.info("å½“å‰æ²¡æœ‰ä»»ä½•å¯ç­›é€‰çš„æ•°æ®ã€‚è¯·å…ˆä¸Šä¼ ã€‚")
else:
    _year_series  = pd.to_numeric(df_all.get("Year",  pd.Series(dtype="Int64")), errors="coerce")
    mask_valid_year = _year_series.isin(YEARS_FIXED)
    df_all = df_all[mask_valid_year].reset_index(drop=True)

_year_series  = pd.to_numeric(df_all.get("Year",  pd.Series(dtype="Int64")), errors="coerce")
_month_series = pd.to_numeric(df_all.get("Month", pd.Series(dtype="Int64")), errors="coerce")

if not df_all.empty:
    with st.expander("ğŸ§ª è§£æè‡ªæ£€ï¼ˆé»˜è®¤æ”¶èµ·ï¼‰", expanded=False):
        valid = _year_series.notna() & _month_series.notna()
        st.write("æœ‰æ•ˆå¯ç­›é€‰çš„è¡Œæ•°ï¼š", int(valid.sum()))
        st.write("å½“å‰é€‰æ‹©ï¼ˆå¹´ä»½ä¼—æ•°ï¼‰ï¼š", f"{int(_year_series.mode().iloc[0]) if valid.any() else ''}")
        ym_dist = (pd.DataFrame({"Year": _year_series, "Month": _month_series})
                   .loc[(_year_series.notna()) & (_month_series.notna())]
                   .groupby(["Year","Month"]).size().reset_index(name="æ•°é‡").sort_values(["Year","Month"]))
        st.dataframe(ym_dist, use_container_width=True, height=180)

# ç»Ÿä¸€è¯»å–â€œæ‰€é€‰æœŸé—´â€ï¼ˆå¯èƒ½æ˜¯å•æœˆï¼Œä¹Ÿå¯èƒ½æ˜¯å­£åº¦ï¼‰
cur_year  = int(st.session_state.get("year", year) if isinstance(year, (int, np.integer)) else year)
_sel_months: List[int] = st.session_state.get("selected_period_months", [1])
_sel_label  = st.session_state.get("selected_period_label", f"{_sel_months[0]:02d}æœˆ")
_is_quarter = bool(st.session_state.get("selected_period_is_quarter", False))

# â€”â€” æœŸé—´æ•°æ®åˆ‡ç‰‡ï¼šYear å›ºå®šä¸ºæ‰€é€‰å¹´ä»½ï¼ŒMonth âˆˆ æ‰€é€‰åˆ—è¡¨
m_ser = pd.to_numeric(df_all.get("Month", pd.Series(dtype="Int64")), errors="coerce")
y_ser = pd.to_numeric(df_all.get("Year",  pd.Series(dtype="Int64")), errors="coerce")
df_period = df_all[(y_ser == cur_year) & (m_ser.isin(_sel_months))].copy()

# â€”â€” å•æœˆä¸Šä¸‹æ–‡ï¼ˆç”¨äºå½•å…¥/è°ƒè¯•/åŸå§‹æ˜ å°„ç­‰å•æœˆåœºæ™¯ï¼›å­£åº¦æ—¶å–æœŸé—´æœ€åä¸€æœˆï¼‰
edit_month = int(sorted(_sel_months)[-1])
cur_month = edit_month  # å…¼å®¹æ—§å˜é‡å

st.markdown(f"### åˆ†ç±»ç»Ÿè®¡ï¼ˆæŒ‰æ‰€é€‰æœŸé—´ï¼š{cur_year}å¹´ {_sel_label}ï¼‰")
if df_period.empty:
    st.warning("å½“å‰æ‰€é€‰æœŸé—´æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•æ•°æ®ã€‚å¯èƒ½åŸå› ï¼š1) å¹´ä»½ä¸åœ¨ 2025â€“2030ï¼›2) æ—¥æœŸåˆ—æ— æ³•è§£æï¼›3) æœ¬æœŸé—´ç¡®æ— è®°å½•ã€‚")
else:
    st.markdown(render_category_table_html(compute_category_stats(df_period)), unsafe_allow_html=True)

# å¹´åº¦è§†è§’
df_year_only = df_all[y_ser == cur_year]
st.markdown(f"### {cur_year}å¹´åº¦ç›®æ ‡ç»´ä¿®ç‡ä¸º{int(load_targets()['target_year_rate']):d}%")
fleet = load_model_fleet()

# æœˆåº¦æ•°å€¼è¡¨ï¼ˆå…¨å¹´ 1â€“12 æœˆï¼‰
pv_num  = build_monthly_numeric(df_year_only, fleet, int(cur_year))
pv_show = build_monthly_display(pv_num)
st.dataframe(pv_show, use_container_width=True)

# å­£åº¦ç»Ÿè®¡ï¼ˆæ•´å¹´ï¼‰
st.markdown("### å­£åº¦ç»Ÿè®¡æ•°æ®ï¼ˆæ•´å¹´ï¼‰")
q_show = build_quarter_from_monthly(pv_num, fleet_mode="avg")
st.dataframe(q_show, use_container_width=True)

# ============== å‹å·ç³»åˆ—ç»´åº¦ï¼ˆæŒ‰æœŸé—´åˆè®¡åœ¨ä¿æ•°é‡ï¼‰ ==============
def resolve_model_key(raw: str) -> str:
    s = (raw or "").strip().replace("\u3000", " ")
    s = re.sub(r"^\s*refrigeration\s*[-_:ï¼š/\\]\s*", "", s, flags=re.I)
    s_norm = re.sub(r"[\s\-_/]+", " ", s).strip()
    key_up = s_norm.upper().replace(" ", "")
    for k, v in ALIASES.items():
        if key_up == k.upper().replace(" ", ""):
            return v
    toks = s_norm.split()
    if len(toks) > 1:
        return " ".join(t.upper() for t in toks)
    return s_norm.upper()

def _parse_bulk_paste(txt: str)->dict:
    updates={}
    if not txt or not txt.strip(): return updates
    for line in txt.strip().splitlines():
        line=line.strip()
        if not line or re.search(r"(å‹å·|series|åœ¨ä¿|æ•°é‡|åˆè®¡)", line, re.I): continue
        parts=re.split(r"[\s,;ï¼Œã€\t]+", line)
        if not parts: continue
        mdl_raw,num_str=parts[0],None
        if len(parts)>=3 and parts[1].upper()=="BASE":
            mdl_raw=parts[0]+" "+parts[1]; num_str=parts[2]
        elif len(parts)>=2:
            num_str=parts[1]
        mdl=resolve_model_key(mdl_raw)
        if mdl not in MODEL_CATEGORY_MAP: continue
        try: val=int(float(str(num_str).replace(",","")))
        except Exception: continue
        updates[mdl]=max(0,val)
    return updates

st.markdown("### å‹å·ç³»åˆ—ç»´åº¦ï¼ˆæŒ‰åœ¨ä¿æ•°é‡å£å¾„ï¼‰")
with st.expander("ğŸ“ å½•å…¥ï¼šå„å‹å·åœ¨ä¿æ•°é‡ï¼ˆæŒ‰æœˆï¼‰", expanded=False):
    st.caption(f"å½“å‰ä½œç”¨å¹´æœˆï¼š{cur_year}-{int(edit_month):02d}ï¼ˆè‹¥é€‰æ‹©å­£åº¦ï¼Œè¿™é‡Œé»˜è®¤ä½¿ç”¨è¯¥æœŸé—´æœ€åä¸€ä¸ªæœˆï¼‰")
    tab1, tab2 = st.tabs(["æ‰¹é‡ç²˜è´´ï¼ˆæ¨èï¼‰","é€ä¸ªè¾“å…¥"])
    with tab1:
        sample="å‹å·ç³»åˆ—\tå½“æœˆåœ¨ä¿æ•°é‡\nMBF\t12345\nMCF\t23456\nMSF\t34567\nCHEF BASE\t4567\n..."
        txt=st.text_area("ä» Excel å¤åˆ¶ä¸¤åˆ—ï¼ˆå‹å·ç³»åˆ— + å½“æœˆåœ¨ä¿æ•°é‡ï¼‰åç²˜è´´åˆ°æ­¤å¤„ï¼š", height=180, placeholder=sample)
        col_l, col_r = st.columns([1,1])
        with col_l:
            if st.button("è§£æå¹¶å†™å…¥å½“æœˆåœ¨ä¿æ•°é‡", type="primary", use_container_width=True, key="btn_parse_fleet_month"):
                upd=_parse_bulk_paste(txt)
                if not upd:
                    st.warning("æ²¡æœ‰è§£æåˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ˜¯å¦ä¸ºä¸¤åˆ—ï¼ˆå‹å·ç³»åˆ— + å½“æœˆåœ¨ä¿æ•°é‡ï¼‰ã€‚")
                else:
                    fleet=set_fleet_month(fleet, int(cur_year), int(edit_month), upd)
                    save_model_fleet(fleet)
                    st.success(f"å·²å†™å…¥ {len(upd)} ä¸ªå‹å·çš„å½“æœˆåœ¨ä¿æ•°é‡ã€‚")
                    st.rerun()
        with col_r:
            month_fleet=get_fleet_month(fleet, int(cur_year), int(edit_month))
            preview=pd.DataFrame({
                "å‹å·ç³»åˆ—":[m for m in MODEL_ORDER if m!="åˆè®¡"],
                f"å½“æœˆåœ¨ä¿æ•°é‡ï¼ˆ{cur_year}-{int(edit_month):02d}ï¼‰":[int(month_fleet.get(m,0)) for m in MODEL_ORDER if m!="åˆè®¡"],
                "ç±»åˆ«":[MODEL_CATEGORY_MAP.get(m,"") for m in MODEL_ORDER if m!="åˆè®¡"],
            })
            st.dataframe(preview, use_container_width=True, height=240)
    with tab2:
        month_fleet=get_fleet_month(fleet, int(cur_year), int(edit_month))
        cols=st.columns(3); changed=False
        for i, mdl in enumerate([m for m in MODEL_ORDER if m!="åˆè®¡"]):
            with cols[i%3]:
                cur=int(month_fleet.get(mdl,0))
                val=st.number_input(mdl, min_value=0, max_value=10_000_000, value=cur, step=1, key=f"fleet_{cur_year}_{edit_month}_{mdl}")
                if val!=cur:
                    month_fleet[mdl]=int(val); changed=True
        if changed:
            fleet=set_fleet_month(fleet, int(cur_year), int(edit_month), month_fleet)
            save_model_fleet(fleet)
            st.success("å·²ä¿å­˜å½“æœˆåœ¨ä¿æ•°é‡ã€‚")

def _find_model_col(df0: pd.DataFrame):
    pri_candidates = ["å‹å·å½’ç±»","å‹å·ç³»åˆ—","series","model_series"]
    sec_candidates = ["æœºå‹","å…·ä½“å‹å·","äº§å“å‹å·","Part Model","PartModel","Part","MODEL","model","å‹å·"]
    for c in df0.columns:
        if str(c).strip().lower() in [n.lower() for n in pri_candidates]:
            return c
    for c in df0.columns:
        if str(c).strip().lower() in [n.lower() for n in sec_candidates]:
            return c
    return None

def build_model_table(df_all: pd.DataFrame, model_col: str, fleet_all: dict,
                      cur_year: int, sel_months: List[int], period_label: str,
                      use_avg_fleet: bool = False) -> pd.DataFrame:
    rows=[]; pat_11a=re.compile(r"(?<![0-9a-z])1\.1\.a(?![0-9a-z])", re.I)

    def _sum_fleet_months(fleet: dict, year: int, months: List[int]) -> dict:
        acc={k:0 for k in MODEL_ORDER if k!="åˆè®¡"}
        for m in months:
            mf = get_fleet_month(fleet, year, int(m))
            for mdl, v in mf.items():
                acc[mdl] = acc.get(mdl, 0) + int(v or 0)
        return acc

    if df_all.empty or (model_col is None):
        df_cur = pd.DataFrame(columns=list(df_all.columns)+["_model_norm","_is_11a","_paid"])
    else:
        y = pd.to_numeric(df_all.get("Year"), errors="coerce")
        m = pd.to_numeric(df_all.get("Month"), errors="coerce")
        df_cur = df_all[(y==int(cur_year)) & (m.isin(sel_months))].copy()

    if not df_cur.empty and model_col in df_cur.columns:
        known = list(MODEL_CATEGORY_MAP.keys())
        known_sorted = sorted(known, key=lambda k: len(k.replace(" ","")), reverse=True)
        known_nospace = {k.replace(" ",""):k for k in known}
        SPECIAL_TO_CHEF_BASE_SET = {"MGF8448GR","MGF8450","MGF8450GR","MGF8451GR","MGF8452GR","MGF8453","MGF8453GR","MGF8454GR"}
        def normalize_series(x:str)->str:
            s=(x or "")
            s_up = re.sub(r"^\s*REFRIGERATION\s*[-_:ï¼š/\\]\s*", "", s.upper())
            s_up = re.sub(r"[\s\-_\/]+"," ", s_up).strip()
            s0   = re.sub(r"[\s\-_\/]+","", s_up)
            if s0 in SPECIAL_TO_CHEF_BASE_SET: return "CHEF BASE"
            if ("CHEF" in s_up and "BASE" in s_up) or re.search(r"æŠ½å±‰|æŠ½å±‰å·¥ä½œå°", s, re.I): return "CHEF BASE"
            if s0 in known_nospace: return known_nospace[s0]
            for k in known_sorted:
                if s0.startswith(k.replace(" ","")): return k
            m0 = re.match(r"^([A-Z]{2,4})(\d.*)?$", s0)
            if m0 and m0.group(1) in known_nospace: return known_nospace[m0.group(1)]
            return ""
        df_cur["_model_norm"] = df_cur[model_col].astype(str).map(normalize_series)
        joined = df_cur.astype(str).agg(" ".join, axis=1).map(_clean_text)
        df_cur["_is_11a"] = joined.str.contains(pat_11a, regex=True)
        df_cur["_paid"]   = pd.to_numeric(df_cur.get("CostUSD", 0), errors="coerce").fillna(0) > 0
    else:
        df_cur = pd.DataFrame(columns=list(df_all.columns)+["_model_norm","_is_11a","_paid"])

    # æœŸé—´åœ¨ä¿é‡ï¼ˆåˆè®¡ï¼‰ï¼Œåç»­æŒ‰éœ€è½¬æˆâ€œå¹³å‡åœ¨ä¿é‡â€
    period_fleet_sum = _sum_fleet_months(fleet_all, cur_year, sel_months)
    n_months = max(1, len(sel_months))
    col_title = (f"åœ¨ä¿æ•°é‡ï¼ˆ{cur_year}å¹´ {period_label} å¹³å‡ï¼‰" if use_avg_fleet
                 else f"åœ¨ä¿æ•°é‡ï¼ˆ{cur_year}å¹´ {period_label} åˆè®¡ï¼‰")

    total_fleet_sum = total_qp = 0
    total_cost  = 0.0

    # å…ˆæŒ‰å‹å·é€è¡Œ
    for mdl in MODEL_ORDER:
        if mdl == "åˆè®¡": continue
        fleet_sum = int(period_fleet_sum.get(mdl, 0))
        fleet_for_rate = int(round(fleet_sum / n_months)) if use_avg_fleet else fleet_sum
        total_fleet_sum += (fleet_sum if not use_avg_fleet else fleet_for_rate)

        if not df_cur.empty and "_model_norm" in df_cur.columns:
            mask_model = (df_cur["_model_norm"] == mdl)
            qual_cnt   = int((mask_model & df_cur["_is_11a"]).sum())
            month_cost = float(pd.to_numeric(df_cur.loc[mask_model & df_cur["_is_11a"] & df_cur["_paid"], "CostUSD"], errors="coerce").fillna(0).sum())
        else:
            qual_cnt = 0; month_cost = 0.0

        total_qp   += qual_cnt
        total_cost += month_cost
        rate = (qual_cnt / fleet_for_rate * 100.0) if fleet_for_rate > 0 else 0.0

        rows.append({
            "å‹å·ç³»åˆ—": mdl,
            "ç±»åˆ«": MODEL_CATEGORY_MAP.get(mdl, ""),
            col_title: fleet_for_rate,
            "è´¨é‡é—®é¢˜ï¼ˆæœŸé—´åˆè®¡ï¼‰": qual_cnt,
            "æœŸé—´ç»´ä¿®ç‡": f"{rate:.3f}%",
            "æœŸé—´ç»´ä¿®è´¹ç”¨åˆè®¡": fmt_money(month_cost),
        })

    # åˆè®¡è¡Œ
    total_rate = (total_qp / total_fleet_sum * 100.0) if total_fleet_sum > 0 else 0.0
    rows.insert(0, {
        "å‹å·ç³»åˆ—": "åˆè®¡", "ç±»åˆ«": "",
        col_title: total_fleet_sum,
        "è´¨é‡é—®é¢˜ï¼ˆæœŸé—´åˆè®¡ï¼‰": total_qp,
        "æœŸé—´ç»´ä¿®ç‡": f"{total_rate:.3f}%",
        "æœŸé—´ç»´ä¿®è´¹ç”¨åˆè®¡": fmt_money(total_cost),
    })
    return pd.DataFrame(rows)

model_col = _find_model_col(df_all) if not df_all.empty else None
model_table = build_model_table(
    df_all, model_col, fleet, int(cur_year),
    sel_months=_sel_months,
    period_label=_sel_label,
    use_avg_fleet=_is_quarter 
)
st.dataframe(model_table, use_container_width=True)

# ============== å›ºå®šæ¸…å•èšåˆ + é“¾æ¥åˆ°é…ä»¶åˆ†æ ==============
def build_fixed_issue_table(df_scope: pd.DataFrame, mapping: list, *, drop_dupes: bool=False)->pd.DataFrame:
    if df_scope.empty: return pd.DataFrame(columns=["é¡¹ç›®ï¼ˆç¼–ç +è‹±æ–‡ï¼‰","é—®é¢˜ä¸­æ–‡å","æ•°é‡","è´¹ç”¨"])
    text_cols=["Category1","Category2","TAG1","TAG2","TAG3","TAG4","é—®é¢˜æè¿°","æè¿°","åŸå› ","å¤‡æ³¨","çŠ¶æ€","æ ‡é¢˜","Summary","Notes"]
    has_cols=[c for c in text_cols if c in df_scope.columns] or df_scope.columns.tolist()
    joined_all=df_scope[has_cols].astype(str).agg(" ".join, axis=1).str.lower()
    pat_11a=re.compile(r"(?<![0-9a-z])1\.1\.a(?![0-9a-z])", re.I)
    mask_11a=joined_all.str.contains(pat_11a)
    if not mask_11a.any(): return pd.DataFrame(columns=["é¡¹ç›®ï¼ˆç¼–ç +è‹±æ–‡ï¼‰","é—®é¢˜ä¸­æ–‡å","æ•°é‡","è´¹ç”¨"])
    df_11a=df_scope.loc[mask_11a].copy(); joined=joined_all.loc[mask_11a].copy()
    if drop_dupes:
        dedupe_keys=[c for c in ["Date","Category1","Category2","TAG1","TAG2","TAG3","TAG4","Summary","Notes"] if c in df_11a.columns]
        if dedupe_keys:
            df_11a["_dedupe_key"]=df_11a[dedupe_keys].astype(str).agg("|".join, axis=1)
            df_11a=df_11a.drop_duplicates(subset=["_dedupe_key"], keep="first")
            joined=df_11a[has_cols].astype(str).agg(" ".join, axis=1).str.lower()
    cost=pd.to_numeric(df_11a.get("CostUSD",0), errors="coerce").fillna(0.0)
    paid_mask=(cost>0)
    rows=[]
    for item in mapping:
        code=item["code"].strip(); en=item["en"].strip(); cn=item["cn"].strip()
        code_pat=re.compile(rf"(?<![0-9a-z]){re.escape(code)}(?![0-9a-z])", re.I)
        m=joined.str.contains(code_pat)
        qty=int(m.sum()); fee_val=float(cost[m & paid_mask].sum())
        rows.append({"é¡¹ç›®ï¼ˆç¼–ç +è‹±æ–‡ï¼‰":f"{code} {en}","é—®é¢˜ä¸­æ–‡å":cn,"æ•°é‡":qty,"è´¹ç”¨":f"${fee_val:,.0f}","_fee_val":fee_val,"_code":code})
    out=(pd.DataFrame(rows).sort_values(["æ•°é‡","_fee_val"], ascending=[False,False]).reset_index(drop=True))
    return out

st.markdown("### è´¨é‡é—®é¢˜æ˜ç»†ï¼ˆå›ºå®šæ¸…å•ï¼Œè‡ªåŠ¨æ±‡æ€»ï¼‰")
scope = st.radio("ç»Ÿè®¡å£å¾„", ["æŒ‰æ‰€é€‰æœŸé—´ï¼ˆæœˆä»½/å­£åº¦ï¼‰","æŒ‰å…¨å¹´"], index=0, horizontal=True)
df_year_only = df_all[_year_series==cur_year]
if scope == "æŒ‰æ‰€é€‰æœŸé—´ï¼ˆæœˆä»½/å­£åº¦ï¼‰":
    df_scope = df_period
    title_suffix = f"{cur_year}å¹´ {_sel_label}"
    _dl_tag = _sel_label.replace(" ", "").replace("(", "").replace(")", "")
    download_name = f"å›ºå®šè´¨é‡é—®é¢˜æ¸…å•_{cur_year}_{_dl_tag}.csv"
else:
    df_scope = df_year_only
    title_suffix = f"{cur_year}å…¨å¹´"
    download_name = f"å›ºå®šè´¨é‡é—®é¢˜æ¸…å•_{cur_year}.csv"

st.session_state['store_df'] = ensure_cols(df_all.copy())

fixed_table = build_fixed_issue_table(df_scope, FIXED_DEFECTS)
if fixed_table.empty:
    st.info(f"{title_suffix} æ— æ•°æ®å¯ç»Ÿè®¡ã€‚")
else:
        # â€”â€” ç»Ÿä¸€æ„é€  months ä¸ q å‚æ•°ï¼ˆæ— è®ºå•æœˆ/å­£åº¦/å¤šæœˆéƒ½ä¼  monthsï¼‰
    _months_param = ",".join(str(m) for m in _sel_months)
    _q_name = None
    if set(_sel_months) == {1,2,3}:   _q_name = "Q1"
    elif set(_sel_months) == {4,5,6}: _q_name = "Q2"
    elif set(_sel_months) == {7,8,9}: _q_name = "Q3"
    elif set(_sel_months) == {10,11,12}: _q_name = "Q4"

    def _build_link(code: str) -> str:
        base = (page_url_by_code(__file__, str(code)) or "#")
        if _q_name:
            return f"{base}?code={quote(str(code))}&year={int(cur_year)}&months={_months_param}&q={_q_name}"
        else:
            return f"{base}?code={quote(str(code))}&year={int(cur_year)}&months={_months_param}"

    fixed_table["é…ä»¶åˆ†æ"] = fixed_table["_code"].apply(_build_link)


    st.caption(f"ç»Ÿè®¡å£å¾„ï¼š{title_suffix}")
    st.data_editor(
        fixed_table[["é¡¹ç›®ï¼ˆç¼–ç +è‹±æ–‡ï¼‰","é—®é¢˜ä¸­æ–‡å","æ•°é‡","è´¹ç”¨","é…ä»¶åˆ†æ"]],
        use_container_width=True, height=520, disabled=True,
        column_config={"é…ä»¶åˆ†æ": st.column_config.LinkColumn("é…ä»¶åˆ†æ", display_text="æ‰“å¼€é…ä»¶åˆ†æ")}
    )
    st.download_button(
        "ä¸‹è½½ CSV",
        data=fixed_table.drop(columns=["_fee_val","_code"], errors="ignore").to_csv(index=False, encoding="utf-8-sig"),
        file_name=download_name,
        mime="text/csv",
        use_container_width=True
    )

# ============== åŸå§‹ Excel è¡¨æ˜ å°„ï¼ˆåŸæ ·æ˜¾ç¤ºâ€œç”Ÿäº§æ—¥æœŸâ€ï¼‰ ==============
def _filter_raw_history_by_month(df_hist: pd.DataFrame, y: int, m: int) -> pd.DataFrame:
    if df_hist is None or df_hist.empty:
        return pd.DataFrame()
    pat = _MMYYYY_ANY
    hits = []
    for col in df_hist.columns:
        if col in {"__SourceFile", "__ImportedAt"}:
            continue
        try:
            s = df_hist[col].astype(str)
        except Exception:
            continue
        ext = s.str.extract(pat)
        if ext.isna().all().all():
            continue
        mm = pd.to_numeric(ext["mm"], errors="coerce")
        yy = pd.to_numeric(ext["yyyy"], errors="coerce")
        mask = (yy == int(y)) & (mm == int(m))
        if mask.any():
            hits.append(df_hist.loc[mask, df_hist.columns])
    if not hits:
        return pd.DataFrame(columns=df_hist.columns)
    out = pd.concat(hits, ignore_index=True)
    try:
        key_cols = [c for c in out.columns if not c.startswith("__")]
        sig = out[key_cols].astype(str).agg("|".join, axis=1).str.lower()
        out = out.loc[~sig.duplicated(keep="first")].reset_index(drop=True)
    except Exception:
        pass
    return out

with st.expander("ğŸ“ åŸå§‹ Excel è¡¨æ˜ å°„ï¼ˆåŸæ ·æ˜¾ç¤ºâ€œç”Ÿäº§æ—¥æœŸâ€ï¼Œæ—  Year/Monthï¼‰", expanded=False):
    _hist = st.session_state.get("excel_raw_history", pd.DataFrame())
    if _hist is None or _hist.empty:
        st.info("æš‚æ— åŸå§‹ä¸Šä¼ å†å²ã€‚è¯·å…ˆä¸Šä¼  Excelã€‚")
    else:
        _excel_filtered = _filter_raw_history_by_month(_hist, cur_year, edit_month)
        st.caption(f"æ˜¾ç¤ºå£å¾„ï¼š{cur_year}-{edit_month:02d}ï¼ˆè‡ªåŠ¨ä»æ‰€æœ‰åˆ—ä¸­è¯†åˆ« MMYYYYï¼‰")
        if _excel_filtered.empty:
            st.info("è¯¥æœˆåœ¨åŸå§‹å†å²ä¸­æ²¡æœ‰åŒ¹é…åˆ°æ•°æ®ã€‚è¯·æ›´æ¢å¹´æœˆæˆ–æ£€æŸ¥æ•°æ®ä¸­çš„æ—¥æœŸæ–‡æœ¬æ˜¯å¦åŒ…å« MMYYYYã€‚")
        else:
            cols = [c for c in _excel_filtered.columns if c not in {"__SourceFile","__ImportedAt"}]
            cols = cols + [c for c in ["__SourceFile","__ImportedAt"] if c in _excel_filtered.columns]
            _view = _excel_filtered[cols]
            def _fmt_prod_date_cell(v):
                s = "" if pd.isna(v) else str(v).strip()
                m6 = re.fullmatch(r"(\d{2})(\d{2})(\d{2})", s)
                if m6:
                    yy, mm, dd = m6.groups()
                    return f"{2000 + int(yy)}/{mm}/{dd}"
                m8 = re.fullmatch(r"(\d{4})(\d{2})(\d{2})", s)
                if m8:
                    y, mm, dd = m8.groups()
                    return f"{int(y)}/{mm}/{dd}"
                try:
                    dt = pd.to_datetime(s, errors="coerce")
                    if pd.isna(dt):
                        return v
                    return f"{dt.year}/{dt.month}/{dt.day}"
                except Exception:
                    return v
            prod_cols = [c for c in _view.columns if re.search(r"ç”Ÿäº§\s*æ—¥æœŸ", str(c), re.I)]
            _view_display = _view.copy()
            for c in prod_cols:
                _view_display[c] = _view_display[c].map(_fmt_prod_date_cell)
            _n = int(min(len(_view_display), 16))
            _h = int(46 + 28 * max(_n, 1))
            st.dataframe(_view_display, use_container_width=True, height=min(_h, 600))

# ============== è°ƒè¯•åŒºåŸŸ ==============
with st.expander("è°ƒè¯•ï¼šæœ¬æœˆå…³é”®å­—å‘½ä¸­ç»Ÿè®¡ï¼ˆå½“é€‰æ‹©å­£åº¦æ—¶ï¼Œè¿™é‡Œé»˜è®¤ç”¨è¯¥æœŸé—´æœ€åä¸€ä¸ªæœˆï¼‰", expanded=False):
    df_month_real = df_all[(_year_series==cur_year) & (_month_series==edit_month)]
    if not df_month_real.empty:
        joined=df_month_real.astype(str).agg(" ".join, axis=1).map(_clean_text)
        cnt_11a = int(joined.str.contains(re.compile(r"1\.1\.a", re.I)).sum())
        cnt_atosa=int(joined.str.contains(re.compile(r"\batosa\b", re.I)).sum())
        real_cat=df_month_real[(df_month_real["Category1"]=="è´¨é‡é—®é¢˜") & (df_month_real["Category2"]=="Atosa")]
        st.write({"1.1.a å‘½ä¸­æ•°(æ–‡æœ¬)":cnt_11a,"atosa å‘½ä¸­æ•°(æ–‡æœ¬)":cnt_atosa,"æœ€ç»ˆåˆ†ç±»åˆ°ã€è´¨é‡é—®é¢˜/Atosaã€":len(real_cat)})
    else:
        st.write("æœ¬æœˆæ— æ•°æ®")

with st.expander("è°ƒè¯•ï¼šæ¥æºä¸å£å¾„", expanded=False):
    if not df_all.empty:
        st.write("æ€»è®°å½•æ•°ï¼ˆå·²æŒ‰ 2025â€“2030 è¿‡æ»¤åï¼‰ï¼š", len(df_all))
        if "_SrcYM" in df_all.columns:
            st.write("_SrcYM åˆ†å¸ƒï¼ˆTop 10ï¼‰ï¼š"); st.write(df_all["_SrcYM"].value_counts().head(10))
        st.write("å½“æœˆè®°å½•æ•°ï¼š", len(df_all[(_year_series==cur_year)&(_month_series==edit_month)]), " | å…¨å¹´è®°å½•æ•°ï¼š", len(df_year_only))
        st.write("æœ€è¿‘ä¸€æ¬¡ä¸Šä¼ æ–‡ä»¶ MD5ï¼š", st.session_state.get("_last_upload_md5","æ— "))
    else:
        st.write("æš‚æ— æ•°æ®")

with st.expander("ğŸ” è·³è½¬è‡ªæ£€", expanded=False):
    st.write("æ˜ å°„è¡¨ï¼š", {k: v for k, v in _FORCE_CODE2PAGE.items()})
    for code, target in _FORCE_CODE2PAGE.items():
        via_pages = _find_page_url(target)
        guessed   = _guess_url_from_filename(target)
        final     = page_url_by_code(__file__, code)
        st.write(f"{code} â†’ {target} â†’ get_pages: {via_pages} | guessed: {guessed} | final: {final}")
